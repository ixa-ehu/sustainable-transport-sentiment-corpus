{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MULTICLASS.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyOvigTWEbt1q8JYe9D2yDBG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"-M5w6GAmP5yR","colab":{"base_uri":"https://localhost:8080/","height":136},"executionInfo":{"status":"ok","timestamp":1602837853045,"user_tz":-120,"elapsed":6497,"user":{"displayName":"Nui Nui","photoUrl":"","userId":"04667784782263367512"}},"outputId":"b12c7f38-8352-478b-a9f1-7bcd18e41619"},"source":["!git clone https://github.com/huggingface/transformers"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Cloning into 'transformers'...\n","remote: Enumerating objects: 58, done.\u001b[K\n","remote: Counting objects: 100% (58/58), done.\u001b[K\n","remote: Compressing objects: 100% (47/47), done.\u001b[K\n","remote: Total 46995 (delta 28), reused 7 (delta 5), pack-reused 46937\u001b[K\n","Receiving objects: 100% (46995/46995), 33.71 MiB | 30.28 MiB/s, done.\n","Resolving deltas: 100% (32650/32650), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cDbv-2a8P8t8","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1602837941504,"user_tz":-120,"elapsed":22554,"user":{"displayName":"Nui Nui","photoUrl":"","userId":"04667784782263367512"}},"outputId":"aa5f897c-0dab-47ae-cc07-809f5c7aeac7"},"source":["#!pip install --upgrade transformers\n","!pip install transformers==2.7.0\n","!pip install seqeval"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting transformers==2.7.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/37/ba/dda44bbf35b071441635708a3dd568a5ca6bf29f77389f7c7c6818ae9498/transformers-2.7.0-py3-none-any.whl (544kB)\n","\u001b[K     |████████████████████████████████| 552kB 4.7MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.7.0) (2019.12.20)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==2.7.0) (4.41.1)\n","Collecting tokenizers==0.5.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n","\u001b[K     |████████████████████████████████| 3.7MB 21.6MB/s \n","\u001b[?25hCollecting boto3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4b/b9/88fbe33f4f4862b06eed9e1fb05abb8883b0bf2683a87f21c45d597adc5a/boto3-1.15.17-py2.py3-none-any.whl (129kB)\n","\u001b[K     |████████████████████████████████| 133kB 38.6MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.7.0) (2.23.0)\n","Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 52.7MB/s \n","\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==2.7.0) (0.7)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.7.0) (3.0.12)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 60.1MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.7.0) (1.18.5)\n","Collecting s3transfer<0.4.0,>=0.3.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69kB)\n","\u001b[K     |████████████████████████████████| 71kB 11.1MB/s \n","\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n","  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n","Collecting botocore<1.19.0,>=1.18.17\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/12/6e/73f5a0c1041090589531d346d9310030a135b04cb0570d357da699a56a52/botocore-1.18.17-py2.py3-none-any.whl (6.7MB)\n","\u001b[K     |████████████████████████████████| 6.7MB 50.6MB/s \n","\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.7.0) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.7.0) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.7.0) (2020.6.20)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.7.0) (2.10)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.7.0) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.7.0) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.7.0) (0.16.0)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.19.0,>=1.18.17->boto3->transformers==2.7.0) (2.8.1)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=72cedcb7d9324862325422026be2cce31f738477801f4549409c43b4a9ba5550\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, jmespath, botocore, s3transfer, boto3, sentencepiece, sacremoses, transformers\n","Successfully installed boto3-1.15.17 botocore-1.18.17 jmespath-0.10.0 s3transfer-0.3.3 sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.5.2 transformers-2.7.0\n","Collecting seqeval\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/be/cd/d467b26ee460ff69c04e225c3bc7ea97ade4dc43c6982bac99ff032bb3e1/seqeval-1.2.0.tar.gz (42kB)\n","\u001b[K     |████████████████████████████████| 51kB 2.5MB/s \n","\u001b[?25hCollecting numpy==1.19.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/97/af8a92864a04bfa48f1b5c9b1f8bf2ccb2847f24530026f26dd223de4ca0/numpy-1.19.2-cp36-cp36m-manylinux2010_x86_64.whl (14.5MB)\n","\u001b[K     |████████████████████████████████| 14.5MB 236kB/s \n","\u001b[?25hCollecting scikit-learn==0.23.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/a1/273def87037a7fb010512bbc5901c31cfddfca8080bc63b42b26e3cc55b3/scikit_learn-0.23.2-cp36-cp36m-manylinux1_x86_64.whl (6.8MB)\n","\u001b[K     |████████████████████████████████| 6.8MB 55.3MB/s \n","\u001b[?25hCollecting threadpoolctl>=2.0.0\n","  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.23.2->seqeval) (0.16.0)\n","Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.23.2->seqeval) (1.4.1)\n","Building wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.0-cp36-none-any.whl size=15774 sha256=91ef02cd8d44b187ce94d2c0c6fc6681d41d9fda9e733945d77b39f498e34c5e\n","  Stored in directory: /root/.cache/pip/wheels/34/10/d6/4d565d510013329c4dac21f42927b88e802e88f824559ad7d9\n","Successfully built seqeval\n","\u001b[31mERROR: tensorflow 2.3.0 has requirement numpy<1.19.0,>=1.16.0, but you'll have numpy 1.19.2 which is incompatible.\u001b[0m\n","\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Installing collected packages: numpy, threadpoolctl, scikit-learn, seqeval\n","  Found existing installation: numpy 1.18.5\n","    Uninstalling numpy-1.18.5:\n","      Successfully uninstalled numpy-1.18.5\n","  Found existing installation: scikit-learn 0.22.2.post1\n","    Uninstalling scikit-learn-0.22.2.post1:\n","      Successfully uninstalled scikit-learn-0.22.2.post1\n","Successfully installed numpy-1.19.2 scikit-learn-0.23.2 seqeval-1.2.0 threadpoolctl-2.1.0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"Oak92WfdLVMi","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1602837973997,"user_tz":-120,"elapsed":26957,"user":{"displayName":"Nui Nui","photoUrl":"","userId":"04667784782263367512"}},"outputId":"95a4cd63-0181-459b-9552-35a3840803f9"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-h67jYZHQoT8"},"source":["!python /content/gdrive/My\\ Drive/pythoncode/utils_classification.py"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AlcARRskNcO5","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1602838594445,"user_tz":-120,"elapsed":607035,"user":{"displayName":"Nui Nui","photoUrl":"","userId":"04667784782263367512"}},"outputId":"6d6e7e21-5a6f-444a-b881-bd28f9d9033b"},"source":["!export CUDA_VISIBLE_DEVICES=0\n","!export MAX_LENGTH=128\n","!export TRAIN_BATCH_SIZE=16\n","!export LEARNING_RATE=5e-5\n","!export SAVE_STEPS=0\n","!export SEED=1\n","!export EPOCHS=10\n","\n","!export CORPUS_DIR=/content/gdrive/My\\ Drive/pythoncode/experiments/CLASSIFICATION_1_2_3_4_5\n","\n","\n","!mkdir model-xlmroberta-e10-MULTICLASS\n","\n","!python /content/gdrive/My\\ Drive/pythoncode/transformers-training-scripts-master/run_classification.py --data_dir=/content/gdrive/My\\ Drive/pythoncode/experiments/CLASSIFICATION_1_2_3_4_5  \\\n","--labels /content/gdrive/My\\ Drive/pythoncode/experiments/CLASSIFICATION_1_2_3_4_5/labels.txt \\\n","--model_type xlm-roberta \\\n","--model_name_or_path 'xlm-roberta-base' \\\n","--output_dir='model-xlmroberta-e10-MULTICLASS' \\\n","--max_seq_length 128 \\\n","--num_train_epochs=10 \\\n","--per_gpu_train_batch_size 16 \\\n","--learning_rate 5e-5 \\\n","--save_steps 0 \\\n","--seed 1 \\\n","--overwrite_cache \\\n","--do_train \\\n","--do_eval \\\n","--do_predict \\\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-10-16 08:46:30.622654: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","10/16/2020 08:46:32 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","10/16/2020 08:46:33 - INFO - filelock -   Lock 140088735149024 acquired on /root/.cache/torch/transformers/762ddd751172e9d3229e5da17a459eee6c0dfdc237c718944d0b1a85f06c7e1e.2b0f807393c56e8861a31cd67d2fc0b45d71d9735dd47dd66afb650f90b6d2a8.lock\n","10/16/2020 08:46:33 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmppwlwufao\n","Downloading: 100% 512/512 [00:00<00:00, 645kB/s]\n","10/16/2020 08:46:33 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-config.json in cache at /root/.cache/torch/transformers/762ddd751172e9d3229e5da17a459eee6c0dfdc237c718944d0b1a85f06c7e1e.2b0f807393c56e8861a31cd67d2fc0b45d71d9735dd47dd66afb650f90b6d2a8\n","10/16/2020 08:46:33 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/762ddd751172e9d3229e5da17a459eee6c0dfdc237c718944d0b1a85f06c7e1e.2b0f807393c56e8861a31cd67d2fc0b45d71d9735dd47dd66afb650f90b6d2a8\n","10/16/2020 08:46:33 - INFO - filelock -   Lock 140088735149024 released on /root/.cache/torch/transformers/762ddd751172e9d3229e5da17a459eee6c0dfdc237c718944d0b1a85f06c7e1e.2b0f807393c56e8861a31cd67d2fc0b45d71d9735dd47dd66afb650f90b6d2a8.lock\n","10/16/2020 08:46:33 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-config.json from cache at /root/.cache/torch/transformers/762ddd751172e9d3229e5da17a459eee6c0dfdc237c718944d0b1a85f06c7e1e.2b0f807393c56e8861a31cd67d2fc0b45d71d9735dd47dd66afb650f90b6d2a8\n","10/16/2020 08:46:33 - INFO - transformers.configuration_utils -   Model config XLMRobertaConfig {\n","  \"_num_labels\": 5,\n","  \"architectures\": [\n","    \"XLMRobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": 2,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"1\",\n","    \"1\": \"2\",\n","    \"2\": \"3\",\n","    \"3\": \"4\",\n","    \"4\": \"5\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"1\": 0,\n","    \"2\": 1,\n","    \"3\": 2,\n","    \"4\": 3,\n","    \"5\": 4\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 514,\n","  \"min_length\": 0,\n","  \"model_type\": \"xlm-roberta\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 1,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 250002\n","}\n","\n","10/16/2020 08:46:33 - INFO - __main__ -   Tokenizer arguments: {'do_lower_case': False}\n","10/16/2020 08:46:33 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-config.json from cache at /root/.cache/torch/transformers/762ddd751172e9d3229e5da17a459eee6c0dfdc237c718944d0b1a85f06c7e1e.2b0f807393c56e8861a31cd67d2fc0b45d71d9735dd47dd66afb650f90b6d2a8\n","10/16/2020 08:46:33 - INFO - transformers.configuration_utils -   Model config XLMRobertaConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"XLMRobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": 2,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 514,\n","  \"min_length\": 0,\n","  \"model_type\": \"xlm-roberta\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 1,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 250002\n","}\n","\n","10/16/2020 08:46:34 - INFO - filelock -   Lock 140088735146672 acquired on /root/.cache/torch/transformers/0c370616ddfc06067c0634160f749c2cf9d8da2c50e03a2617ce5841c8df3b1d.309f0c29486cffc28e1e40a2ab0ac8f500c203fe080b95f820aa9cb58e5b84ed.lock\n","10/16/2020 08:46:34 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-sentencepiece.bpe.model not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp6hh0bnq9\n","Downloading: 100% 5.07M/5.07M [00:00<00:00, 9.16MB/s]\n","10/16/2020 08:46:35 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-sentencepiece.bpe.model in cache at /root/.cache/torch/transformers/0c370616ddfc06067c0634160f749c2cf9d8da2c50e03a2617ce5841c8df3b1d.309f0c29486cffc28e1e40a2ab0ac8f500c203fe080b95f820aa9cb58e5b84ed\n","10/16/2020 08:46:35 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/0c370616ddfc06067c0634160f749c2cf9d8da2c50e03a2617ce5841c8df3b1d.309f0c29486cffc28e1e40a2ab0ac8f500c203fe080b95f820aa9cb58e5b84ed\n","10/16/2020 08:46:35 - INFO - filelock -   Lock 140088735146672 released on /root/.cache/torch/transformers/0c370616ddfc06067c0634160f749c2cf9d8da2c50e03a2617ce5841c8df3b1d.309f0c29486cffc28e1e40a2ab0ac8f500c203fe080b95f820aa9cb58e5b84ed.lock\n","10/16/2020 08:46:35 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-sentencepiece.bpe.model from cache at /root/.cache/torch/transformers/0c370616ddfc06067c0634160f749c2cf9d8da2c50e03a2617ce5841c8df3b1d.309f0c29486cffc28e1e40a2ab0ac8f500c203fe080b95f820aa9cb58e5b84ed\n","tokenizer object loaded:  <transformers.tokenization_xlm_roberta.XLMRobertaTokenizer object at 0x7f68f34ba390>\n","10/16/2020 08:46:35 - INFO - filelock -   Lock 140088735474128 acquired on /root/.cache/torch/transformers/f80a708b21cc9b248e8af5a630ad9f887326bbaf0098b9f354427b2463d55346.aeeaca90954dc20ffa2909de722cfbfd455c5bb16d480c5bdf6d7fe79c68c267.lock\n","10/16/2020 08:46:35 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp6rjn8kr4\n","Downloading: 100% 1.12G/1.12G [00:27<00:00, 39.9MB/s]\n","10/16/2020 08:47:04 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-pytorch_model.bin in cache at /root/.cache/torch/transformers/f80a708b21cc9b248e8af5a630ad9f887326bbaf0098b9f354427b2463d55346.aeeaca90954dc20ffa2909de722cfbfd455c5bb16d480c5bdf6d7fe79c68c267\n","10/16/2020 08:47:04 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/f80a708b21cc9b248e8af5a630ad9f887326bbaf0098b9f354427b2463d55346.aeeaca90954dc20ffa2909de722cfbfd455c5bb16d480c5bdf6d7fe79c68c267\n","10/16/2020 08:47:04 - INFO - filelock -   Lock 140088735474128 released on /root/.cache/torch/transformers/f80a708b21cc9b248e8af5a630ad9f887326bbaf0098b9f354427b2463d55346.aeeaca90954dc20ffa2909de722cfbfd455c5bb16d480c5bdf6d7fe79c68c267.lock\n","10/16/2020 08:47:04 - INFO - transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-pytorch_model.bin from cache at /root/.cache/torch/transformers/f80a708b21cc9b248e8af5a630ad9f887326bbaf0098b9f354427b2463d55346.aeeaca90954dc20ffa2909de722cfbfd455c5bb16d480c5bdf6d7fe79c68c267\n","10/16/2020 08:47:16 - INFO - transformers.modeling_utils -   Weights of XLMRobertaForSequenceClassification not initialized from pretrained model: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n","10/16/2020 08:47:16 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in XLMRobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n","10/16/2020 08:47:30 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir='/content/gdrive/My Drive/pythoncode/experiments/regresion', device=device(type='cuda'), do_eval=True, do_lower_case=False, do_predict=True, do_train=True, eval_all_checkpoints=False, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, keep_accents=None, labels='/content/gdrive/My Drive/pythoncode/experiments/regresion/labels.txt', learning_rate=5e-05, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='xlm-roberta-base', model_type='xlm-roberta', n_gpu=1, no_cuda=False, num_train_epochs=10.0, output_dir='model-xlmroberta-e10-regresion', overwrite_cache=True, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=16, save_steps=0, seed=1, server_ip='', server_port='', strip_accents=None, tokenizer_name='', use_fast=None, warmup_steps=0, weight_decay=0.0)\n","10/16/2020 08:47:30 - INFO - __main__ -   Creating features from dataset file at /content/gdrive/My Drive/pythoncode/experiments/regresion\n","100% 1760/1760 [00:00<00:00, 15002.86it/s]\n","10/16/2020 08:47:30 - INFO - __main__ -   Saving features into cached file /content/gdrive/My Drive/pythoncode/experiments/regresion/cached_train_xlm-roberta-base_128\n","10/16/2020 08:47:31 - INFO - __main__ -   ***** Running training *****\n","10/16/2020 08:47:31 - INFO - __main__ -     Num examples = 1760\n","10/16/2020 08:47:31 - INFO - __main__ -     Num Epochs = 10\n","10/16/2020 08:47:31 - INFO - __main__ -     Instantaneous batch size per GPU = 16\n","10/16/2020 08:47:31 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 16\n","10/16/2020 08:47:31 - INFO - __main__ -     Gradient Accumulation steps = 1\n","10/16/2020 08:47:31 - INFO - __main__ -     Total optimization steps = 1100\n","Epoch:   0% 0/10 [00:00<?, ?it/s]\n","Iteration:   0% 0/110 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.6/dist-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n","  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n","\n","Iteration:   1% 1/110 [00:00<01:17,  1.40it/s]\u001b[A\n","Iteration:   2% 2/110 [00:01<01:07,  1.60it/s]\u001b[A\n","Iteration:   3% 3/110 [00:01<01:00,  1.78it/s]\u001b[A\n","Iteration:   4% 4/110 [00:01<00:55,  1.92it/s]\u001b[A\n","Iteration:   5% 5/110 [00:02<00:51,  2.04it/s]\u001b[A\n","Iteration:   5% 6/110 [00:02<00:48,  2.13it/s]\u001b[A\n","Iteration:   6% 7/110 [00:03<00:46,  2.20it/s]\u001b[A\n","Iteration:   7% 8/110 [00:03<00:45,  2.25it/s]\u001b[A\n","Iteration:   8% 9/110 [00:04<00:44,  2.29it/s]\u001b[A\n","Iteration:   9% 10/110 [00:04<00:43,  2.31it/s]\u001b[A\n","Iteration:  10% 11/110 [00:04<00:42,  2.32it/s]\u001b[A\n","Iteration:  11% 12/110 [00:05<00:41,  2.33it/s]\u001b[A\n","Iteration:  12% 13/110 [00:05<00:41,  2.35it/s]\u001b[A\n","Iteration:  13% 14/110 [00:06<00:40,  2.35it/s]\u001b[A\n","Iteration:  14% 15/110 [00:06<00:40,  2.36it/s]\u001b[A\n","Iteration:  15% 16/110 [00:07<00:40,  2.31it/s]\u001b[A\n","Iteration:  15% 17/110 [00:07<00:39,  2.33it/s]\u001b[A\n","Iteration:  16% 18/110 [00:07<00:39,  2.34it/s]\u001b[A\n","Iteration:  17% 19/110 [00:08<00:38,  2.34it/s]\u001b[A\n","Iteration:  18% 20/110 [00:08<00:38,  2.34it/s]\u001b[A\n","Iteration:  19% 21/110 [00:09<00:37,  2.35it/s]\u001b[A\n","Iteration:  20% 22/110 [00:09<00:37,  2.35it/s]\u001b[A\n","Iteration:  21% 23/110 [00:10<00:37,  2.33it/s]\u001b[A\n","Iteration:  22% 24/110 [00:10<00:36,  2.35it/s]\u001b[A\n","Iteration:  23% 25/110 [00:10<00:36,  2.35it/s]\u001b[A\n","Iteration:  24% 26/110 [00:11<00:35,  2.35it/s]\u001b[A\n","Iteration:  25% 27/110 [00:11<00:35,  2.35it/s]\u001b[A\n","Iteration:  25% 28/110 [00:12<00:34,  2.35it/s]\u001b[A\n","Iteration:  26% 29/110 [00:12<00:34,  2.35it/s]\u001b[A\n","Iteration:  27% 30/110 [00:13<00:34,  2.35it/s]\u001b[A\n","Iteration:  28% 31/110 [00:13<00:33,  2.35it/s]\u001b[A\n","Iteration:  29% 32/110 [00:13<00:33,  2.34it/s]\u001b[A\n","Iteration:  30% 33/110 [00:14<00:32,  2.35it/s]\u001b[A\n","Iteration:  31% 34/110 [00:14<00:32,  2.35it/s]\u001b[A\n","Iteration:  32% 35/110 [00:15<00:31,  2.34it/s]\u001b[A\n","Iteration:  33% 36/110 [00:15<00:31,  2.35it/s]\u001b[A\n","Iteration:  34% 37/110 [00:15<00:31,  2.35it/s]\u001b[A\n","Iteration:  35% 38/110 [00:16<00:30,  2.35it/s]\u001b[A\n","Iteration:  35% 39/110 [00:16<00:30,  2.35it/s]\u001b[A\n","Iteration:  36% 40/110 [00:17<00:29,  2.34it/s]\u001b[A\n","Iteration:  37% 41/110 [00:17<00:29,  2.34it/s]\u001b[A\n","Iteration:  38% 42/110 [00:18<00:29,  2.34it/s]\u001b[A\n","Iteration:  39% 43/110 [00:18<00:28,  2.33it/s]\u001b[A\n","Iteration:  40% 44/110 [00:18<00:28,  2.33it/s]\u001b[A\n","Iteration:  41% 45/110 [00:19<00:27,  2.33it/s]\u001b[A\n","Iteration:  42% 46/110 [00:19<00:27,  2.34it/s]\u001b[A\n","Iteration:  43% 47/110 [00:20<00:26,  2.34it/s]\u001b[A\n","Iteration:  44% 48/110 [00:20<00:26,  2.33it/s]\u001b[A\n","Iteration:  45% 49/110 [00:21<00:26,  2.32it/s]\u001b[A\n","Iteration:  45% 50/110 [00:21<00:25,  2.32it/s]\u001b[A\n","Iteration:  46% 51/110 [00:21<00:25,  2.34it/s]\u001b[A\n","Iteration:  47% 52/110 [00:22<00:24,  2.33it/s]\u001b[A\n","Iteration:  48% 53/110 [00:22<00:24,  2.31it/s]\u001b[A\n","Iteration:  49% 54/110 [00:23<00:24,  2.32it/s]\u001b[A\n","Iteration:  50% 55/110 [00:23<00:23,  2.31it/s]\u001b[A\n","Iteration:  51% 56/110 [00:24<00:23,  2.32it/s]\u001b[A\n","Iteration:  52% 57/110 [00:24<00:22,  2.32it/s]\u001b[A\n","Iteration:  53% 58/110 [00:25<00:22,  2.32it/s]\u001b[A\n","Iteration:  54% 59/110 [00:25<00:22,  2.32it/s]\u001b[A\n","Iteration:  55% 60/110 [00:25<00:21,  2.31it/s]\u001b[A\n","Iteration:  55% 61/110 [00:26<00:21,  2.32it/s]\u001b[A\n","Iteration:  56% 62/110 [00:26<00:20,  2.31it/s]\u001b[A\n","Iteration:  57% 63/110 [00:27<00:20,  2.31it/s]\u001b[A\n","Iteration:  58% 64/110 [00:27<00:19,  2.31it/s]\u001b[A\n","Iteration:  59% 65/110 [00:28<00:19,  2.31it/s]\u001b[A\n","Iteration:  60% 66/110 [00:28<00:19,  2.31it/s]\u001b[A\n","Iteration:  61% 67/110 [00:28<00:18,  2.30it/s]\u001b[A\n","Iteration:  62% 68/110 [00:29<00:18,  2.30it/s]\u001b[A\n","Iteration:  63% 69/110 [00:29<00:17,  2.30it/s]\u001b[A\n","Iteration:  64% 70/110 [00:30<00:17,  2.30it/s]\u001b[A\n","Iteration:  65% 71/110 [00:30<00:16,  2.30it/s]\u001b[A\n","Iteration:  65% 72/110 [00:31<00:16,  2.30it/s]\u001b[A\n","Iteration:  66% 73/110 [00:31<00:16,  2.30it/s]\u001b[A\n","Iteration:  67% 74/110 [00:31<00:15,  2.30it/s]\u001b[A\n","Iteration:  68% 75/110 [00:32<00:15,  2.29it/s]\u001b[A\n","Iteration:  69% 76/110 [00:32<00:14,  2.29it/s]\u001b[A\n","Iteration:  70% 77/110 [00:33<00:14,  2.29it/s]\u001b[A\n","Iteration:  71% 78/110 [00:33<00:13,  2.29it/s]\u001b[A\n","Iteration:  72% 79/110 [00:34<00:13,  2.30it/s]\u001b[A\n","Iteration:  73% 80/110 [00:34<00:13,  2.28it/s]\u001b[A\n","Iteration:  74% 81/110 [00:35<00:12,  2.29it/s]\u001b[A\n","Iteration:  75% 82/110 [00:35<00:12,  2.28it/s]\u001b[A\n","Iteration:  75% 83/110 [00:35<00:11,  2.28it/s]\u001b[A\n","Iteration:  76% 84/110 [00:36<00:11,  2.28it/s]\u001b[A\n","Iteration:  77% 85/110 [00:36<00:10,  2.29it/s]\u001b[A\n","Iteration:  78% 86/110 [00:37<00:10,  2.29it/s]\u001b[A\n","Iteration:  79% 87/110 [00:37<00:10,  2.29it/s]\u001b[A\n","Iteration:  80% 88/110 [00:38<00:09,  2.28it/s]\u001b[A\n","Iteration:  81% 89/110 [00:38<00:09,  2.28it/s]\u001b[A\n","Iteration:  82% 90/110 [00:38<00:08,  2.28it/s]\u001b[A\n","Iteration:  83% 91/110 [00:39<00:08,  2.28it/s]\u001b[A\n","Iteration:  84% 92/110 [00:39<00:07,  2.28it/s]\u001b[A\n","Iteration:  85% 93/110 [00:40<00:07,  2.28it/s]\u001b[A\n","Iteration:  85% 94/110 [00:40<00:07,  2.28it/s]\u001b[A\n","Iteration:  86% 95/110 [00:41<00:06,  2.28it/s]\u001b[A\n","Iteration:  87% 96/110 [00:41<00:06,  2.27it/s]\u001b[A\n","Iteration:  88% 97/110 [00:42<00:05,  2.27it/s]\u001b[A\n","Iteration:  89% 98/110 [00:42<00:05,  2.27it/s]\u001b[A\n","Iteration:  90% 99/110 [00:42<00:04,  2.27it/s]\u001b[A\n","Iteration:  91% 100/110 [00:43<00:04,  2.26it/s]\u001b[A\n","Iteration:  92% 101/110 [00:43<00:03,  2.26it/s]\u001b[A\n","Iteration:  93% 102/110 [00:44<00:03,  2.26it/s]\u001b[A\n","Iteration:  94% 103/110 [00:44<00:03,  2.26it/s]\u001b[A\n","Iteration:  95% 104/110 [00:45<00:02,  2.26it/s]\u001b[A\n","Iteration:  95% 105/110 [00:45<00:02,  2.25it/s]\u001b[A\n","Iteration:  96% 106/110 [00:46<00:01,  2.25it/s]\u001b[A\n","Iteration:  97% 107/110 [00:46<00:01,  2.25it/s]\u001b[A\n","Iteration:  98% 108/110 [00:46<00:00,  2.25it/s]\u001b[A\n","Iteration:  99% 109/110 [00:47<00:00,  2.25it/s]\u001b[A\n","Iteration: 100% 110/110 [00:47<00:00,  2.30it/s]\n","Epoch:  10% 1/10 [00:47<07:10, 47.82s/it]\n","Iteration:   0% 0/110 [00:00<?, ?it/s]\u001b[A\n","Iteration:   1% 1/110 [00:00<00:48,  2.26it/s]\u001b[A\n","Iteration:   2% 2/110 [00:00<00:48,  2.25it/s]\u001b[A\n","Iteration:   3% 3/110 [00:01<00:47,  2.25it/s]\u001b[A\n","Iteration:   4% 4/110 [00:01<00:47,  2.25it/s]\u001b[A\n","Iteration:   5% 5/110 [00:02<00:46,  2.24it/s]\u001b[A\n","Iteration:   5% 6/110 [00:02<00:46,  2.24it/s]\u001b[A\n","Iteration:   6% 7/110 [00:03<00:45,  2.24it/s]\u001b[A\n","Iteration:   7% 8/110 [00:03<00:45,  2.23it/s]\u001b[A\n","Iteration:   8% 9/110 [00:04<00:45,  2.22it/s]\u001b[A\n","Iteration:   9% 10/110 [00:04<00:44,  2.23it/s]\u001b[A\n","Iteration:  10% 11/110 [00:04<00:44,  2.23it/s]\u001b[A\n","Iteration:  11% 12/110 [00:05<00:44,  2.21it/s]\u001b[A\n","Iteration:  12% 13/110 [00:05<00:43,  2.21it/s]\u001b[A\n","Iteration:  13% 14/110 [00:06<00:43,  2.23it/s]\u001b[A\n","Iteration:  14% 15/110 [00:06<00:42,  2.22it/s]\u001b[A\n","Iteration:  15% 16/110 [00:07<00:42,  2.22it/s]\u001b[A\n","Iteration:  15% 17/110 [00:07<00:41,  2.22it/s]\u001b[A\n","Iteration:  16% 18/110 [00:08<00:41,  2.22it/s]\u001b[A\n","Iteration:  17% 19/110 [00:08<00:41,  2.22it/s]\u001b[A\n","Iteration:  18% 20/110 [00:08<00:40,  2.22it/s]\u001b[A\n","Iteration:  19% 21/110 [00:09<00:40,  2.22it/s]\u001b[A\n","Iteration:  20% 22/110 [00:09<00:39,  2.21it/s]\u001b[A\n","Iteration:  21% 23/110 [00:10<00:39,  2.21it/s]\u001b[A\n","Iteration:  22% 24/110 [00:10<00:38,  2.21it/s]\u001b[A\n","Iteration:  23% 25/110 [00:11<00:38,  2.20it/s]\u001b[A\n","Iteration:  24% 26/110 [00:11<00:38,  2.21it/s]\u001b[A\n","Iteration:  25% 27/110 [00:12<00:37,  2.21it/s]\u001b[A\n","Iteration:  25% 28/110 [00:12<00:37,  2.20it/s]\u001b[A\n","Iteration:  26% 29/110 [00:13<00:36,  2.20it/s]\u001b[A\n","Iteration:  27% 30/110 [00:13<00:36,  2.20it/s]\u001b[A\n","Iteration:  28% 31/110 [00:13<00:35,  2.20it/s]\u001b[A\n","Iteration:  29% 32/110 [00:14<00:35,  2.19it/s]\u001b[A\n","Iteration:  30% 33/110 [00:14<00:35,  2.20it/s]\u001b[A\n","Iteration:  31% 34/110 [00:15<00:34,  2.18it/s]\u001b[A\n","Iteration:  32% 35/110 [00:15<00:34,  2.19it/s]\u001b[A\n","Iteration:  33% 36/110 [00:16<00:33,  2.18it/s]\u001b[A\n","Iteration:  34% 37/110 [00:16<00:33,  2.18it/s]\u001b[A\n","Iteration:  35% 38/110 [00:17<00:32,  2.18it/s]\u001b[A\n","Iteration:  35% 39/110 [00:17<00:32,  2.18it/s]\u001b[A\n","Iteration:  36% 40/110 [00:18<00:32,  2.18it/s]\u001b[A\n","Iteration:  37% 41/110 [00:18<00:31,  2.18it/s]\u001b[A\n","Iteration:  38% 42/110 [00:19<00:31,  2.18it/s]\u001b[A\n","Iteration:  39% 43/110 [00:19<00:30,  2.17it/s]\u001b[A\n","Iteration:  40% 44/110 [00:19<00:30,  2.17it/s]\u001b[A\n","Iteration:  41% 45/110 [00:20<00:29,  2.17it/s]\u001b[A\n","Iteration:  42% 46/110 [00:20<00:29,  2.17it/s]\u001b[A\n","Iteration:  43% 47/110 [00:21<00:29,  2.16it/s]\u001b[A\n","Iteration:  44% 48/110 [00:21<00:28,  2.16it/s]\u001b[A\n","Iteration:  45% 49/110 [00:22<00:28,  2.16it/s]\u001b[A\n","Iteration:  45% 50/110 [00:22<00:27,  2.16it/s]\u001b[A\n","Iteration:  46% 51/110 [00:23<00:27,  2.16it/s]\u001b[A\n","Iteration:  47% 52/110 [00:23<00:26,  2.16it/s]\u001b[A\n","Iteration:  48% 53/110 [00:24<00:26,  2.16it/s]\u001b[A\n","Iteration:  49% 54/110 [00:24<00:26,  2.15it/s]\u001b[A\n","Iteration:  50% 55/110 [00:25<00:25,  2.16it/s]\u001b[A\n","Iteration:  51% 56/110 [00:25<00:25,  2.15it/s]\u001b[A\n","Iteration:  52% 57/110 [00:25<00:24,  2.15it/s]\u001b[A\n","Iteration:  53% 58/110 [00:26<00:24,  2.15it/s]\u001b[A\n","Iteration:  54% 59/110 [00:26<00:23,  2.15it/s]\u001b[A\n","Iteration:  55% 60/110 [00:27<00:23,  2.15it/s]\u001b[A\n","Iteration:  55% 61/110 [00:27<00:22,  2.15it/s]\u001b[A\n","Iteration:  56% 62/110 [00:28<00:22,  2.14it/s]\u001b[A\n","Iteration:  57% 63/110 [00:28<00:21,  2.14it/s]\u001b[A\n","Iteration:  58% 64/110 [00:29<00:21,  2.15it/s]\u001b[A\n","Iteration:  59% 65/110 [00:29<00:20,  2.14it/s]\u001b[A\n","Iteration:  60% 66/110 [00:30<00:20,  2.14it/s]\u001b[A\n","Iteration:  61% 67/110 [00:30<00:20,  2.15it/s]\u001b[A\n","Iteration:  62% 68/110 [00:31<00:19,  2.15it/s]\u001b[A\n","Iteration:  63% 69/110 [00:31<00:19,  2.14it/s]\u001b[A\n","Iteration:  64% 70/110 [00:32<00:18,  2.15it/s]\u001b[A\n","Iteration:  65% 71/110 [00:32<00:18,  2.15it/s]\u001b[A\n","Iteration:  65% 72/110 [00:32<00:17,  2.15it/s]\u001b[A\n","Iteration:  66% 73/110 [00:33<00:17,  2.15it/s]\u001b[A\n","Iteration:  67% 74/110 [00:33<00:16,  2.15it/s]\u001b[A\n","Iteration:  68% 75/110 [00:34<00:16,  2.16it/s]\u001b[A\n","Iteration:  69% 76/110 [00:34<00:15,  2.16it/s]\u001b[A\n","Iteration:  70% 77/110 [00:35<00:15,  2.17it/s]\u001b[A\n","Iteration:  71% 78/110 [00:35<00:14,  2.17it/s]\u001b[A\n","Iteration:  72% 79/110 [00:36<00:14,  2.16it/s]\u001b[A\n","Iteration:  73% 80/110 [00:36<00:13,  2.17it/s]\u001b[A\n","Iteration:  74% 81/110 [00:37<00:13,  2.17it/s]\u001b[A\n","Iteration:  75% 82/110 [00:37<00:12,  2.17it/s]\u001b[A\n","Iteration:  75% 83/110 [00:38<00:12,  2.18it/s]\u001b[A\n","Iteration:  76% 84/110 [00:38<00:11,  2.18it/s]\u001b[A\n","Iteration:  77% 85/110 [00:38<00:11,  2.18it/s]\u001b[A\n","Iteration:  78% 86/110 [00:39<00:11,  2.18it/s]\u001b[A\n","Iteration:  79% 87/110 [00:39<00:10,  2.18it/s]\u001b[A\n","Iteration:  80% 88/110 [00:40<00:10,  2.19it/s]\u001b[A\n","Iteration:  81% 89/110 [00:40<00:09,  2.19it/s]\u001b[A\n","Iteration:  82% 90/110 [00:41<00:09,  2.19it/s]\u001b[A\n","Iteration:  83% 91/110 [00:41<00:08,  2.19it/s]\u001b[A\n","Iteration:  84% 92/110 [00:42<00:08,  2.19it/s]\u001b[A\n","Iteration:  85% 93/110 [00:42<00:07,  2.19it/s]\u001b[A\n","Iteration:  85% 94/110 [00:43<00:07,  2.19it/s]\u001b[A\n","Iteration:  86% 95/110 [00:43<00:06,  2.19it/s]\u001b[A\n","Iteration:  87% 96/110 [00:43<00:06,  2.20it/s]\u001b[A\n","Iteration:  88% 97/110 [00:44<00:05,  2.20it/s]\u001b[A\n","Iteration:  89% 98/110 [00:44<00:05,  2.20it/s]\u001b[A\n","Iteration:  90% 99/110 [00:45<00:04,  2.21it/s]\u001b[A\n","Iteration:  91% 100/110 [00:45<00:04,  2.20it/s]\u001b[A\n","Iteration:  92% 101/110 [00:46<00:04,  2.21it/s]\u001b[A\n","Iteration:  93% 102/110 [00:46<00:03,  2.21it/s]\u001b[A\n","Iteration:  94% 103/110 [00:47<00:03,  2.21it/s]\u001b[A\n","Iteration:  95% 104/110 [00:47<00:02,  2.21it/s]\u001b[A\n","Iteration:  95% 105/110 [00:48<00:02,  2.21it/s]\u001b[A\n","Iteration:  96% 106/110 [00:48<00:01,  2.21it/s]\u001b[A\n","Iteration:  97% 107/110 [00:48<00:01,  2.21it/s]\u001b[A\n","Iteration:  98% 108/110 [00:49<00:00,  2.22it/s]\u001b[A\n","Iteration:  99% 109/110 [00:49<00:00,  2.22it/s]\u001b[A\n","Iteration: 100% 110/110 [00:50<00:00,  2.19it/s]\n","Epoch:  20% 2/10 [01:38<06:28, 48.57s/it]\n","Iteration:   0% 0/110 [00:00<?, ?it/s]\u001b[A\n","Iteration:   1% 1/110 [00:00<00:49,  2.22it/s]\u001b[A\n","Iteration:   2% 2/110 [00:00<00:48,  2.22it/s]\u001b[A\n","Iteration:   3% 3/110 [00:01<00:48,  2.23it/s]\u001b[A\n","Iteration:   4% 4/110 [00:01<00:47,  2.22it/s]\u001b[A\n","Iteration:   5% 5/110 [00:02<00:47,  2.22it/s]\u001b[A\n","Iteration:   5% 6/110 [00:02<00:46,  2.22it/s]\u001b[A\n","Iteration:   6% 7/110 [00:03<00:46,  2.22it/s]\u001b[A\n","Iteration:   7% 8/110 [00:03<00:45,  2.22it/s]\u001b[A\n","Iteration:   8% 9/110 [00:04<00:45,  2.22it/s]\u001b[A\n","Iteration:   9% 10/110 [00:04<00:45,  2.22it/s]\u001b[A\n","Iteration:  10% 11/110 [00:04<00:44,  2.22it/s]\u001b[A\n","Iteration:  11% 12/110 [00:05<00:44,  2.22it/s]\u001b[A\n","Iteration:  12% 13/110 [00:05<00:43,  2.23it/s]\u001b[A\n","Iteration:  13% 14/110 [00:06<00:43,  2.23it/s]\u001b[A\n","Iteration:  14% 15/110 [00:06<00:42,  2.23it/s]\u001b[A\n","Iteration:  15% 16/110 [00:07<00:42,  2.23it/s]\u001b[A\n","Iteration:  15% 17/110 [00:07<00:41,  2.23it/s]\u001b[A\n","Iteration:  16% 18/110 [00:08<00:41,  2.23it/s]\u001b[A\n","Iteration:  17% 19/110 [00:08<00:41,  2.21it/s]\u001b[A\n","Iteration:  18% 20/110 [00:08<00:40,  2.22it/s]\u001b[A\n","Iteration:  19% 21/110 [00:09<00:39,  2.23it/s]\u001b[A\n","Iteration:  20% 22/110 [00:09<00:39,  2.23it/s]\u001b[A\n","Iteration:  21% 23/110 [00:10<00:39,  2.23it/s]\u001b[A\n","Iteration:  22% 24/110 [00:10<00:38,  2.22it/s]\u001b[A\n","Iteration:  23% 25/110 [00:11<00:38,  2.22it/s]\u001b[A\n","Iteration:  24% 26/110 [00:11<00:37,  2.22it/s]\u001b[A\n","Iteration:  25% 27/110 [00:12<00:37,  2.23it/s]\u001b[A\n","Iteration:  25% 28/110 [00:12<00:36,  2.23it/s]\u001b[A\n","Iteration:  26% 29/110 [00:13<00:36,  2.22it/s]\u001b[A\n","Iteration:  27% 30/110 [00:13<00:35,  2.22it/s]\u001b[A\n","Iteration:  28% 31/110 [00:13<00:35,  2.23it/s]\u001b[A\n","Iteration:  29% 32/110 [00:14<00:34,  2.23it/s]\u001b[A\n","Iteration:  30% 33/110 [00:14<00:34,  2.23it/s]\u001b[A\n","Iteration:  31% 34/110 [00:15<00:34,  2.23it/s]\u001b[A\n","Iteration:  32% 35/110 [00:15<00:33,  2.22it/s]\u001b[A\n","Iteration:  33% 36/110 [00:16<00:33,  2.23it/s]\u001b[A\n","Iteration:  34% 37/110 [00:16<00:32,  2.23it/s]\u001b[A\n","Iteration:  35% 38/110 [00:17<00:32,  2.23it/s]\u001b[A\n","Iteration:  35% 39/110 [00:17<00:31,  2.23it/s]\u001b[A\n","Iteration:  36% 40/110 [00:17<00:31,  2.23it/s]\u001b[A\n","Iteration:  37% 41/110 [00:18<00:30,  2.23it/s]\u001b[A\n","Iteration:  38% 42/110 [00:18<00:30,  2.23it/s]\u001b[A\n","Iteration:  39% 43/110 [00:19<00:30,  2.23it/s]\u001b[A\n","Iteration:  40% 44/110 [00:19<00:29,  2.23it/s]\u001b[A\n","Iteration:  41% 45/110 [00:20<00:29,  2.23it/s]\u001b[A\n","Iteration:  42% 46/110 [00:20<00:28,  2.23it/s]\u001b[A\n","Iteration:  43% 47/110 [00:21<00:28,  2.23it/s]\u001b[A\n","Iteration:  44% 48/110 [00:21<00:27,  2.23it/s]\u001b[A\n","Iteration:  45% 49/110 [00:22<00:27,  2.23it/s]\u001b[A\n","Iteration:  45% 50/110 [00:22<00:26,  2.23it/s]\u001b[A\n","Iteration:  46% 51/110 [00:22<00:26,  2.23it/s]\u001b[A\n","Iteration:  47% 52/110 [00:23<00:26,  2.23it/s]\u001b[A\n","Iteration:  48% 53/110 [00:23<00:25,  2.23it/s]\u001b[A\n","Iteration:  49% 54/110 [00:24<00:25,  2.23it/s]\u001b[A\n","Iteration:  50% 55/110 [00:24<00:24,  2.23it/s]\u001b[A\n","Iteration:  51% 56/110 [00:25<00:24,  2.23it/s]\u001b[A\n","Iteration:  52% 57/110 [00:25<00:23,  2.23it/s]\u001b[A\n","Iteration:  53% 58/110 [00:26<00:23,  2.23it/s]\u001b[A\n","Iteration:  54% 59/110 [00:26<00:22,  2.22it/s]\u001b[A\n","Iteration:  55% 60/110 [00:26<00:22,  2.23it/s]\u001b[A\n","Iteration:  55% 61/110 [00:27<00:22,  2.22it/s]\u001b[A\n","Iteration:  56% 62/110 [00:27<00:21,  2.23it/s]\u001b[A\n","Iteration:  57% 63/110 [00:28<00:21,  2.22it/s]\u001b[A\n","Iteration:  58% 64/110 [00:28<00:20,  2.23it/s]\u001b[A\n","Iteration:  59% 65/110 [00:29<00:20,  2.23it/s]\u001b[A\n","Iteration:  60% 66/110 [00:29<00:19,  2.22it/s]\u001b[A\n","Iteration:  61% 67/110 [00:30<00:19,  2.22it/s]\u001b[A\n","Iteration:  62% 68/110 [00:30<00:18,  2.23it/s]\u001b[A\n","Iteration:  63% 69/110 [00:30<00:18,  2.23it/s]\u001b[A\n","Iteration:  64% 70/110 [00:31<00:17,  2.23it/s]\u001b[A\n","Iteration:  65% 71/110 [00:31<00:17,  2.23it/s]\u001b[A\n","Iteration:  65% 72/110 [00:32<00:17,  2.22it/s]\u001b[A\n","Iteration:  66% 73/110 [00:32<00:16,  2.22it/s]\u001b[A\n","Iteration:  67% 74/110 [00:33<00:16,  2.22it/s]\u001b[A\n","Iteration:  68% 75/110 [00:33<00:15,  2.22it/s]\u001b[A\n","Iteration:  69% 76/110 [00:34<00:15,  2.22it/s]\u001b[A\n","Iteration:  70% 77/110 [00:34<00:14,  2.22it/s]\u001b[A\n","Iteration:  71% 78/110 [00:35<00:14,  2.21it/s]\u001b[A\n","Iteration:  72% 79/110 [00:35<00:13,  2.22it/s]\u001b[A\n","Iteration:  73% 80/110 [00:35<00:13,  2.22it/s]\u001b[A\n","Iteration:  74% 81/110 [00:36<00:13,  2.22it/s]\u001b[A\n","Iteration:  75% 82/110 [00:36<00:12,  2.21it/s]\u001b[A\n","Iteration:  75% 83/110 [00:37<00:12,  2.21it/s]\u001b[A\n","Iteration:  76% 84/110 [00:37<00:11,  2.21it/s]\u001b[A\n","Iteration:  77% 85/110 [00:38<00:11,  2.21it/s]\u001b[A\n","Iteration:  78% 86/110 [00:38<00:10,  2.21it/s]\u001b[A\n","Iteration:  79% 87/110 [00:39<00:10,  2.21it/s]\u001b[A\n","Iteration:  80% 88/110 [00:39<00:09,  2.21it/s]\u001b[A\n","Iteration:  81% 89/110 [00:40<00:09,  2.21it/s]\u001b[A\n","Iteration:  82% 90/110 [00:40<00:09,  2.21it/s]\u001b[A\n","Iteration:  83% 91/110 [00:40<00:08,  2.21it/s]\u001b[A\n","Iteration:  84% 92/110 [00:41<00:08,  2.21it/s]\u001b[A\n","Iteration:  85% 93/110 [00:41<00:07,  2.21it/s]\u001b[A\n","Iteration:  85% 94/110 [00:42<00:07,  2.21it/s]\u001b[A\n","Iteration:  86% 95/110 [00:42<00:06,  2.21it/s]\u001b[A\n","Iteration:  87% 96/110 [00:43<00:06,  2.21it/s]\u001b[A\n","Iteration:  88% 97/110 [00:43<00:05,  2.21it/s]\u001b[A\n","Iteration:  89% 98/110 [00:44<00:05,  2.21it/s]\u001b[A\n","Iteration:  90% 99/110 [00:44<00:04,  2.21it/s]\u001b[A\n","Iteration:  91% 100/110 [00:44<00:04,  2.21it/s]\u001b[A\n","Iteration:  92% 101/110 [00:45<00:04,  2.20it/s]\u001b[A\n","Iteration:  93% 102/110 [00:45<00:03,  2.20it/s]\u001b[A\n","Iteration:  94% 103/110 [00:46<00:03,  2.20it/s]\u001b[A\n","Iteration:  95% 104/110 [00:46<00:02,  2.20it/s]\u001b[A\n","Iteration:  95% 105/110 [00:47<00:02,  2.20it/s]\u001b[A\n","Iteration:  96% 106/110 [00:47<00:01,  2.20it/s]\u001b[A\n","Iteration:  97% 107/110 [00:48<00:01,  2.19it/s]\u001b[A\n","Iteration:  98% 108/110 [00:48<00:00,  2.20it/s]\u001b[A\n","Iteration:  99% 109/110 [00:49<00:00,  2.20it/s]\u001b[A\n","Iteration: 100% 110/110 [00:49<00:00,  2.22it/s]\n","Epoch:  30% 3/10 [02:27<05:42, 48.86s/it]\n","Iteration:   0% 0/110 [00:00<?, ?it/s]\u001b[A\n","Iteration:   1% 1/110 [00:00<00:49,  2.22it/s]\u001b[A\n","Iteration:   2% 2/110 [00:00<00:48,  2.21it/s]\u001b[A\n","Iteration:   3% 3/110 [00:01<00:48,  2.20it/s]\u001b[A\n","Iteration:   4% 4/110 [00:01<00:48,  2.20it/s]\u001b[A\n","Iteration:   5% 5/110 [00:02<00:47,  2.19it/s]\u001b[A\n","Iteration:   5% 6/110 [00:02<00:47,  2.19it/s]\u001b[A\n","Iteration:   6% 7/110 [00:03<00:46,  2.20it/s]\u001b[A\n","Iteration:   7% 8/110 [00:03<00:46,  2.20it/s]\u001b[A\n","Iteration:   8% 9/110 [00:04<00:45,  2.20it/s]\u001b[A\n","Iteration:   9% 10/110 [00:04<00:45,  2.20it/s]\u001b[A\n","Iteration:  10% 11/110 [00:05<00:45,  2.20it/s]\u001b[A\n","Iteration:  11% 12/110 [00:05<00:44,  2.20it/s]\u001b[A\n","Iteration:  12% 13/110 [00:05<00:44,  2.19it/s]\u001b[A\n","Iteration:  13% 14/110 [00:06<00:43,  2.19it/s]\u001b[A\n","Iteration:  14% 15/110 [00:06<00:43,  2.20it/s]\u001b[A\n","Iteration:  15% 16/110 [00:07<00:42,  2.19it/s]\u001b[A\n","Iteration:  15% 17/110 [00:07<00:42,  2.20it/s]\u001b[A\n","Iteration:  16% 18/110 [00:08<00:41,  2.20it/s]\u001b[A\n","Iteration:  17% 19/110 [00:08<00:41,  2.19it/s]\u001b[A\n","Iteration:  18% 20/110 [00:09<00:41,  2.19it/s]\u001b[A\n","Iteration:  19% 21/110 [00:09<00:40,  2.19it/s]\u001b[A\n","Iteration:  20% 22/110 [00:10<00:40,  2.19it/s]\u001b[A\n","Iteration:  21% 23/110 [00:10<00:39,  2.19it/s]\u001b[A\n","Iteration:  22% 24/110 [00:10<00:39,  2.19it/s]\u001b[A\n","Iteration:  23% 25/110 [00:11<00:38,  2.19it/s]\u001b[A\n","Iteration:  24% 26/110 [00:11<00:38,  2.19it/s]\u001b[A\n","Iteration:  25% 27/110 [00:12<00:37,  2.19it/s]\u001b[A\n","Iteration:  25% 28/110 [00:12<00:37,  2.19it/s]\u001b[A\n","Iteration:  26% 29/110 [00:13<00:36,  2.20it/s]\u001b[A\n","Iteration:  27% 30/110 [00:13<00:36,  2.20it/s]\u001b[A\n","Iteration:  28% 31/110 [00:14<00:35,  2.20it/s]\u001b[A\n","Iteration:  29% 32/110 [00:14<00:35,  2.20it/s]\u001b[A\n","Iteration:  30% 33/110 [00:15<00:34,  2.20it/s]\u001b[A\n","Iteration:  31% 34/110 [00:15<00:34,  2.20it/s]\u001b[A\n","Iteration:  32% 35/110 [00:15<00:34,  2.20it/s]\u001b[A\n","Iteration:  33% 36/110 [00:16<00:33,  2.20it/s]\u001b[A\n","Iteration:  34% 37/110 [00:16<00:33,  2.20it/s]\u001b[A\n","Iteration:  35% 38/110 [00:17<00:32,  2.20it/s]\u001b[A\n","Iteration:  35% 39/110 [00:17<00:32,  2.20it/s]\u001b[A\n","Iteration:  36% 40/110 [00:18<00:31,  2.20it/s]\u001b[A\n","Iteration:  37% 41/110 [00:18<00:31,  2.20it/s]\u001b[A\n","Iteration:  38% 42/110 [00:19<00:30,  2.20it/s]\u001b[A\n","Iteration:  39% 43/110 [00:19<00:30,  2.20it/s]\u001b[A\n","Iteration:  40% 44/110 [00:20<00:29,  2.20it/s]\u001b[A\n","Iteration:  41% 45/110 [00:20<00:29,  2.20it/s]\u001b[A\n","Iteration:  42% 46/110 [00:20<00:29,  2.20it/s]\u001b[A\n","Iteration:  43% 47/110 [00:21<00:28,  2.20it/s]\u001b[A\n","Iteration:  44% 48/110 [00:21<00:28,  2.20it/s]\u001b[A\n","Iteration:  45% 49/110 [00:22<00:27,  2.21it/s]\u001b[A\n","Iteration:  45% 50/110 [00:22<00:27,  2.21it/s]\u001b[A\n","Iteration:  46% 51/110 [00:23<00:26,  2.20it/s]\u001b[A\n","Iteration:  47% 52/110 [00:23<00:26,  2.21it/s]\u001b[A\n","Iteration:  48% 53/110 [00:24<00:25,  2.21it/s]\u001b[A\n","Iteration:  49% 54/110 [00:24<00:25,  2.21it/s]\u001b[A\n","Iteration:  50% 55/110 [00:25<00:24,  2.21it/s]\u001b[A\n","Iteration:  51% 56/110 [00:25<00:24,  2.21it/s]\u001b[A\n","Iteration:  52% 57/110 [00:25<00:23,  2.21it/s]\u001b[A\n","Iteration:  53% 58/110 [00:26<00:23,  2.21it/s]\u001b[A\n","Iteration:  54% 59/110 [00:26<00:23,  2.21it/s]\u001b[A\n","Iteration:  55% 60/110 [00:27<00:22,  2.21it/s]\u001b[A\n","Iteration:  55% 61/110 [00:27<00:22,  2.21it/s]\u001b[A\n","Iteration:  56% 62/110 [00:28<00:21,  2.21it/s]\u001b[A\n","Iteration:  57% 63/110 [00:28<00:21,  2.22it/s]\u001b[A\n","Iteration:  58% 64/110 [00:29<00:20,  2.21it/s]\u001b[A\n","Iteration:  59% 65/110 [00:29<00:20,  2.21it/s]\u001b[A\n","Iteration:  60% 66/110 [00:29<00:19,  2.21it/s]\u001b[A\n","Iteration:  61% 67/110 [00:30<00:19,  2.21it/s]\u001b[A\n","Iteration:  62% 68/110 [00:30<00:19,  2.21it/s]\u001b[A\n","Iteration:  63% 69/110 [00:31<00:18,  2.21it/s]\u001b[A\n","Iteration:  64% 70/110 [00:31<00:18,  2.21it/s]\u001b[A\n","Iteration:  65% 71/110 [00:32<00:17,  2.21it/s]\u001b[A\n","Iteration:  65% 72/110 [00:32<00:17,  2.21it/s]\u001b[A\n","Iteration:  66% 73/110 [00:33<00:16,  2.21it/s]\u001b[A\n","Iteration:  67% 74/110 [00:33<00:16,  2.21it/s]\u001b[A\n","Iteration:  68% 75/110 [00:34<00:15,  2.21it/s]\u001b[A\n","Iteration:  69% 76/110 [00:34<00:15,  2.22it/s]\u001b[A\n","Iteration:  70% 77/110 [00:34<00:14,  2.22it/s]\u001b[A\n","Iteration:  71% 78/110 [00:35<00:14,  2.22it/s]\u001b[A\n","Iteration:  72% 79/110 [00:35<00:13,  2.22it/s]\u001b[A\n","Iteration:  73% 80/110 [00:36<00:13,  2.22it/s]\u001b[A\n","Iteration:  74% 81/110 [00:36<00:13,  2.22it/s]\u001b[A\n","Iteration:  75% 82/110 [00:37<00:12,  2.22it/s]\u001b[A\n","Iteration:  75% 83/110 [00:37<00:12,  2.21it/s]\u001b[A\n","Iteration:  76% 84/110 [00:38<00:11,  2.22it/s]\u001b[A\n","Iteration:  77% 85/110 [00:38<00:11,  2.21it/s]\u001b[A\n","Iteration:  78% 86/110 [00:39<00:10,  2.21it/s]\u001b[A\n","Iteration:  79% 87/110 [00:39<00:10,  2.22it/s]\u001b[A\n","Iteration:  80% 88/110 [00:39<00:09,  2.21it/s]\u001b[A\n","Iteration:  81% 89/110 [00:40<00:09,  2.21it/s]\u001b[A\n","Iteration:  82% 90/110 [00:40<00:09,  2.22it/s]\u001b[A\n","Iteration:  83% 91/110 [00:41<00:08,  2.22it/s]\u001b[A\n","Iteration:  84% 92/110 [00:41<00:08,  2.21it/s]\u001b[A\n","Iteration:  85% 93/110 [00:42<00:07,  2.22it/s]\u001b[A\n","Iteration:  85% 94/110 [00:42<00:07,  2.21it/s]\u001b[A\n","Iteration:  86% 95/110 [00:43<00:06,  2.22it/s]\u001b[A\n","Iteration:  87% 96/110 [00:43<00:06,  2.21it/s]\u001b[A\n","Iteration:  88% 97/110 [00:44<00:05,  2.21it/s]\u001b[A\n","Iteration:  89% 98/110 [00:44<00:05,  2.22it/s]\u001b[A\n","Iteration:  90% 99/110 [00:44<00:04,  2.22it/s]\u001b[A\n","Iteration:  91% 100/110 [00:45<00:04,  2.22it/s]\u001b[A\n","Iteration:  92% 101/110 [00:45<00:04,  2.22it/s]\u001b[A\n","Iteration:  93% 102/110 [00:46<00:03,  2.22it/s]\u001b[A\n","Iteration:  94% 103/110 [00:46<00:03,  2.22it/s]\u001b[A\n","Iteration:  95% 104/110 [00:47<00:02,  2.22it/s]\u001b[A\n","Iteration:  95% 105/110 [00:47<00:02,  2.22it/s]\u001b[A\n","Iteration:  96% 106/110 [00:48<00:01,  2.21it/s]\u001b[A\n","Iteration:  97% 107/110 [00:48<00:01,  2.21it/s]\u001b[A\n","Iteration:  98% 108/110 [00:48<00:00,  2.21it/s]\u001b[A\n","Iteration:  99% 109/110 [00:49<00:00,  2.21it/s]\u001b[A\n","Iteration: 100% 110/110 [00:49<00:00,  2.21it/s]\n","Epoch:  40% 4/10 [03:17<04:54, 49.17s/it]\n","Iteration:   0% 0/110 [00:00<?, ?it/s]\u001b[A\n","Iteration:   1% 1/110 [00:00<00:49,  2.21it/s]\u001b[A\n","Iteration:   2% 2/110 [00:00<00:48,  2.21it/s]\u001b[A\n","Iteration:   3% 3/110 [00:01<00:48,  2.21it/s]\u001b[A\n","Iteration:   4% 4/110 [00:01<00:47,  2.21it/s]\u001b[A\n","Iteration:   5% 5/110 [00:02<00:47,  2.22it/s]\u001b[A\n","Iteration:   5% 6/110 [00:02<00:46,  2.22it/s]\u001b[A\n","Iteration:   6% 7/110 [00:03<00:46,  2.21it/s]\u001b[A\n","Iteration:   7% 8/110 [00:03<00:46,  2.22it/s]\u001b[A\n","Iteration:   8% 9/110 [00:04<00:45,  2.22it/s]\u001b[A\n","Iteration:   9% 10/110 [00:04<00:45,  2.22it/s]\u001b[A\n","Iteration:  10% 11/110 [00:04<00:44,  2.22it/s]\u001b[A\n","Iteration:  11% 12/110 [00:05<00:44,  2.22it/s]\u001b[A\n","Iteration:  12% 13/110 [00:05<00:43,  2.22it/s]\u001b[A\n","Iteration:  13% 14/110 [00:06<00:43,  2.22it/s]\u001b[A\n","Iteration:  14% 15/110 [00:06<00:42,  2.22it/s]\u001b[A\n","Iteration:  15% 16/110 [00:07<00:42,  2.22it/s]\u001b[A\n","Iteration:  15% 17/110 [00:07<00:41,  2.22it/s]\u001b[A\n","Iteration:  16% 18/110 [00:08<00:41,  2.21it/s]\u001b[A\n","Iteration:  17% 19/110 [00:08<00:41,  2.21it/s]\u001b[A\n","Iteration:  18% 20/110 [00:09<00:40,  2.21it/s]\u001b[A\n","Iteration:  19% 21/110 [00:09<00:40,  2.21it/s]\u001b[A\n","Iteration:  20% 22/110 [00:09<00:39,  2.21it/s]\u001b[A\n","Iteration:  21% 23/110 [00:10<00:39,  2.21it/s]\u001b[A\n","Iteration:  22% 24/110 [00:10<00:38,  2.21it/s]\u001b[A\n","Iteration:  23% 25/110 [00:11<00:38,  2.21it/s]\u001b[A\n","Iteration:  24% 26/110 [00:11<00:38,  2.21it/s]\u001b[A\n","Iteration:  25% 27/110 [00:12<00:37,  2.21it/s]\u001b[A\n","Iteration:  25% 28/110 [00:12<00:37,  2.21it/s]\u001b[A\n","Iteration:  26% 29/110 [00:13<00:36,  2.21it/s]\u001b[A\n","Iteration:  27% 30/110 [00:13<00:36,  2.21it/s]\u001b[A\n","Iteration:  28% 31/110 [00:14<00:35,  2.21it/s]\u001b[A\n","Iteration:  29% 32/110 [00:14<00:35,  2.21it/s]\u001b[A\n","Iteration:  30% 33/110 [00:14<00:34,  2.22it/s]\u001b[A\n","Iteration:  31% 34/110 [00:15<00:34,  2.21it/s]\u001b[A\n","Iteration:  32% 35/110 [00:15<00:33,  2.21it/s]\u001b[A\n","Iteration:  33% 36/110 [00:16<00:33,  2.21it/s]\u001b[A\n","Iteration:  34% 37/110 [00:16<00:33,  2.20it/s]\u001b[A\n","Iteration:  35% 38/110 [00:17<00:32,  2.21it/s]\u001b[A\n","Iteration:  35% 39/110 [00:17<00:32,  2.21it/s]\u001b[A\n","Iteration:  36% 40/110 [00:18<00:31,  2.21it/s]\u001b[A\n","Iteration:  37% 41/110 [00:18<00:31,  2.21it/s]\u001b[A\n","Iteration:  38% 42/110 [00:18<00:30,  2.21it/s]\u001b[A\n","Iteration:  39% 43/110 [00:19<00:30,  2.20it/s]\u001b[A\n","Iteration:  40% 44/110 [00:19<00:29,  2.21it/s]\u001b[A\n","Iteration:  41% 45/110 [00:20<00:29,  2.21it/s]\u001b[A\n","Iteration:  42% 46/110 [00:20<00:28,  2.21it/s]\u001b[A\n","Iteration:  43% 47/110 [00:21<00:28,  2.21it/s]\u001b[A\n","Iteration:  44% 48/110 [00:21<00:28,  2.21it/s]\u001b[A\n","Iteration:  45% 49/110 [00:22<00:27,  2.21it/s]\u001b[A\n","Iteration:  45% 50/110 [00:22<00:27,  2.21it/s]\u001b[A\n","Iteration:  46% 51/110 [00:23<00:26,  2.20it/s]\u001b[A\n","Iteration:  47% 52/110 [00:23<00:26,  2.21it/s]\u001b[A\n","Iteration:  48% 53/110 [00:23<00:25,  2.21it/s]\u001b[A\n","Iteration:  49% 54/110 [00:24<00:25,  2.20it/s]\u001b[A\n","Iteration:  50% 55/110 [00:24<00:24,  2.21it/s]\u001b[A\n","Iteration:  51% 56/110 [00:25<00:24,  2.21it/s]\u001b[A\n","Iteration:  52% 57/110 [00:25<00:24,  2.21it/s]\u001b[A\n","Iteration:  53% 58/110 [00:26<00:23,  2.21it/s]\u001b[A\n","Iteration:  54% 59/110 [00:26<00:23,  2.21it/s]\u001b[A/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:231: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","\n","Iteration:  55% 60/110 [00:27<00:22,  2.21it/s]\u001b[A\n","Iteration:  55% 61/110 [00:27<00:22,  2.21it/s]\u001b[A\n","Iteration:  56% 62/110 [00:28<00:21,  2.21it/s]\u001b[A\n","Iteration:  57% 63/110 [00:28<00:21,  2.21it/s]\u001b[A\n","Iteration:  58% 64/110 [00:28<00:20,  2.21it/s]\u001b[A\n","Iteration:  59% 65/110 [00:29<00:20,  2.21it/s]\u001b[A\n","Iteration:  60% 66/110 [00:29<00:19,  2.21it/s]\u001b[A\n","Iteration:  61% 67/110 [00:30<00:19,  2.21it/s]\u001b[A\n","Iteration:  62% 68/110 [00:30<00:19,  2.21it/s]\u001b[A\n","Iteration:  63% 69/110 [00:31<00:18,  2.21it/s]\u001b[A\n","Iteration:  64% 70/110 [00:31<00:18,  2.21it/s]\u001b[A\n","Iteration:  65% 71/110 [00:32<00:17,  2.21it/s]\u001b[A\n","Iteration:  65% 72/110 [00:32<00:17,  2.21it/s]\u001b[A\n","Iteration:  66% 73/110 [00:33<00:16,  2.20it/s]\u001b[A\n","Iteration:  67% 74/110 [00:33<00:16,  2.20it/s]\u001b[A\n","Iteration:  68% 75/110 [00:33<00:15,  2.19it/s]\u001b[A\n","Iteration:  69% 76/110 [00:34<00:15,  2.20it/s]\u001b[A\n","Iteration:  70% 77/110 [00:34<00:14,  2.20it/s]\u001b[A\n","Iteration:  71% 78/110 [00:35<00:14,  2.21it/s]\u001b[A\n","Iteration:  72% 79/110 [00:35<00:14,  2.21it/s]\u001b[A\n","Iteration:  73% 80/110 [00:36<00:13,  2.20it/s]\u001b[A\n","Iteration:  74% 81/110 [00:36<00:13,  2.20it/s]\u001b[A\n","Iteration:  75% 82/110 [00:37<00:12,  2.20it/s]\u001b[A\n","Iteration:  75% 83/110 [00:37<00:12,  2.20it/s]\u001b[A\n","Iteration:  76% 84/110 [00:38<00:11,  2.20it/s]\u001b[A\n","Iteration:  77% 85/110 [00:38<00:11,  2.20it/s]\u001b[A\n","Iteration:  78% 86/110 [00:38<00:10,  2.20it/s]\u001b[A\n","Iteration:  79% 87/110 [00:39<00:10,  2.20it/s]\u001b[A\n","Iteration:  80% 88/110 [00:39<00:09,  2.21it/s]\u001b[A\n","Iteration:  81% 89/110 [00:40<00:09,  2.20it/s]\u001b[A\n","Iteration:  82% 90/110 [00:40<00:09,  2.20it/s]\u001b[A\n","Iteration:  83% 91/110 [00:41<00:08,  2.20it/s]\u001b[A\n","Iteration:  84% 92/110 [00:41<00:08,  2.20it/s]\u001b[A\n","Iteration:  85% 93/110 [00:42<00:07,  2.21it/s]\u001b[A\n","Iteration:  85% 94/110 [00:42<00:07,  2.20it/s]\u001b[A\n","Iteration:  86% 95/110 [00:43<00:06,  2.21it/s]\u001b[A\n","Iteration:  87% 96/110 [00:43<00:06,  2.20it/s]\u001b[A\n","Iteration:  88% 97/110 [00:43<00:05,  2.20it/s]\u001b[A\n","Iteration:  89% 98/110 [00:44<00:05,  2.21it/s]\u001b[A\n","Iteration:  90% 99/110 [00:44<00:04,  2.21it/s]\u001b[A\n","Iteration:  91% 100/110 [00:45<00:04,  2.21it/s]\u001b[A\n","Iteration:  92% 101/110 [00:45<00:04,  2.21it/s]\u001b[A\n","Iteration:  93% 102/110 [00:46<00:03,  2.21it/s]\u001b[A\n","Iteration:  94% 103/110 [00:46<00:03,  2.21it/s]\u001b[A\n","Iteration:  95% 104/110 [00:47<00:02,  2.21it/s]\u001b[A\n","Iteration:  95% 105/110 [00:47<00:02,  2.20it/s]\u001b[A\n","Iteration:  96% 106/110 [00:47<00:01,  2.20it/s]\u001b[A\n","Iteration:  97% 107/110 [00:48<00:01,  2.21it/s]\u001b[A\n","Iteration:  98% 108/110 [00:48<00:00,  2.20it/s]\u001b[A\n","Iteration:  99% 109/110 [00:49<00:00,  2.20it/s]\u001b[A\n","Iteration: 100% 110/110 [00:49<00:00,  2.21it/s]\n","Epoch:  50% 5/10 [04:07<04:06, 49.36s/it]\n","Iteration:   0% 0/110 [00:00<?, ?it/s]\u001b[A\n","Iteration:   1% 1/110 [00:00<00:49,  2.22it/s]\u001b[A\n","Iteration:   2% 2/110 [00:00<00:48,  2.21it/s]\u001b[A\n","Iteration:   3% 3/110 [00:01<00:48,  2.21it/s]\u001b[A\n","Iteration:   4% 4/110 [00:01<00:48,  2.20it/s]\u001b[A\n","Iteration:   5% 5/110 [00:02<00:47,  2.20it/s]\u001b[A\n","Iteration:   5% 6/110 [00:02<00:47,  2.20it/s]\u001b[A\n","Iteration:   6% 7/110 [00:03<00:46,  2.20it/s]\u001b[A\n","Iteration:   7% 8/110 [00:03<00:46,  2.21it/s]\u001b[A\n","Iteration:   8% 9/110 [00:04<00:45,  2.21it/s]\u001b[A\n","Iteration:   9% 10/110 [00:04<00:45,  2.20it/s]\u001b[A\n","Iteration:  10% 11/110 [00:04<00:44,  2.20it/s]\u001b[A\n","Iteration:  11% 12/110 [00:05<00:44,  2.20it/s]\u001b[A\n","Iteration:  12% 13/110 [00:05<00:44,  2.20it/s]\u001b[A\n","Iteration:  13% 14/110 [00:06<00:43,  2.20it/s]\u001b[A\n","Iteration:  14% 15/110 [00:06<00:43,  2.20it/s]\u001b[A\n","Iteration:  15% 16/110 [00:07<00:42,  2.20it/s]\u001b[A\n","Iteration:  15% 17/110 [00:07<00:42,  2.20it/s]\u001b[A\n","Iteration:  16% 18/110 [00:08<00:41,  2.21it/s]\u001b[A\n","Iteration:  17% 19/110 [00:08<00:41,  2.20it/s]\u001b[A\n","Iteration:  18% 20/110 [00:09<00:40,  2.20it/s]\u001b[A\n","Iteration:  19% 21/110 [00:09<00:40,  2.21it/s]\u001b[A\n","Iteration:  20% 22/110 [00:09<00:39,  2.20it/s]\u001b[A\n","Iteration:  21% 23/110 [00:10<00:39,  2.20it/s]\u001b[A\n","Iteration:  22% 24/110 [00:10<00:38,  2.21it/s]\u001b[A\n","Iteration:  23% 25/110 [00:11<00:38,  2.21it/s]\u001b[A\n","Iteration:  24% 26/110 [00:11<00:38,  2.21it/s]\u001b[A\n","Iteration:  25% 27/110 [00:12<00:37,  2.21it/s]\u001b[A\n","Iteration:  25% 28/110 [00:12<00:37,  2.20it/s]\u001b[A\n","Iteration:  26% 29/110 [00:13<00:36,  2.20it/s]\u001b[A\n","Iteration:  27% 30/110 [00:13<00:36,  2.20it/s]\u001b[A\n","Iteration:  28% 31/110 [00:14<00:35,  2.20it/s]\u001b[A\n","Iteration:  29% 32/110 [00:14<00:35,  2.20it/s]\u001b[A\n","Iteration:  30% 33/110 [00:14<00:34,  2.20it/s]\u001b[A\n","Iteration:  31% 34/110 [00:15<00:34,  2.20it/s]\u001b[A\n","Iteration:  32% 35/110 [00:15<00:34,  2.20it/s]\u001b[A\n","Iteration:  33% 36/110 [00:16<00:33,  2.20it/s]\u001b[A\n","Iteration:  34% 37/110 [00:16<00:33,  2.20it/s]\u001b[A\n","Iteration:  35% 38/110 [00:17<00:32,  2.20it/s]\u001b[A\n","Iteration:  35% 39/110 [00:17<00:32,  2.20it/s]\u001b[A\n","Iteration:  36% 40/110 [00:18<00:31,  2.20it/s]\u001b[A\n","Iteration:  37% 41/110 [00:18<00:31,  2.21it/s]\u001b[A\n","Iteration:  38% 42/110 [00:19<00:30,  2.21it/s]\u001b[A\n","Iteration:  39% 43/110 [00:19<00:30,  2.20it/s]\u001b[A\n","Iteration:  40% 44/110 [00:19<00:29,  2.20it/s]\u001b[A\n","Iteration:  41% 45/110 [00:20<00:29,  2.20it/s]\u001b[A\n","Iteration:  42% 46/110 [00:20<00:29,  2.21it/s]\u001b[A\n","Iteration:  43% 47/110 [00:21<00:28,  2.20it/s]\u001b[A\n","Iteration:  44% 48/110 [00:21<00:28,  2.20it/s]\u001b[A\n","Iteration:  45% 49/110 [00:22<00:27,  2.21it/s]\u001b[A\n","Iteration:  45% 50/110 [00:22<00:27,  2.21it/s]\u001b[A\n","Iteration:  46% 51/110 [00:23<00:26,  2.21it/s]\u001b[A\n","Iteration:  47% 52/110 [00:23<00:26,  2.21it/s]\u001b[A\n","Iteration:  48% 53/110 [00:24<00:25,  2.21it/s]\u001b[A\n","Iteration:  49% 54/110 [00:24<00:25,  2.20it/s]\u001b[A\n","Iteration:  50% 55/110 [00:24<00:25,  2.20it/s]\u001b[A\n","Iteration:  51% 56/110 [00:25<00:24,  2.20it/s]\u001b[A\n","Iteration:  52% 57/110 [00:25<00:24,  2.20it/s]\u001b[A\n","Iteration:  53% 58/110 [00:26<00:23,  2.20it/s]\u001b[A\n","Iteration:  54% 59/110 [00:26<00:23,  2.20it/s]\u001b[A\n","Iteration:  55% 60/110 [00:27<00:22,  2.20it/s]\u001b[A\n","Iteration:  55% 61/110 [00:27<00:22,  2.21it/s]\u001b[A\n","Iteration:  56% 62/110 [00:28<00:21,  2.21it/s]\u001b[A\n","Iteration:  57% 63/110 [00:28<00:21,  2.21it/s]\u001b[A\n","Iteration:  58% 64/110 [00:29<00:20,  2.21it/s]\u001b[A\n","Iteration:  59% 65/110 [00:29<00:20,  2.20it/s]\u001b[A\n","Iteration:  60% 66/110 [00:29<00:19,  2.20it/s]\u001b[A\n","Iteration:  61% 67/110 [00:30<00:19,  2.20it/s]\u001b[A\n","Iteration:  62% 68/110 [00:30<00:19,  2.21it/s]\u001b[A\n","Iteration:  63% 69/110 [00:31<00:18,  2.21it/s]\u001b[A\n","Iteration:  64% 70/110 [00:31<00:18,  2.21it/s]\u001b[A\n","Iteration:  65% 71/110 [00:32<00:17,  2.21it/s]\u001b[A\n","Iteration:  65% 72/110 [00:32<00:17,  2.20it/s]\u001b[A\n","Iteration:  66% 73/110 [00:33<00:16,  2.21it/s]\u001b[A\n","Iteration:  67% 74/110 [00:33<00:16,  2.20it/s]\u001b[A\n","Iteration:  68% 75/110 [00:34<00:15,  2.21it/s]\u001b[A\n","Iteration:  69% 76/110 [00:34<00:15,  2.20it/s]\u001b[A\n","Iteration:  70% 77/110 [00:34<00:14,  2.21it/s]\u001b[A\n","Iteration:  71% 78/110 [00:35<00:14,  2.21it/s]\u001b[A\n","Iteration:  72% 79/110 [00:35<00:14,  2.21it/s]\u001b[A\n","Iteration:  73% 80/110 [00:36<00:13,  2.21it/s]\u001b[A\n","Iteration:  74% 81/110 [00:36<00:13,  2.21it/s]\u001b[A\n","Iteration:  75% 82/110 [00:37<00:12,  2.21it/s]\u001b[A\n","Iteration:  75% 83/110 [00:37<00:12,  2.21it/s]\u001b[A\n","Iteration:  76% 84/110 [00:38<00:11,  2.21it/s]\u001b[A\n","Iteration:  77% 85/110 [00:38<00:11,  2.21it/s]\u001b[A\n","Iteration:  78% 86/110 [00:39<00:10,  2.21it/s]\u001b[A\n","Iteration:  79% 87/110 [00:39<00:10,  2.21it/s]\u001b[A\n","Iteration:  80% 88/110 [00:39<00:09,  2.21it/s]\u001b[A\n","Iteration:  81% 89/110 [00:40<00:09,  2.21it/s]\u001b[A\n","Iteration:  82% 90/110 [00:40<00:09,  2.21it/s]\u001b[A\n","Iteration:  83% 91/110 [00:41<00:08,  2.21it/s]\u001b[A\n","Iteration:  84% 92/110 [00:41<00:08,  2.21it/s]\u001b[A\n","Iteration:  85% 93/110 [00:42<00:07,  2.21it/s]\u001b[A\n","Iteration:  85% 94/110 [00:42<00:07,  2.21it/s]\u001b[A\n","Iteration:  86% 95/110 [00:43<00:06,  2.21it/s]\u001b[A\n","Iteration:  87% 96/110 [00:43<00:06,  2.22it/s]\u001b[A\n","Iteration:  88% 97/110 [00:43<00:05,  2.22it/s]\u001b[A\n","Iteration:  89% 98/110 [00:44<00:05,  2.21it/s]\u001b[A\n","Iteration:  90% 99/110 [00:44<00:04,  2.21it/s]\u001b[A\n","Iteration:  91% 100/110 [00:45<00:04,  2.21it/s]\u001b[A\n","Iteration:  92% 101/110 [00:45<00:04,  2.21it/s]\u001b[A\n","Iteration:  93% 102/110 [00:46<00:03,  2.21it/s]\u001b[A\n","Iteration:  94% 103/110 [00:46<00:03,  2.21it/s]\u001b[A\n","Iteration:  95% 104/110 [00:47<00:02,  2.21it/s]\u001b[A\n","Iteration:  95% 105/110 [00:47<00:02,  2.21it/s]\u001b[A\n","Iteration:  96% 106/110 [00:48<00:01,  2.21it/s]\u001b[A\n","Iteration:  97% 107/110 [00:48<00:01,  2.21it/s]\u001b[A\n","Iteration:  98% 108/110 [00:48<00:00,  2.21it/s]\u001b[A\n","Iteration:  99% 109/110 [00:49<00:00,  2.21it/s]\u001b[A\n","Iteration: 100% 110/110 [00:49<00:00,  2.21it/s]\n","Epoch:  60% 6/10 [04:57<03:18, 49.51s/it]\n","Iteration:   0% 0/110 [00:00<?, ?it/s]\u001b[A\n","Iteration:   1% 1/110 [00:00<00:49,  2.21it/s]\u001b[A\n","Iteration:   2% 2/110 [00:00<00:48,  2.21it/s]\u001b[A\n","Iteration:   3% 3/110 [00:01<00:48,  2.21it/s]\u001b[A\n","Iteration:   4% 4/110 [00:01<00:47,  2.21it/s]\u001b[A\n","Iteration:   5% 5/110 [00:02<00:47,  2.21it/s]\u001b[A\n","Iteration:   5% 6/110 [00:02<00:46,  2.21it/s]\u001b[A\n","Iteration:   6% 7/110 [00:03<00:46,  2.21it/s]\u001b[A\n","Iteration:   7% 8/110 [00:03<00:46,  2.21it/s]\u001b[A\n","Iteration:   8% 9/110 [00:04<00:45,  2.21it/s]\u001b[A\n","Iteration:   9% 10/110 [00:04<00:45,  2.21it/s]\u001b[A\n","Iteration:  10% 11/110 [00:04<00:44,  2.21it/s]\u001b[A\n","Iteration:  11% 12/110 [00:05<00:44,  2.21it/s]\u001b[A\n","Iteration:  12% 13/110 [00:05<00:43,  2.21it/s]\u001b[A\n","Iteration:  13% 14/110 [00:06<00:43,  2.21it/s]\u001b[A\n","Iteration:  14% 15/110 [00:06<00:42,  2.21it/s]\u001b[A\n","Iteration:  15% 16/110 [00:07<00:42,  2.21it/s]\u001b[A\n","Iteration:  15% 17/110 [00:07<00:42,  2.21it/s]\u001b[A\n","Iteration:  16% 18/110 [00:08<00:41,  2.21it/s]\u001b[A\n","Iteration:  17% 19/110 [00:08<00:41,  2.21it/s]\u001b[A\n","Iteration:  18% 20/110 [00:09<00:40,  2.22it/s]\u001b[A\n","Iteration:  19% 21/110 [00:09<00:40,  2.22it/s]\u001b[A\n","Iteration:  20% 22/110 [00:09<00:39,  2.21it/s]\u001b[A\n","Iteration:  21% 23/110 [00:10<00:39,  2.21it/s]\u001b[A\n","Iteration:  22% 24/110 [00:10<00:38,  2.21it/s]\u001b[A\n","Iteration:  23% 25/110 [00:11<00:38,  2.21it/s]\u001b[A\n","Iteration:  24% 26/110 [00:11<00:38,  2.21it/s]\u001b[A\n","Iteration:  25% 27/110 [00:12<00:37,  2.21it/s]\u001b[A\n","Iteration:  25% 28/110 [00:12<00:37,  2.21it/s]\u001b[A\n","Iteration:  26% 29/110 [00:13<00:36,  2.22it/s]\u001b[A\n","Iteration:  27% 30/110 [00:13<00:36,  2.22it/s]\u001b[A\n","Iteration:  28% 31/110 [00:14<00:35,  2.22it/s]\u001b[A\n","Iteration:  29% 32/110 [00:14<00:35,  2.22it/s]\u001b[A\n","Iteration:  30% 33/110 [00:14<00:34,  2.21it/s]\u001b[A\n","Iteration:  31% 34/110 [00:15<00:34,  2.21it/s]\u001b[A\n","Iteration:  32% 35/110 [00:15<00:33,  2.21it/s]\u001b[A\n","Iteration:  33% 36/110 [00:16<00:33,  2.21it/s]\u001b[A\n","Iteration:  34% 37/110 [00:16<00:33,  2.21it/s]\u001b[A\n","Iteration:  35% 38/110 [00:17<00:32,  2.21it/s]\u001b[A\n","Iteration:  35% 39/110 [00:17<00:32,  2.21it/s]\u001b[A\n","Iteration:  36% 40/110 [00:18<00:31,  2.21it/s]\u001b[A\n","Iteration:  37% 41/110 [00:18<00:31,  2.20it/s]\u001b[A\n","Iteration:  38% 42/110 [00:18<00:30,  2.21it/s]\u001b[A\n","Iteration:  39% 43/110 [00:19<00:30,  2.21it/s]\u001b[A\n","Iteration:  40% 44/110 [00:19<00:29,  2.21it/s]\u001b[A\n","Iteration:  41% 45/110 [00:20<00:29,  2.21it/s]\u001b[A\n","Iteration:  42% 46/110 [00:20<00:28,  2.21it/s]\u001b[A\n","Iteration:  43% 47/110 [00:21<00:28,  2.21it/s]\u001b[A\n","Iteration:  44% 48/110 [00:21<00:28,  2.21it/s]\u001b[A\n","Iteration:  45% 49/110 [00:22<00:27,  2.21it/s]\u001b[A\n","Iteration:  45% 50/110 [00:22<00:27,  2.21it/s]\u001b[A\n","Iteration:  46% 51/110 [00:23<00:26,  2.21it/s]\u001b[A\n","Iteration:  47% 52/110 [00:23<00:26,  2.21it/s]\u001b[A\n","Iteration:  48% 53/110 [00:23<00:25,  2.22it/s]\u001b[A\n","Iteration:  49% 54/110 [00:24<00:25,  2.21it/s]\u001b[A\n","Iteration:  50% 55/110 [00:24<00:24,  2.21it/s]\u001b[A\n","Iteration:  51% 56/110 [00:25<00:24,  2.21it/s]\u001b[A\n","Iteration:  52% 57/110 [00:25<00:23,  2.21it/s]\u001b[A\n","Iteration:  53% 58/110 [00:26<00:23,  2.21it/s]\u001b[A\n","Iteration:  54% 59/110 [00:26<00:23,  2.21it/s]\u001b[A\n","Iteration:  55% 60/110 [00:27<00:22,  2.22it/s]\u001b[A\n","Iteration:  55% 61/110 [00:27<00:22,  2.22it/s]\u001b[A\n","Iteration:  56% 62/110 [00:28<00:21,  2.21it/s]\u001b[A\n","Iteration:  57% 63/110 [00:28<00:21,  2.21it/s]\u001b[A\n","Iteration:  58% 64/110 [00:28<00:20,  2.21it/s]\u001b[A\n","Iteration:  59% 65/110 [00:29<00:20,  2.22it/s]\u001b[A\n","Iteration:  60% 66/110 [00:29<00:19,  2.21it/s]\u001b[A\n","Iteration:  61% 67/110 [00:30<00:19,  2.21it/s]\u001b[A\n","Iteration:  62% 68/110 [00:30<00:18,  2.21it/s]\u001b[A\n","Iteration:  63% 69/110 [00:31<00:18,  2.21it/s]\u001b[A\n","Iteration:  64% 70/110 [00:31<00:18,  2.21it/s]\u001b[A\n","Iteration:  65% 71/110 [00:32<00:17,  2.21it/s]\u001b[A\n","Iteration:  65% 72/110 [00:32<00:17,  2.21it/s]\u001b[A\n","Iteration:  66% 73/110 [00:32<00:16,  2.21it/s]\u001b[A\n","Iteration:  67% 74/110 [00:33<00:16,  2.21it/s]\u001b[A\n","Iteration:  68% 75/110 [00:33<00:15,  2.21it/s]\u001b[A\n","Iteration:  69% 76/110 [00:34<00:15,  2.21it/s]\u001b[A\n","Iteration:  70% 77/110 [00:34<00:14,  2.21it/s]\u001b[A\n","Iteration:  71% 78/110 [00:35<00:14,  2.21it/s]\u001b[A\n","Iteration:  72% 79/110 [00:35<00:14,  2.21it/s]\u001b[A\n","Iteration:  73% 80/110 [00:36<00:13,  2.21it/s]\u001b[A\n","Iteration:  74% 81/110 [00:36<00:13,  2.21it/s]\u001b[A\n","Iteration:  75% 82/110 [00:37<00:12,  2.21it/s]\u001b[A\n","Iteration:  75% 83/110 [00:37<00:12,  2.21it/s]\u001b[A\n","Iteration:  76% 84/110 [00:37<00:11,  2.21it/s]\u001b[A\n","Iteration:  77% 85/110 [00:38<00:11,  2.21it/s]\u001b[A\n","Iteration:  78% 86/110 [00:38<00:10,  2.21it/s]\u001b[A\n","Iteration:  79% 87/110 [00:39<00:10,  2.20it/s]\u001b[A\n","Iteration:  80% 88/110 [00:39<00:09,  2.21it/s]\u001b[A\n","Iteration:  81% 89/110 [00:40<00:09,  2.21it/s]\u001b[A\n","Iteration:  82% 90/110 [00:40<00:09,  2.21it/s]\u001b[A\n","Iteration:  83% 91/110 [00:41<00:08,  2.21it/s]\u001b[A\n","Iteration:  84% 92/110 [00:41<00:08,  2.21it/s]\u001b[A\n","Iteration:  85% 93/110 [00:42<00:07,  2.21it/s]\u001b[A\n","Iteration:  85% 94/110 [00:42<00:07,  2.21it/s]\u001b[A\n","Iteration:  86% 95/110 [00:42<00:06,  2.21it/s]\u001b[A\n","Iteration:  87% 96/110 [00:43<00:06,  2.21it/s]\u001b[A\n","Iteration:  88% 97/110 [00:43<00:05,  2.21it/s]\u001b[A\n","Iteration:  89% 98/110 [00:44<00:05,  2.21it/s]\u001b[A\n","Iteration:  90% 99/110 [00:44<00:04,  2.21it/s]\u001b[A\n","Iteration:  91% 100/110 [00:45<00:04,  2.20it/s]\u001b[A\n","Iteration:  92% 101/110 [00:45<00:04,  2.20it/s]\u001b[A\n","Iteration:  93% 102/110 [00:46<00:03,  2.21it/s]\u001b[A\n","Iteration:  94% 103/110 [00:46<00:03,  2.22it/s]\u001b[A\n","Iteration:  95% 104/110 [00:47<00:02,  2.21it/s]\u001b[A\n","Iteration:  95% 105/110 [00:47<00:02,  2.21it/s]\u001b[A\n","Iteration:  96% 106/110 [00:47<00:01,  2.21it/s]\u001b[A\n","Iteration:  97% 107/110 [00:48<00:01,  2.21it/s]\u001b[A\n","Iteration:  98% 108/110 [00:48<00:00,  2.21it/s]\u001b[A\n","Iteration:  99% 109/110 [00:49<00:00,  2.22it/s]\u001b[A\n","Iteration: 100% 110/110 [00:49<00:00,  2.21it/s]\n","Epoch:  70% 7/10 [05:46<02:28, 49.58s/it]\n","Iteration:   0% 0/110 [00:00<?, ?it/s]\u001b[A\n","Iteration:   1% 1/110 [00:00<00:49,  2.22it/s]\u001b[A\n","Iteration:   2% 2/110 [00:00<00:48,  2.22it/s]\u001b[A\n","Iteration:   3% 3/110 [00:01<00:48,  2.22it/s]\u001b[A\n","Iteration:   4% 4/110 [00:01<00:47,  2.21it/s]\u001b[A\n","Iteration:   5% 5/110 [00:02<00:47,  2.21it/s]\u001b[A\n","Iteration:   5% 6/110 [00:02<00:46,  2.21it/s]\u001b[A\n","Iteration:   6% 7/110 [00:03<00:46,  2.21it/s]\u001b[A\n","Iteration:   7% 8/110 [00:03<00:46,  2.21it/s]\u001b[A\n","Iteration:   8% 9/110 [00:04<00:45,  2.21it/s]\u001b[A\n","Iteration:   9% 10/110 [00:04<00:45,  2.21it/s]\u001b[A\n","Iteration:  10% 11/110 [00:04<00:44,  2.21it/s]\u001b[A\n","Iteration:  11% 12/110 [00:05<00:44,  2.21it/s]\u001b[A\n","Iteration:  12% 13/110 [00:05<00:43,  2.21it/s]\u001b[A\n","Iteration:  13% 14/110 [00:06<00:43,  2.21it/s]\u001b[A\n","Iteration:  14% 15/110 [00:06<00:43,  2.20it/s]\u001b[A\n","Iteration:  15% 16/110 [00:07<00:42,  2.21it/s]\u001b[A\n","Iteration:  15% 17/110 [00:07<00:42,  2.21it/s]\u001b[A\n","Iteration:  16% 18/110 [00:08<00:41,  2.21it/s]\u001b[A\n","Iteration:  17% 19/110 [00:08<00:41,  2.21it/s]\u001b[A\n","Iteration:  18% 20/110 [00:09<00:40,  2.21it/s]\u001b[A\n","Iteration:  19% 21/110 [00:09<00:40,  2.21it/s]\u001b[A\n","Iteration:  20% 22/110 [00:09<00:39,  2.20it/s]\u001b[A\n","Iteration:  21% 23/110 [00:10<00:39,  2.20it/s]\u001b[A\n","Iteration:  22% 24/110 [00:10<00:38,  2.21it/s]\u001b[A\n","Iteration:  23% 25/110 [00:11<00:38,  2.21it/s]\u001b[A\n","Iteration:  24% 26/110 [00:11<00:38,  2.20it/s]\u001b[A\n","Iteration:  25% 27/110 [00:12<00:37,  2.20it/s]\u001b[A\n","Iteration:  25% 28/110 [00:12<00:37,  2.20it/s]\u001b[A\n","Iteration:  26% 29/110 [00:13<00:36,  2.20it/s]\u001b[A\n","Iteration:  27% 30/110 [00:13<00:36,  2.21it/s]\u001b[A\n","Iteration:  28% 31/110 [00:14<00:35,  2.20it/s]\u001b[A\n","Iteration:  29% 32/110 [00:14<00:35,  2.21it/s]\u001b[A\n","Iteration:  30% 33/110 [00:14<00:34,  2.21it/s]\u001b[A\n","Iteration:  31% 34/110 [00:15<00:34,  2.20it/s]\u001b[A\n","Iteration:  32% 35/110 [00:15<00:33,  2.21it/s]\u001b[A\n","Iteration:  33% 36/110 [00:16<00:33,  2.21it/s]\u001b[A\n","Iteration:  34% 37/110 [00:16<00:33,  2.21it/s]\u001b[A\n","Iteration:  35% 38/110 [00:17<00:32,  2.21it/s]\u001b[A\n","Iteration:  35% 39/110 [00:17<00:32,  2.21it/s]\u001b[A\n","Iteration:  36% 40/110 [00:18<00:31,  2.21it/s]\u001b[A\n","Iteration:  37% 41/110 [00:18<00:31,  2.20it/s]\u001b[A\n","Iteration:  38% 42/110 [00:19<00:30,  2.20it/s]\u001b[A\n","Iteration:  39% 43/110 [00:19<00:30,  2.21it/s]\u001b[A\n","Iteration:  40% 44/110 [00:19<00:30,  2.20it/s]\u001b[A\n","Iteration:  41% 45/110 [00:20<00:29,  2.20it/s]\u001b[A\n","Iteration:  42% 46/110 [00:20<00:28,  2.21it/s]\u001b[A\n","Iteration:  43% 47/110 [00:21<00:28,  2.21it/s]\u001b[A\n","Iteration:  44% 48/110 [00:21<00:28,  2.21it/s]\u001b[A\n","Iteration:  45% 49/110 [00:22<00:27,  2.21it/s]\u001b[A\n","Iteration:  45% 50/110 [00:22<00:27,  2.21it/s]\u001b[A\n","Iteration:  46% 51/110 [00:23<00:26,  2.20it/s]\u001b[A\n","Iteration:  47% 52/110 [00:23<00:26,  2.20it/s]\u001b[A\n","Iteration:  48% 53/110 [00:24<00:25,  2.21it/s]\u001b[A\n","Iteration:  49% 54/110 [00:24<00:25,  2.21it/s]\u001b[A\n","Iteration:  50% 55/110 [00:24<00:24,  2.21it/s]\u001b[A\n","Iteration:  51% 56/110 [00:25<00:24,  2.21it/s]\u001b[A\n","Iteration:  52% 57/110 [00:25<00:24,  2.21it/s]\u001b[A\n","Iteration:  53% 58/110 [00:26<00:23,  2.21it/s]\u001b[A\n","Iteration:  54% 59/110 [00:26<00:23,  2.21it/s]\u001b[A\n","Iteration:  55% 60/110 [00:27<00:22,  2.21it/s]\u001b[A\n","Iteration:  55% 61/110 [00:27<00:22,  2.21it/s]\u001b[A\n","Iteration:  56% 62/110 [00:28<00:21,  2.21it/s]\u001b[A\n","Iteration:  57% 63/110 [00:28<00:21,  2.21it/s]\u001b[A\n","Iteration:  58% 64/110 [00:28<00:20,  2.21it/s]\u001b[A\n","Iteration:  59% 65/110 [00:29<00:20,  2.21it/s]\u001b[A\n","Iteration:  60% 66/110 [00:29<00:19,  2.22it/s]\u001b[A\n","Iteration:  61% 67/110 [00:30<00:19,  2.21it/s]\u001b[A\n","Iteration:  62% 68/110 [00:30<00:19,  2.21it/s]\u001b[A\n","Iteration:  63% 69/110 [00:31<00:18,  2.21it/s]\u001b[A\n","Iteration:  64% 70/110 [00:31<00:18,  2.21it/s]\u001b[A\n","Iteration:  65% 71/110 [00:32<00:17,  2.21it/s]\u001b[A\n","Iteration:  65% 72/110 [00:32<00:17,  2.21it/s]\u001b[A\n","Iteration:  66% 73/110 [00:33<00:16,  2.20it/s]\u001b[A\n","Iteration:  67% 74/110 [00:33<00:16,  2.21it/s]\u001b[A\n","Iteration:  68% 75/110 [00:33<00:15,  2.21it/s]\u001b[A\n","Iteration:  69% 76/110 [00:34<00:15,  2.21it/s]\u001b[A\n","Iteration:  70% 77/110 [00:34<00:14,  2.20it/s]\u001b[A\n","Iteration:  71% 78/110 [00:35<00:14,  2.21it/s]\u001b[A\n","Iteration:  72% 79/110 [00:35<00:14,  2.21it/s]\u001b[A\n","Iteration:  73% 80/110 [00:36<00:13,  2.21it/s]\u001b[A\n","Iteration:  74% 81/110 [00:36<00:13,  2.21it/s]\u001b[A\n","Iteration:  75% 82/110 [00:37<00:12,  2.21it/s]\u001b[A\n","Iteration:  75% 83/110 [00:37<00:12,  2.21it/s]\u001b[A\n","Iteration:  76% 84/110 [00:38<00:11,  2.21it/s]\u001b[A\n","Iteration:  77% 85/110 [00:38<00:11,  2.21it/s]\u001b[A\n","Iteration:  78% 86/110 [00:38<00:10,  2.21it/s]\u001b[A\n","Iteration:  79% 87/110 [00:39<00:10,  2.21it/s]\u001b[A\n","Iteration:  80% 88/110 [00:39<00:09,  2.21it/s]\u001b[A\n","Iteration:  81% 89/110 [00:40<00:09,  2.21it/s]\u001b[A\n","Iteration:  82% 90/110 [00:40<00:09,  2.21it/s]\u001b[A\n","Iteration:  83% 91/110 [00:41<00:08,  2.20it/s]\u001b[A\n","Iteration:  84% 92/110 [00:41<00:08,  2.21it/s]\u001b[A\n","Iteration:  85% 93/110 [00:42<00:07,  2.21it/s]\u001b[A\n","Iteration:  85% 94/110 [00:42<00:07,  2.21it/s]\u001b[A\n","Iteration:  86% 95/110 [00:43<00:06,  2.21it/s]\u001b[A\n","Iteration:  87% 96/110 [00:43<00:06,  2.21it/s]\u001b[A\n","Iteration:  88% 97/110 [00:43<00:05,  2.21it/s]\u001b[A\n","Iteration:  89% 98/110 [00:44<00:05,  2.21it/s]\u001b[A\n","Iteration:  90% 99/110 [00:44<00:04,  2.21it/s]\u001b[A\n","Iteration:  91% 100/110 [00:45<00:04,  2.21it/s]\u001b[A\n","Iteration:  92% 101/110 [00:45<00:04,  2.21it/s]\u001b[A\n","Iteration:  93% 102/110 [00:46<00:03,  2.21it/s]\u001b[A\n","Iteration:  94% 103/110 [00:46<00:03,  2.21it/s]\u001b[A\n","Iteration:  95% 104/110 [00:47<00:02,  2.21it/s]\u001b[A\n","Iteration:  95% 105/110 [00:47<00:02,  2.21it/s]\u001b[A\n","Iteration:  96% 106/110 [00:48<00:01,  2.21it/s]\u001b[A\n","Iteration:  97% 107/110 [00:48<00:01,  2.21it/s]\u001b[A\n","Iteration:  98% 108/110 [00:48<00:00,  2.21it/s]\u001b[A\n","Iteration:  99% 109/110 [00:49<00:00,  2.21it/s]\u001b[A\n","Iteration: 100% 110/110 [00:49<00:00,  2.21it/s]\n","Epoch:  80% 8/10 [06:36<01:39, 49.65s/it]\n","Iteration:   0% 0/110 [00:00<?, ?it/s]\u001b[A\n","Iteration:   1% 1/110 [00:00<00:49,  2.19it/s]\u001b[A\n","Iteration:   2% 2/110 [00:00<00:49,  2.20it/s]\u001b[A\n","Iteration:   3% 3/110 [00:01<00:48,  2.20it/s]\u001b[A\n","Iteration:   4% 4/110 [00:01<00:47,  2.21it/s]\u001b[A\n","Iteration:   5% 5/110 [00:02<00:47,  2.21it/s]\u001b[A\n","Iteration:   5% 6/110 [00:02<00:47,  2.21it/s]\u001b[A\n","Iteration:   6% 7/110 [00:03<00:46,  2.21it/s]\u001b[A\n","Iteration:   7% 8/110 [00:03<00:46,  2.20it/s]\u001b[A\n","Iteration:   8% 9/110 [00:04<00:45,  2.21it/s]\u001b[A\n","Iteration:   9% 10/110 [00:04<00:45,  2.21it/s]\u001b[A\n","Iteration:  10% 11/110 [00:04<00:44,  2.21it/s]\u001b[A\n","Iteration:  11% 12/110 [00:05<00:44,  2.20it/s]\u001b[A\n","Iteration:  12% 13/110 [00:05<00:43,  2.21it/s]\u001b[A\n","Iteration:  13% 14/110 [00:06<00:43,  2.20it/s]\u001b[A\n","Iteration:  14% 15/110 [00:06<00:43,  2.20it/s]\u001b[A\n","Iteration:  15% 16/110 [00:07<00:42,  2.21it/s]\u001b[A\n","Iteration:  15% 17/110 [00:07<00:42,  2.21it/s]\u001b[A\n","Iteration:  16% 18/110 [00:08<00:41,  2.21it/s]\u001b[A\n","Iteration:  17% 19/110 [00:08<00:41,  2.21it/s]\u001b[A\n","Iteration:  18% 20/110 [00:09<00:40,  2.21it/s]\u001b[A\n","Iteration:  19% 21/110 [00:09<00:40,  2.21it/s]\u001b[A\n","Iteration:  20% 22/110 [00:09<00:39,  2.21it/s]\u001b[A\n","Iteration:  21% 23/110 [00:10<00:39,  2.21it/s]\u001b[A\n","Iteration:  22% 24/110 [00:10<00:38,  2.21it/s]\u001b[A\n","Iteration:  23% 25/110 [00:11<00:38,  2.21it/s]\u001b[A\n","Iteration:  24% 26/110 [00:11<00:38,  2.21it/s]\u001b[A\n","Iteration:  25% 27/110 [00:12<00:37,  2.21it/s]\u001b[A\n","Iteration:  25% 28/110 [00:12<00:37,  2.21it/s]\u001b[A\n","Iteration:  26% 29/110 [00:13<00:36,  2.21it/s]\u001b[A\n","Iteration:  27% 30/110 [00:13<00:36,  2.21it/s]\u001b[A\n","Iteration:  28% 31/110 [00:14<00:35,  2.21it/s]\u001b[A\n","Iteration:  29% 32/110 [00:14<00:35,  2.21it/s]\u001b[A\n","Iteration:  30% 33/110 [00:14<00:34,  2.21it/s]\u001b[A\n","Iteration:  31% 34/110 [00:15<00:34,  2.21it/s]\u001b[A\n","Iteration:  32% 35/110 [00:15<00:33,  2.21it/s]\u001b[A\n","Iteration:  33% 36/110 [00:16<00:33,  2.21it/s]\u001b[A\n","Iteration:  34% 37/110 [00:16<00:33,  2.21it/s]\u001b[A\n","Iteration:  35% 38/110 [00:17<00:32,  2.21it/s]\u001b[A\n","Iteration:  35% 39/110 [00:17<00:32,  2.21it/s]\u001b[A\n","Iteration:  36% 40/110 [00:18<00:31,  2.20it/s]\u001b[A\n","Iteration:  37% 41/110 [00:18<00:31,  2.21it/s]\u001b[A\n","Iteration:  38% 42/110 [00:19<00:30,  2.21it/s]\u001b[A\n","Iteration:  39% 43/110 [00:19<00:30,  2.21it/s]\u001b[A\n","Iteration:  40% 44/110 [00:19<00:29,  2.22it/s]\u001b[A\n","Iteration:  41% 45/110 [00:20<00:29,  2.21it/s]\u001b[A\n","Iteration:  42% 46/110 [00:20<00:28,  2.21it/s]\u001b[A\n","Iteration:  43% 47/110 [00:21<00:28,  2.21it/s]\u001b[A\n","Iteration:  44% 48/110 [00:21<00:28,  2.20it/s]\u001b[A\n","Iteration:  45% 49/110 [00:22<00:27,  2.21it/s]\u001b[A\n","Iteration:  45% 50/110 [00:22<00:27,  2.21it/s]\u001b[A\n","Iteration:  46% 51/110 [00:23<00:26,  2.21it/s]\u001b[A\n","Iteration:  47% 52/110 [00:23<00:26,  2.21it/s]\u001b[A\n","Iteration:  48% 53/110 [00:23<00:25,  2.21it/s]\u001b[A\n","Iteration:  49% 54/110 [00:24<00:25,  2.21it/s]\u001b[A\n","Iteration:  50% 55/110 [00:24<00:24,  2.21it/s]\u001b[A\n","Iteration:  51% 56/110 [00:25<00:24,  2.21it/s]\u001b[A\n","Iteration:  52% 57/110 [00:25<00:23,  2.21it/s]\u001b[A\n","Iteration:  53% 58/110 [00:26<00:23,  2.21it/s]\u001b[A\n","Iteration:  54% 59/110 [00:26<00:23,  2.21it/s]\u001b[A\n","Iteration:  55% 60/110 [00:27<00:22,  2.21it/s]\u001b[A\n","Iteration:  55% 61/110 [00:27<00:22,  2.21it/s]\u001b[A\n","Iteration:  56% 62/110 [00:28<00:21,  2.22it/s]\u001b[A\n","Iteration:  57% 63/110 [00:28<00:21,  2.22it/s]\u001b[A\n","Iteration:  58% 64/110 [00:28<00:20,  2.21it/s]\u001b[A\n","Iteration:  59% 65/110 [00:29<00:20,  2.21it/s]\u001b[A\n","Iteration:  60% 66/110 [00:29<00:19,  2.21it/s]\u001b[A\n","Iteration:  61% 67/110 [00:30<00:19,  2.22it/s]\u001b[A\n","Iteration:  62% 68/110 [00:30<00:18,  2.21it/s]\u001b[A\n","Iteration:  63% 69/110 [00:31<00:18,  2.21it/s]\u001b[A\n","Iteration:  64% 70/110 [00:31<00:18,  2.21it/s]\u001b[A\n","Iteration:  65% 71/110 [00:32<00:17,  2.21it/s]\u001b[A\n","Iteration:  65% 72/110 [00:32<00:17,  2.21it/s]\u001b[A\n","Iteration:  66% 73/110 [00:33<00:16,  2.21it/s]\u001b[A\n","Iteration:  67% 74/110 [00:33<00:16,  2.21it/s]\u001b[A\n","Iteration:  68% 75/110 [00:33<00:15,  2.21it/s]\u001b[A\n","Iteration:  69% 76/110 [00:34<00:15,  2.21it/s]\u001b[A\n","Iteration:  70% 77/110 [00:34<00:14,  2.21it/s]\u001b[A\n","Iteration:  71% 78/110 [00:35<00:14,  2.21it/s]\u001b[A\n","Iteration:  72% 79/110 [00:35<00:14,  2.21it/s]\u001b[A\n","Iteration:  73% 80/110 [00:36<00:13,  2.21it/s]\u001b[A\n","Iteration:  74% 81/110 [00:36<00:13,  2.21it/s]\u001b[A\n","Iteration:  75% 82/110 [00:37<00:12,  2.21it/s]\u001b[A\n","Iteration:  75% 83/110 [00:37<00:12,  2.21it/s]\u001b[A\n","Iteration:  76% 84/110 [00:38<00:11,  2.21it/s]\u001b[A\n","Iteration:  77% 85/110 [00:38<00:11,  2.21it/s]\u001b[A\n","Iteration:  78% 86/110 [00:38<00:10,  2.21it/s]\u001b[A\n","Iteration:  79% 87/110 [00:39<00:10,  2.21it/s]\u001b[A\n","Iteration:  80% 88/110 [00:39<00:09,  2.21it/s]\u001b[A\n","Iteration:  81% 89/110 [00:40<00:09,  2.21it/s]\u001b[A\n","Iteration:  82% 90/110 [00:40<00:09,  2.21it/s]\u001b[A\n","Iteration:  83% 91/110 [00:41<00:08,  2.21it/s]\u001b[A\n","Iteration:  84% 92/110 [00:41<00:08,  2.21it/s]\u001b[A\n","Iteration:  85% 93/110 [00:42<00:07,  2.22it/s]\u001b[A\n","Iteration:  85% 94/110 [00:42<00:07,  2.22it/s]\u001b[A\n","Iteration:  86% 95/110 [00:42<00:06,  2.22it/s]\u001b[A\n","Iteration:  87% 96/110 [00:43<00:06,  2.22it/s]\u001b[A\n","Iteration:  88% 97/110 [00:43<00:05,  2.22it/s]\u001b[A\n","Iteration:  89% 98/110 [00:44<00:05,  2.22it/s]\u001b[A\n","Iteration:  90% 99/110 [00:44<00:04,  2.21it/s]\u001b[A\n","Iteration:  91% 100/110 [00:45<00:04,  2.21it/s]\u001b[A\n","Iteration:  92% 101/110 [00:45<00:04,  2.22it/s]\u001b[A\n","Iteration:  93% 102/110 [00:46<00:03,  2.22it/s]\u001b[A\n","Iteration:  94% 103/110 [00:46<00:03,  2.22it/s]\u001b[A\n","Iteration:  95% 104/110 [00:47<00:02,  2.22it/s]\u001b[A\n","Iteration:  95% 105/110 [00:47<00:02,  2.21it/s]\u001b[A\n","Iteration:  96% 106/110 [00:47<00:01,  2.22it/s]\u001b[A\n","Iteration:  97% 107/110 [00:48<00:01,  2.21it/s]\u001b[A\n","Iteration:  98% 108/110 [00:48<00:00,  2.22it/s]\u001b[A\n","Iteration:  99% 109/110 [00:49<00:00,  2.22it/s]\u001b[A\n","Iteration: 100% 110/110 [00:49<00:00,  2.21it/s]\n","Epoch:  90% 9/10 [07:26<00:49, 49.68s/it]\n","Iteration:   0% 0/110 [00:00<?, ?it/s]\u001b[A\n","Iteration:   1% 1/110 [00:00<00:48,  2.23it/s]\u001b[A\n","Iteration:   2% 2/110 [00:00<00:48,  2.22it/s]\u001b[A\n","Iteration:   3% 3/110 [00:01<00:48,  2.22it/s]\u001b[A\n","Iteration:   4% 4/110 [00:01<00:47,  2.22it/s]\u001b[A\n","Iteration:   5% 5/110 [00:02<00:47,  2.21it/s]\u001b[A\n","Iteration:   5% 6/110 [00:02<00:46,  2.22it/s]\u001b[A\n","Iteration:   6% 7/110 [00:03<00:46,  2.22it/s]\u001b[A\n","Iteration:   7% 8/110 [00:03<00:46,  2.22it/s]\u001b[A\n","Iteration:   8% 9/110 [00:04<00:45,  2.22it/s]\u001b[A\n","Iteration:   9% 10/110 [00:04<00:45,  2.22it/s]\u001b[A\n","Iteration:  10% 11/110 [00:04<00:44,  2.22it/s]\u001b[A\n","Iteration:  11% 12/110 [00:05<00:44,  2.21it/s]\u001b[A\n","Iteration:  12% 13/110 [00:05<00:43,  2.22it/s]\u001b[A\n","Iteration:  13% 14/110 [00:06<00:43,  2.22it/s]\u001b[A\n","Iteration:  14% 15/110 [00:06<00:42,  2.22it/s]\u001b[A\n","Iteration:  15% 16/110 [00:07<00:42,  2.21it/s]\u001b[A\n","Iteration:  15% 17/110 [00:07<00:42,  2.21it/s]\u001b[A\n","Iteration:  16% 18/110 [00:08<00:41,  2.22it/s]\u001b[A\n","Iteration:  17% 19/110 [00:08<00:41,  2.21it/s]\u001b[A\n","Iteration:  18% 20/110 [00:09<00:40,  2.21it/s]\u001b[A\n","Iteration:  19% 21/110 [00:09<00:40,  2.21it/s]\u001b[A\n","Iteration:  20% 22/110 [00:09<00:39,  2.21it/s]\u001b[A\n","Iteration:  21% 23/110 [00:10<00:39,  2.21it/s]\u001b[A\n","Iteration:  22% 24/110 [00:10<00:38,  2.21it/s]\u001b[A\n","Iteration:  23% 25/110 [00:11<00:38,  2.21it/s]\u001b[A\n","Iteration:  24% 26/110 [00:11<00:37,  2.21it/s]\u001b[A\n","Iteration:  25% 27/110 [00:12<00:37,  2.22it/s]\u001b[A\n","Iteration:  25% 28/110 [00:12<00:37,  2.21it/s]\u001b[A\n","Iteration:  26% 29/110 [00:13<00:36,  2.21it/s]\u001b[A\n","Iteration:  27% 30/110 [00:13<00:36,  2.22it/s]\u001b[A\n","Iteration:  28% 31/110 [00:13<00:35,  2.21it/s]\u001b[A\n","Iteration:  29% 32/110 [00:14<00:35,  2.22it/s]\u001b[A\n","Iteration:  30% 33/110 [00:14<00:34,  2.21it/s]\u001b[A\n","Iteration:  31% 34/110 [00:15<00:34,  2.21it/s]\u001b[A\n","Iteration:  32% 35/110 [00:15<00:33,  2.21it/s]\u001b[A\n","Iteration:  33% 36/110 [00:16<00:33,  2.21it/s]\u001b[A\n","Iteration:  34% 37/110 [00:16<00:33,  2.21it/s]\u001b[A\n","Iteration:  35% 38/110 [00:17<00:32,  2.21it/s]\u001b[A\n","Iteration:  35% 39/110 [00:17<00:32,  2.21it/s]\u001b[A\n","Iteration:  36% 40/110 [00:18<00:31,  2.21it/s]\u001b[A\n","Iteration:  37% 41/110 [00:18<00:31,  2.21it/s]\u001b[A\n","Iteration:  38% 42/110 [00:18<00:30,  2.21it/s]\u001b[A\n","Iteration:  39% 43/110 [00:19<00:30,  2.21it/s]\u001b[A\n","Iteration:  40% 44/110 [00:19<00:29,  2.21it/s]\u001b[A\n","Iteration:  41% 45/110 [00:20<00:29,  2.22it/s]\u001b[A\n","Iteration:  42% 46/110 [00:20<00:28,  2.21it/s]\u001b[A\n","Iteration:  43% 47/110 [00:21<00:28,  2.22it/s]\u001b[A\n","Iteration:  44% 48/110 [00:21<00:27,  2.21it/s]\u001b[A\n","Iteration:  45% 49/110 [00:22<00:27,  2.22it/s]\u001b[A\n","Iteration:  45% 50/110 [00:22<00:27,  2.21it/s]\u001b[A\n","Iteration:  46% 51/110 [00:23<00:26,  2.21it/s]\u001b[A\n","Iteration:  47% 52/110 [00:23<00:26,  2.21it/s]\u001b[A\n","Iteration:  48% 53/110 [00:23<00:25,  2.21it/s]\u001b[A\n","Iteration:  49% 54/110 [00:24<00:25,  2.21it/s]\u001b[A\n","Iteration:  50% 55/110 [00:24<00:24,  2.21it/s]\u001b[A\n","Iteration:  51% 56/110 [00:25<00:24,  2.21it/s]\u001b[A\n","Iteration:  52% 57/110 [00:25<00:23,  2.22it/s]\u001b[A\n","Iteration:  53% 58/110 [00:26<00:23,  2.22it/s]\u001b[A\n","Iteration:  54% 59/110 [00:26<00:23,  2.22it/s]\u001b[A\n","Iteration:  55% 60/110 [00:27<00:22,  2.22it/s]\u001b[A\n","Iteration:  55% 61/110 [00:27<00:22,  2.22it/s]\u001b[A\n","Iteration:  56% 62/110 [00:28<00:21,  2.22it/s]\u001b[A\n","Iteration:  57% 63/110 [00:28<00:21,  2.21it/s]\u001b[A\n","Iteration:  58% 64/110 [00:28<00:20,  2.21it/s]\u001b[A\n","Iteration:  59% 65/110 [00:29<00:20,  2.21it/s]\u001b[A\n","Iteration:  60% 66/110 [00:29<00:19,  2.21it/s]\u001b[A\n","Iteration:  61% 67/110 [00:30<00:19,  2.21it/s]\u001b[A\n","Iteration:  62% 68/110 [00:30<00:18,  2.21it/s]\u001b[A\n","Iteration:  63% 69/110 [00:31<00:18,  2.22it/s]\u001b[A\n","Iteration:  64% 70/110 [00:31<00:18,  2.21it/s]\u001b[A\n","Iteration:  65% 71/110 [00:32<00:17,  2.22it/s]\u001b[A\n","Iteration:  65% 72/110 [00:32<00:17,  2.22it/s]\u001b[A\n","Iteration:  66% 73/110 [00:32<00:16,  2.21it/s]\u001b[A\n","Iteration:  67% 74/110 [00:33<00:16,  2.21it/s]\u001b[A\n","Iteration:  68% 75/110 [00:33<00:15,  2.21it/s]\u001b[A\n","Iteration:  69% 76/110 [00:34<00:15,  2.21it/s]\u001b[A\n","Iteration:  70% 77/110 [00:34<00:14,  2.21it/s]\u001b[A\n","Iteration:  71% 78/110 [00:35<00:14,  2.21it/s]\u001b[A\n","Iteration:  72% 79/110 [00:35<00:14,  2.21it/s]\u001b[A\n","Iteration:  73% 80/110 [00:36<00:13,  2.21it/s]\u001b[A\n","Iteration:  74% 81/110 [00:36<00:13,  2.21it/s]\u001b[A\n","Iteration:  75% 82/110 [00:37<00:12,  2.21it/s]\u001b[A\n","Iteration:  75% 83/110 [00:37<00:12,  2.21it/s]\u001b[A\n","Iteration:  76% 84/110 [00:37<00:11,  2.21it/s]\u001b[A\n","Iteration:  77% 85/110 [00:38<00:11,  2.20it/s]\u001b[A\n","Iteration:  78% 86/110 [00:38<00:10,  2.21it/s]\u001b[A\n","Iteration:  79% 87/110 [00:39<00:10,  2.21it/s]\u001b[A\n","Iteration:  80% 88/110 [00:39<00:09,  2.21it/s]\u001b[A\n","Iteration:  81% 89/110 [00:40<00:09,  2.22it/s]\u001b[A\n","Iteration:  82% 90/110 [00:40<00:09,  2.22it/s]\u001b[A\n","Iteration:  83% 91/110 [00:41<00:08,  2.21it/s]\u001b[A\n","Iteration:  84% 92/110 [00:41<00:08,  2.21it/s]\u001b[A\n","Iteration:  85% 93/110 [00:42<00:07,  2.21it/s]\u001b[A\n","Iteration:  85% 94/110 [00:42<00:07,  2.21it/s]\u001b[A\n","Iteration:  86% 95/110 [00:42<00:06,  2.21it/s]\u001b[A\n","Iteration:  87% 96/110 [00:43<00:06,  2.21it/s]\u001b[A\n","Iteration:  88% 97/110 [00:43<00:05,  2.21it/s]\u001b[A\n","Iteration:  89% 98/110 [00:44<00:05,  2.21it/s]\u001b[A\n","Iteration:  90% 99/110 [00:44<00:04,  2.21it/s]\u001b[A\n","Iteration:  91% 100/110 [00:45<00:04,  2.22it/s]\u001b[A\n","Iteration:  92% 101/110 [00:45<00:04,  2.21it/s]\u001b[A\n","Iteration:  93% 102/110 [00:46<00:03,  2.21it/s]\u001b[A\n","Iteration:  94% 103/110 [00:46<00:03,  2.21it/s]\u001b[A\n","Iteration:  95% 104/110 [00:46<00:02,  2.21it/s]\u001b[A\n","Iteration:  95% 105/110 [00:47<00:02,  2.21it/s]\u001b[A\n","Iteration:  96% 106/110 [00:47<00:01,  2.21it/s]\u001b[A\n","Iteration:  97% 107/110 [00:48<00:01,  2.21it/s]\u001b[A\n","Iteration:  98% 108/110 [00:48<00:00,  2.21it/s]\u001b[A\n","Iteration:  99% 109/110 [00:49<00:00,  2.21it/s]\u001b[A\n","Iteration: 100% 110/110 [00:49<00:00,  2.21it/s]\n","Epoch: 100% 10/10 [08:16<00:00, 49.63s/it]\n","10/16/2020 08:55:47 - INFO - __main__ -    global_step = 1100, average loss = 0.7020824713293802\n","10/16/2020 08:55:47 - INFO - __main__ -   Saving model checkpoint to model-xlmroberta-e10-regresion\n","10/16/2020 08:55:47 - INFO - transformers.configuration_utils -   Configuration saved in model-xlmroberta-e10-regresion/config.json\n","10/16/2020 08:55:52 - INFO - transformers.modeling_utils -   Model weights saved in model-xlmroberta-e10-regresion/pytorch_model.bin\n","10/16/2020 08:55:53 - INFO - transformers.configuration_utils -   loading configuration file model-xlmroberta-e10-regresion/config.json\n","10/16/2020 08:55:53 - INFO - transformers.configuration_utils -   Model config XLMRobertaConfig {\n","  \"_num_labels\": 5,\n","  \"architectures\": [\n","    \"XLMRobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": 2,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"1\",\n","    \"1\": \"2\",\n","    \"2\": \"3\",\n","    \"3\": \"4\",\n","    \"4\": \"5\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"1\": 0,\n","    \"2\": 1,\n","    \"3\": 2,\n","    \"4\": 3,\n","    \"5\": 4\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 514,\n","  \"min_length\": 0,\n","  \"model_type\": \"xlm-roberta\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 1,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 250002\n","}\n","\n","10/16/2020 08:55:53 - INFO - transformers.tokenization_utils -   Model name 'model-xlmroberta-e10-regresion' not found in model shortcut name list (xlm-roberta-base, xlm-roberta-large, xlm-roberta-large-finetuned-conll02-dutch, xlm-roberta-large-finetuned-conll02-spanish, xlm-roberta-large-finetuned-conll03-english, xlm-roberta-large-finetuned-conll03-german). Assuming 'model-xlmroberta-e10-regresion' is a path, a model identifier, or url to a directory containing tokenizer files.\n","10/16/2020 08:55:53 - INFO - transformers.tokenization_utils -   Didn't find file model-xlmroberta-e10-regresion/added_tokens.json. We won't load it.\n","10/16/2020 08:55:53 - INFO - transformers.tokenization_utils -   loading file model-xlmroberta-e10-regresion/sentencepiece.bpe.model\n","10/16/2020 08:55:53 - INFO - transformers.tokenization_utils -   loading file None\n","10/16/2020 08:55:53 - INFO - transformers.tokenization_utils -   loading file model-xlmroberta-e10-regresion/special_tokens_map.json\n","10/16/2020 08:55:53 - INFO - transformers.tokenization_utils -   loading file model-xlmroberta-e10-regresion/tokenizer_config.json\n","10/16/2020 08:55:53 - INFO - __main__ -   Evaluate the following checkpoints: ['model-xlmroberta-e10-regresion']\n","10/16/2020 08:55:53 - INFO - transformers.configuration_utils -   loading configuration file model-xlmroberta-e10-regresion/config.json\n","10/16/2020 08:55:53 - INFO - transformers.configuration_utils -   Model config XLMRobertaConfig {\n","  \"_num_labels\": 5,\n","  \"architectures\": [\n","    \"XLMRobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": 2,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"1\",\n","    \"1\": \"2\",\n","    \"2\": \"3\",\n","    \"3\": \"4\",\n","    \"4\": \"5\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"1\": 0,\n","    \"2\": 1,\n","    \"3\": 2,\n","    \"4\": 3,\n","    \"5\": 4\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 514,\n","  \"min_length\": 0,\n","  \"model_type\": \"xlm-roberta\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 1,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 250002\n","}\n","\n","10/16/2020 08:55:53 - INFO - transformers.modeling_utils -   loading weights file model-xlmroberta-e10-regresion/pytorch_model.bin\n","10/16/2020 08:56:05 - INFO - __main__ -   Creating features from dataset file at /content/gdrive/My Drive/pythoncode/experiments/regresion\n","100% 180/180 [00:00<00:00, 14359.68it/s]\n","10/16/2020 08:56:06 - INFO - __main__ -   Saving features into cached file /content/gdrive/My Drive/pythoncode/experiments/regresion/cached_dev_xlm-roberta-base_128\n","10/16/2020 08:56:06 - INFO - __main__ -   ***** Running evaluation  on  dev set*****\n","10/16/2020 08:56:06 - INFO - __main__ -     Num examples = 180\n","10/16/2020 08:56:06 - INFO - __main__ -     Batch size = 8\n","Evaluating: 100% 23/23 [00:01<00:00, 14.76it/s]\n","10/16/2020 08:56:07 - INFO - __main__ -   ***** Eval results  on dev set*****\n","10/16/2020 08:56:07 - INFO - __main__ -     f1 = 0.37777777777777777\n","10/16/2020 08:56:07 - INFO - __main__ -     loss = 2.811426081087278\n","10/16/2020 08:56:07 - INFO - __main__ -     precision = 0.37777777777777777\n","10/16/2020 08:56:07 - INFO - __main__ -     recall = 0.37777777777777777\n","10/16/2020 08:56:07 - INFO - __main__ -     report =\n","               precision    recall  f1-score   support\n","\n","           1     0.7083    0.4722    0.5667        36\n","           2     0.3509    0.5556    0.4301        36\n","           3     0.2857    0.1111    0.1600        36\n","           4     0.2769    0.5000    0.3564        36\n","           5     0.4500    0.2500    0.3214        36\n","\n","    accuracy                         0.3778       180\n","   macro avg     0.4144    0.3778    0.3669       180\n","weighted avg     0.4144    0.3778    0.3669       180\n","\n","10/16/2020 08:56:07 - INFO - transformers.configuration_utils -   loading configuration file model-xlmroberta-e10-regresion/config.json\n","10/16/2020 08:56:07 - INFO - transformers.configuration_utils -   Model config XLMRobertaConfig {\n","  \"_num_labels\": 5,\n","  \"architectures\": [\n","    \"XLMRobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": 2,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"1\",\n","    \"1\": \"2\",\n","    \"2\": \"3\",\n","    \"3\": \"4\",\n","    \"4\": \"5\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"1\": 0,\n","    \"2\": 1,\n","    \"3\": 2,\n","    \"4\": 3,\n","    \"5\": 4\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 514,\n","  \"min_length\": 0,\n","  \"model_type\": \"xlm-roberta\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 1,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 250002\n","}\n","\n","10/16/2020 08:56:07 - INFO - transformers.tokenization_utils -   Model name 'model-xlmroberta-e10-regresion' not found in model shortcut name list (xlm-roberta-base, xlm-roberta-large, xlm-roberta-large-finetuned-conll02-dutch, xlm-roberta-large-finetuned-conll02-spanish, xlm-roberta-large-finetuned-conll03-english, xlm-roberta-large-finetuned-conll03-german). Assuming 'model-xlmroberta-e10-regresion' is a path, a model identifier, or url to a directory containing tokenizer files.\n","10/16/2020 08:56:07 - INFO - transformers.tokenization_utils -   Didn't find file model-xlmroberta-e10-regresion/added_tokens.json. We won't load it.\n","10/16/2020 08:56:07 - INFO - transformers.tokenization_utils -   loading file model-xlmroberta-e10-regresion/sentencepiece.bpe.model\n","10/16/2020 08:56:07 - INFO - transformers.tokenization_utils -   loading file None\n","10/16/2020 08:56:07 - INFO - transformers.tokenization_utils -   loading file model-xlmroberta-e10-regresion/special_tokens_map.json\n","10/16/2020 08:56:07 - INFO - transformers.tokenization_utils -   loading file model-xlmroberta-e10-regresion/tokenizer_config.json\n","10/16/2020 08:56:08 - INFO - transformers.configuration_utils -   loading configuration file model-xlmroberta-e10-regresion/config.json\n","10/16/2020 08:56:08 - INFO - transformers.configuration_utils -   Model config XLMRobertaConfig {\n","  \"_num_labels\": 5,\n","  \"architectures\": [\n","    \"XLMRobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": 2,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"1\",\n","    \"1\": \"2\",\n","    \"2\": \"3\",\n","    \"3\": \"4\",\n","    \"4\": \"5\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"1\": 0,\n","    \"2\": 1,\n","    \"3\": 2,\n","    \"4\": 3,\n","    \"5\": 4\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 514,\n","  \"min_length\": 0,\n","  \"model_type\": \"xlm-roberta\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 1,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 250002\n","}\n","\n","10/16/2020 08:56:08 - INFO - transformers.modeling_utils -   loading weights file model-xlmroberta-e10-regresion/pytorch_model.bin\n","10/16/2020 08:56:28 - INFO - __main__ -   Creating features from dataset file at /content/gdrive/My Drive/pythoncode/experiments/regresion\n","100% 360/360 [00:00<00:00, 4031.79it/s]\n","10/16/2020 08:56:29 - INFO - __main__ -   Saving features into cached file /content/gdrive/My Drive/pythoncode/experiments/regresion/cached_test_xlm-roberta-base_128\n","10/16/2020 08:56:29 - INFO - __main__ -   ***** Running evaluation  on  test set*****\n","10/16/2020 08:56:29 - INFO - __main__ -     Num examples = 360\n","10/16/2020 08:56:29 - INFO - __main__ -     Batch size = 8\n","Evaluating: 100% 45/45 [00:03<00:00, 14.29it/s]\n","10/16/2020 08:56:32 - INFO - __main__ -   ***** Eval results  on test set*****\n","10/16/2020 08:56:32 - INFO - __main__ -     f1 = 0.5333333333333333\n","10/16/2020 08:56:32 - INFO - __main__ -     loss = 2.0178420729107325\n","10/16/2020 08:56:32 - INFO - __main__ -     precision = 0.5333333333333333\n","10/16/2020 08:56:32 - INFO - __main__ -     recall = 0.5333333333333333\n","10/16/2020 08:56:32 - INFO - __main__ -     report =\n","               precision    recall  f1-score   support\n","\n","           1     0.7000    0.4861    0.5738        72\n","           2     0.4766    0.7083    0.5698        72\n","           3     0.7447    0.4861    0.5882        72\n","           4     0.4262    0.7222    0.5361        72\n","           5     0.5588    0.2639    0.3585        72\n","\n","    accuracy                         0.5333       360\n","   macro avg     0.5813    0.5333    0.5253       360\n","weighted avg     0.5813    0.5333    0.5253       360\n","\n"],"name":"stdout"}]}]}