{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7009,
     "status": "ok",
     "timestamp": 1604587584440,
     "user": {
      "displayName": "Nui Nui",
      "photoUrl": "",
      "userId": "04667784782263367512"
     },
     "user_tz": -60
    },
    "id": "-M5w6GAmP5yR",
    "outputId": "0862d74a-7693-49b5-a1be-4a18fccee25e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'transformers'...\n",
      "remote: Enumerating objects: 63, done.\u001b[K\n",
      "remote: Counting objects: 100% (63/63), done.\u001b[K\n",
      "remote: Compressing objects: 100% (41/41), done.\u001b[K\n",
      "remote: Total 49541 (delta 26), reused 30 (delta 17), pack-reused 49478\u001b[K\n",
      "Receiving objects: 100% (49541/49541), 36.75 MiB | 27.43 MiB/s, done.\n",
      "Resolving deltas: 100% (34569/34569), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/huggingface/transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15683,
     "status": "ok",
     "timestamp": 1604587602766,
     "user": {
      "displayName": "Nui Nui",
      "photoUrl": "",
      "userId": "04667784782263367512"
     },
     "user_tz": -60
    },
    "id": "cDbv-2a8P8t8",
    "outputId": "823542db-2926-4018-f61b-01780b1c5383"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==2.7.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/37/ba/dda44bbf35b071441635708a3dd568a5ca6bf29f77389f7c7c6818ae9498/transformers-2.7.0-py3-none-any.whl (544kB)\n",
      "\r",
      "\u001b[K     |▋                               | 10kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |█▏                              | 20kB 2.9MB/s eta 0:00:01\r",
      "\u001b[K     |█▉                              | 30kB 3.7MB/s eta 0:00:01\r",
      "\u001b[K     |██▍                             | 40kB 4.1MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 51kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |███▋                            | 61kB 3.8MB/s eta 0:00:01\r",
      "\u001b[K     |████▏                           | 71kB 4.1MB/s eta 0:00:01\r",
      "\u001b[K     |████▉                           | 81kB 4.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████▍                          | 92kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 102kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████▋                         | 112kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████▏                        | 122kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████▉                        | 133kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████▍                       | 143kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 153kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▋                      | 163kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▎                     | 174kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▉                     | 184kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▍                    | 194kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████████                    | 204kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▋                   | 215kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▎                  | 225kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▉                  | 235kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▍                 | 245kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████                 | 256kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▋                | 266kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▎               | 276kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▉               | 286kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▌              | 296kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████              | 307kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▋             | 317kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▎            | 327kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▉            | 337kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▌           | 348kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████           | 358kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▋          | 368kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▎         | 378kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▉         | 389kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▌        | 399kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████        | 409kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▊       | 419kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▎      | 430kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▉      | 440kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▌     | 450kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████     | 460kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▊    | 471kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▎   | 481kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▉   | 491kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▌  | 501kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████  | 512kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▊ | 522kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▎| 532kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 542kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 552kB 4.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.7.0) (3.0.12)\n",
      "Collecting boto3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/56/7a7f901084210f4f12ea4c57f6265e4e690147ffaac6f68fb0a826403919/boto3-1.16.11-py2.py3-none-any.whl (129kB)\n",
      "\u001b[K     |████████████████████████████████| 133kB 19.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.7.0) (2.23.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.7.0) (1.18.5)\n",
      "Collecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1MB 19.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==2.7.0) (0.7)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.7.0) (2019.12.20)\n",
      "Collecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
      "\u001b[K     |████████████████████████████████| 890kB 31.1MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==2.7.0) (4.41.1)\n",
      "Collecting tokenizers==0.5.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
      "\u001b[K     |████████████████████████████████| 3.7MB 51.7MB/s \n",
      "\u001b[?25hCollecting botocore<1.20.0,>=1.19.11\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cf/b9/869df2dca1a9b874cf6c826a56bd2c7ff97770d66103876f99ec77b2c86d/botocore-1.19.11-py2.py3-none-any.whl (6.7MB)\n",
      "\u001b[K     |████████████████████████████████| 6.7MB 41.6MB/s \n",
      "\u001b[?25hCollecting s3transfer<0.4.0,>=0.3.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 479kB/s \n",
      "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
      "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.7.0) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.7.0) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.7.0) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.7.0) (3.0.4)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.7.0) (1.15.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.7.0) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.7.0) (0.17.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.20.0,>=1.19.11->boto3->transformers==2.7.0) (2.8.1)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=c9470116b6faccbf280a216639d423f08d766802eb726bf87923731b01df1dca\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
      "Successfully built sacremoses\n",
      "\u001b[31mERROR: botocore 1.19.11 has requirement urllib3<1.26,>=1.25.4; python_version != \"3.4\", but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
      "Installing collected packages: jmespath, botocore, s3transfer, boto3, sentencepiece, sacremoses, tokenizers, transformers\n",
      "Successfully installed boto3-1.16.11 botocore-1.19.11 jmespath-0.10.0 s3transfer-0.3.3 sacremoses-0.0.43 sentencepiece-0.1.94 tokenizers-0.5.2 transformers-2.7.0\n",
      "Collecting seqeval\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 2.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from seqeval) (1.18.5)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.6/dist-packages (from seqeval) (0.22.2.post1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->seqeval) (0.17.0)\n",
      "Building wheels for collected packages: seqeval\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for seqeval: filename=seqeval-1.2.2-cp36-none-any.whl size=16171 sha256=669939d7688f9b1d9b49de1f589b5969737c7b4535ba063321d1630e5c1751c4\n",
      "  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f\n",
      "Successfully built seqeval\n",
      "Installing collected packages: seqeval\n",
      "Successfully installed seqeval-1.2.2\n"
     ]
    }
   ],
   "source": [
    "#!pip install --upgrade transformers\n",
    "!pip install transformers==2.7.0\n",
    "!pip install seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24566,
     "status": "ok",
     "timestamp": 1604587634928,
     "user": {
      "displayName": "Nui Nui",
      "photoUrl": "",
      "userId": "04667784782263367512"
     },
     "user_tz": -60
    },
    "id": "Oak92WfdLVMi",
    "outputId": "c44f9183-51b2-4d41-bbc0-bc1a7cf06d6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-h67jYZHQoT8"
   },
   "outputs": [],
   "source": [
    "!python /content/gdrive/My\\ Drive/pythoncode/utils_classification.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 496699,
     "status": "ok",
     "timestamp": 1604588981624,
     "user": {
      "displayName": "Nui Nui",
      "photoUrl": "",
      "userId": "04667784782263367512"
     },
     "user_tz": -60
    },
    "id": "AlcARRskNcO5",
    "outputId": "58a9a930-ac40-46b7-8c68-3c76342a16b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-05 15:01:28.232476: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "11/05/2020 15:01:30 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
      "11/05/2020 15:01:30 - INFO - filelock -   Lock 140049216351592 acquired on /root/.cache/torch/transformers/762ddd751172e9d3229e5da17a459eee6c0dfdc237c718944d0b1a85f06c7e1e.2b0f807393c56e8861a31cd67d2fc0b45d71d9735dd47dd66afb650f90b6d2a8.lock\n",
      "11/05/2020 15:01:30 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpomp_tsuj\n",
      "Downloading: 100% 512/512 [00:00<00:00, 484kB/s]\n",
      "11/05/2020 15:01:31 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-config.json in cache at /root/.cache/torch/transformers/762ddd751172e9d3229e5da17a459eee6c0dfdc237c718944d0b1a85f06c7e1e.2b0f807393c56e8861a31cd67d2fc0b45d71d9735dd47dd66afb650f90b6d2a8\n",
      "11/05/2020 15:01:31 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/762ddd751172e9d3229e5da17a459eee6c0dfdc237c718944d0b1a85f06c7e1e.2b0f807393c56e8861a31cd67d2fc0b45d71d9735dd47dd66afb650f90b6d2a8\n",
      "11/05/2020 15:01:31 - INFO - filelock -   Lock 140049216351592 released on /root/.cache/torch/transformers/762ddd751172e9d3229e5da17a459eee6c0dfdc237c718944d0b1a85f06c7e1e.2b0f807393c56e8861a31cd67d2fc0b45d71d9735dd47dd66afb650f90b6d2a8.lock\n",
      "11/05/2020 15:01:31 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-config.json from cache at /root/.cache/torch/transformers/762ddd751172e9d3229e5da17a459eee6c0dfdc237c718944d0b1a85f06c7e1e.2b0f807393c56e8861a31cd67d2fc0b45d71d9735dd47dd66afb650f90b6d2a8\n",
      "11/05/2020 15:01:31 - INFO - transformers.configuration_utils -   Model config XLMRobertaConfig {\n",
      "  \"_num_labels\": 2,\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "11/05/2020 15:01:31 - INFO - __main__ -   Tokenizer arguments: {'do_lower_case': False}\n",
      "11/05/2020 15:01:31 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-config.json from cache at /root/.cache/torch/transformers/762ddd751172e9d3229e5da17a459eee6c0dfdc237c718944d0b1a85f06c7e1e.2b0f807393c56e8861a31cd67d2fc0b45d71d9735dd47dd66afb650f90b6d2a8\n",
      "11/05/2020 15:01:31 - INFO - transformers.configuration_utils -   Model config XLMRobertaConfig {\n",
      "  \"_num_labels\": 2,\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "11/05/2020 15:01:31 - INFO - filelock -   Lock 140049216350920 acquired on /root/.cache/torch/transformers/0c370616ddfc06067c0634160f749c2cf9d8da2c50e03a2617ce5841c8df3b1d.309f0c29486cffc28e1e40a2ab0ac8f500c203fe080b95f820aa9cb58e5b84ed.lock\n",
      "11/05/2020 15:01:31 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-sentencepiece.bpe.model not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpr7d40j8e\n",
      "Downloading: 100% 5.07M/5.07M [00:00<00:00, 8.72MB/s]\n",
      "11/05/2020 15:01:32 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-sentencepiece.bpe.model in cache at /root/.cache/torch/transformers/0c370616ddfc06067c0634160f749c2cf9d8da2c50e03a2617ce5841c8df3b1d.309f0c29486cffc28e1e40a2ab0ac8f500c203fe080b95f820aa9cb58e5b84ed\n",
      "11/05/2020 15:01:32 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/0c370616ddfc06067c0634160f749c2cf9d8da2c50e03a2617ce5841c8df3b1d.309f0c29486cffc28e1e40a2ab0ac8f500c203fe080b95f820aa9cb58e5b84ed\n",
      "11/05/2020 15:01:32 - INFO - filelock -   Lock 140049216350920 released on /root/.cache/torch/transformers/0c370616ddfc06067c0634160f749c2cf9d8da2c50e03a2617ce5841c8df3b1d.309f0c29486cffc28e1e40a2ab0ac8f500c203fe080b95f820aa9cb58e5b84ed.lock\n",
      "11/05/2020 15:01:32 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-sentencepiece.bpe.model from cache at /root/.cache/torch/transformers/0c370616ddfc06067c0634160f749c2cf9d8da2c50e03a2617ce5841c8df3b1d.309f0c29486cffc28e1e40a2ab0ac8f500c203fe080b95f820aa9cb58e5b84ed\n",
      "tokenizer object loaded:  <transformers.tokenization_xlm_roberta.XLMRobertaTokenizer object at 0x7f5fbfcaaef0>\n",
      "11/05/2020 15:01:33 - INFO - filelock -   Lock 140049216317648 acquired on /root/.cache/torch/transformers/f80a708b21cc9b248e8af5a630ad9f887326bbaf0098b9f354427b2463d55346.aeeaca90954dc20ffa2909de722cfbfd455c5bb16d480c5bdf6d7fe79c68c267.lock\n",
      "11/05/2020 15:01:33 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp_6spsra3\n",
      "Downloading: 100% 1.12G/1.12G [00:26<00:00, 42.5MB/s]\n",
      "11/05/2020 15:02:00 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-pytorch_model.bin in cache at /root/.cache/torch/transformers/f80a708b21cc9b248e8af5a630ad9f887326bbaf0098b9f354427b2463d55346.aeeaca90954dc20ffa2909de722cfbfd455c5bb16d480c5bdf6d7fe79c68c267\n",
      "11/05/2020 15:02:00 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/f80a708b21cc9b248e8af5a630ad9f887326bbaf0098b9f354427b2463d55346.aeeaca90954dc20ffa2909de722cfbfd455c5bb16d480c5bdf6d7fe79c68c267\n",
      "11/05/2020 15:02:00 - INFO - filelock -   Lock 140049216317648 released on /root/.cache/torch/transformers/f80a708b21cc9b248e8af5a630ad9f887326bbaf0098b9f354427b2463d55346.aeeaca90954dc20ffa2909de722cfbfd455c5bb16d480c5bdf6d7fe79c68c267.lock\n",
      "11/05/2020 15:02:00 - INFO - transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-pytorch_model.bin from cache at /root/.cache/torch/transformers/f80a708b21cc9b248e8af5a630ad9f887326bbaf0098b9f354427b2463d55346.aeeaca90954dc20ffa2909de722cfbfd455c5bb16d480c5bdf6d7fe79c68c267\n",
      "11/05/2020 15:02:14 - INFO - transformers.modeling_utils -   Weights of XLMRobertaForSequenceClassification not initialized from pretrained model: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "11/05/2020 15:02:14 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in XLMRobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "11/05/2020 15:02:28 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir='/content/gdrive/My Drive/pythoncode/experiments/corpus_manual_1_5stars', device=device(type='cuda'), do_eval=True, do_lower_case=False, do_predict=True, do_train=True, eval_all_checkpoints=False, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, keep_accents=None, labels='/content/gdrive/My Drive/pythoncode/experiments/corpus_manual_1_5stars/labels.txt', learning_rate=5e-05, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='xlm-roberta-base', model_type='xlm-roberta', n_gpu=1, no_cuda=False, num_train_epochs=10.0, output_dir='model-xlmroberta-e10-manual', overwrite_cache=True, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=16, save_steps=0, seed=1, server_ip='', server_port='', strip_accents=None, tokenizer_name='', use_fast=None, warmup_steps=0, weight_decay=0.0)\n",
      "11/05/2020 15:02:28 - INFO - __main__ -   Creating features from dataset file at /content/gdrive/My Drive/pythoncode/experiments/corpus_manual_1_5stars\n",
      "100% 1460/1460 [00:00<00:00, 12876.68it/s]\n",
      "11/05/2020 15:02:29 - INFO - __main__ -   Saving features into cached file /content/gdrive/My Drive/pythoncode/experiments/corpus_manual_1_5stars/cached_train_xlm-roberta-base_128\n",
      "11/05/2020 15:02:29 - INFO - __main__ -   ***** Running training *****\n",
      "11/05/2020 15:02:29 - INFO - __main__ -     Num examples = 1460\n",
      "11/05/2020 15:02:29 - INFO - __main__ -     Num Epochs = 10\n",
      "11/05/2020 15:02:29 - INFO - __main__ -     Instantaneous batch size per GPU = 16\n",
      "11/05/2020 15:02:29 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "11/05/2020 15:02:29 - INFO - __main__ -     Gradient Accumulation steps = 1\n",
      "11/05/2020 15:02:29 - INFO - __main__ -     Total optimization steps = 920\n",
      "Epoch:   0% 0/10 [00:00<?, ?it/s]\n",
      "Iteration:   0% 0/92 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.6/dist-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n",
      "\n",
      "Iteration:   1% 1/92 [00:00<00:49,  1.85it/s]\u001b[A\n",
      "Iteration:   2% 2/92 [00:00<00:44,  2.01it/s]\u001b[A\n",
      "Iteration:   3% 3/92 [00:01<00:41,  2.12it/s]\u001b[A\n",
      "Iteration:   4% 4/92 [00:01<00:39,  2.21it/s]\u001b[A\n",
      "Iteration:   5% 5/92 [00:02<00:38,  2.28it/s]\u001b[A\n",
      "Iteration:   7% 6/92 [00:02<00:37,  2.32it/s]\u001b[A\n",
      "Iteration:   8% 7/92 [00:02<00:36,  2.35it/s]\u001b[A\n",
      "Iteration:   9% 8/92 [00:03<00:35,  2.38it/s]\u001b[A\n",
      "Iteration:  10% 9/92 [00:03<00:34,  2.40it/s]\u001b[A\n",
      "Iteration:  11% 10/92 [00:04<00:34,  2.40it/s]\u001b[A\n",
      "Iteration:  12% 11/92 [00:04<00:33,  2.41it/s]\u001b[A\n",
      "Iteration:  13% 12/92 [00:05<00:32,  2.43it/s]\u001b[A\n",
      "Iteration:  14% 13/92 [00:05<00:32,  2.40it/s]\u001b[A\n",
      "Iteration:  15% 14/92 [00:05<00:32,  2.40it/s]\u001b[A\n",
      "Iteration:  16% 15/92 [00:06<00:31,  2.42it/s]\u001b[A\n",
      "Iteration:  17% 16/92 [00:06<00:31,  2.42it/s]\u001b[A\n",
      "Iteration:  18% 17/92 [00:07<00:31,  2.42it/s]\u001b[A\n",
      "Iteration:  20% 18/92 [00:07<00:30,  2.43it/s]\u001b[A\n",
      "Iteration:  21% 19/92 [00:07<00:30,  2.42it/s]\u001b[A\n",
      "Iteration:  22% 20/92 [00:08<00:29,  2.42it/s]\u001b[A\n",
      "Iteration:  23% 21/92 [00:08<00:29,  2.43it/s]\u001b[A\n",
      "Iteration:  24% 22/92 [00:09<00:28,  2.42it/s]\u001b[A\n",
      "Iteration:  25% 23/92 [00:09<00:28,  2.42it/s]\u001b[A\n",
      "Iteration:  26% 24/92 [00:10<00:28,  2.42it/s]\u001b[A\n",
      "Iteration:  27% 25/92 [00:10<00:27,  2.42it/s]\u001b[A\n",
      "Iteration:  28% 26/92 [00:10<00:27,  2.42it/s]\u001b[A\n",
      "Iteration:  29% 27/92 [00:11<00:26,  2.41it/s]\u001b[A\n",
      "Iteration:  30% 28/92 [00:11<00:26,  2.41it/s]\u001b[A\n",
      "Iteration:  32% 29/92 [00:12<00:26,  2.41it/s]\u001b[A\n",
      "Iteration:  33% 30/92 [00:12<00:25,  2.41it/s]\u001b[A\n",
      "Iteration:  34% 31/92 [00:12<00:25,  2.41it/s]\u001b[A\n",
      "Iteration:  35% 32/92 [00:13<00:24,  2.41it/s]\u001b[A\n",
      "Iteration:  36% 33/92 [00:13<00:24,  2.41it/s]\u001b[A\n",
      "Iteration:  37% 34/92 [00:14<00:24,  2.42it/s]\u001b[A\n",
      "Iteration:  38% 35/92 [00:14<00:23,  2.42it/s]\u001b[A\n",
      "Iteration:  39% 36/92 [00:14<00:23,  2.41it/s]\u001b[A\n",
      "Iteration:  40% 37/92 [00:15<00:22,  2.40it/s]\u001b[A\n",
      "Iteration:  41% 38/92 [00:15<00:22,  2.41it/s]\u001b[A\n",
      "Iteration:  42% 39/92 [00:16<00:22,  2.40it/s]\u001b[A\n",
      "Iteration:  43% 40/92 [00:16<00:21,  2.41it/s]\u001b[A\n",
      "Iteration:  45% 41/92 [00:17<00:21,  2.41it/s]\u001b[A\n",
      "Iteration:  46% 42/92 [00:17<00:20,  2.41it/s]\u001b[A\n",
      "Iteration:  47% 43/92 [00:17<00:20,  2.40it/s]\u001b[A\n",
      "Iteration:  48% 44/92 [00:18<00:19,  2.41it/s]\u001b[A\n",
      "Iteration:  49% 45/92 [00:18<00:19,  2.41it/s]\u001b[A\n",
      "Iteration:  50% 46/92 [00:19<00:19,  2.41it/s]\u001b[A\n",
      "Iteration:  51% 47/92 [00:19<00:18,  2.41it/s]\u001b[A\n",
      "Iteration:  52% 48/92 [00:19<00:18,  2.41it/s]\u001b[A\n",
      "Iteration:  53% 49/92 [00:20<00:17,  2.40it/s]\u001b[A\n",
      "Iteration:  54% 50/92 [00:20<00:17,  2.40it/s]\u001b[A\n",
      "Iteration:  55% 51/92 [00:21<00:17,  2.40it/s]\u001b[A\n",
      "Iteration:  57% 52/92 [00:21<00:16,  2.40it/s]\u001b[A\n",
      "Iteration:  58% 53/92 [00:22<00:16,  2.41it/s]\u001b[A\n",
      "Iteration:  59% 54/92 [00:22<00:15,  2.41it/s]\u001b[A\n",
      "Iteration:  60% 55/92 [00:22<00:15,  2.40it/s]\u001b[A\n",
      "Iteration:  61% 56/92 [00:23<00:15,  2.40it/s]\u001b[A\n",
      "Iteration:  62% 57/92 [00:23<00:14,  2.39it/s]\u001b[A\n",
      "Iteration:  63% 58/92 [00:24<00:14,  2.40it/s]\u001b[A\n",
      "Iteration:  64% 59/92 [00:24<00:13,  2.40it/s]\u001b[A\n",
      "Iteration:  65% 60/92 [00:24<00:13,  2.39it/s]\u001b[A\n",
      "Iteration:  66% 61/92 [00:25<00:12,  2.39it/s]\u001b[A\n",
      "Iteration:  67% 62/92 [00:25<00:12,  2.39it/s]\u001b[A\n",
      "Iteration:  68% 63/92 [00:26<00:12,  2.39it/s]\u001b[A\n",
      "Iteration:  70% 64/92 [00:26<00:11,  2.39it/s]\u001b[A\n",
      "Iteration:  71% 65/92 [00:27<00:11,  2.39it/s]\u001b[A\n",
      "Iteration:  72% 66/92 [00:27<00:10,  2.39it/s]\u001b[A\n",
      "Iteration:  73% 67/92 [00:27<00:10,  2.39it/s]\u001b[A\n",
      "Iteration:  74% 68/92 [00:28<00:10,  2.40it/s]\u001b[A\n",
      "Iteration:  75% 69/92 [00:28<00:09,  2.39it/s]\u001b[A\n",
      "Iteration:  76% 70/92 [00:29<00:09,  2.38it/s]\u001b[A\n",
      "Iteration:  77% 71/92 [00:29<00:08,  2.39it/s]\u001b[A\n",
      "Iteration:  78% 72/92 [00:29<00:08,  2.38it/s]\u001b[A\n",
      "Iteration:  79% 73/92 [00:30<00:07,  2.38it/s]\u001b[A\n",
      "Iteration:  80% 74/92 [00:30<00:07,  2.38it/s]\u001b[A\n",
      "Iteration:  82% 75/92 [00:31<00:07,  2.38it/s]\u001b[A\n",
      "Iteration:  83% 76/92 [00:31<00:06,  2.38it/s]\u001b[A\n",
      "Iteration:  84% 77/92 [00:32<00:06,  2.37it/s]\u001b[A\n",
      "Iteration:  85% 78/92 [00:32<00:05,  2.38it/s]\u001b[A\n",
      "Iteration:  86% 79/92 [00:32<00:05,  2.38it/s]\u001b[A\n",
      "Iteration:  87% 80/92 [00:33<00:05,  2.38it/s]\u001b[A\n",
      "Iteration:  88% 81/92 [00:33<00:04,  2.39it/s]\u001b[A\n",
      "Iteration:  89% 82/92 [00:34<00:04,  2.39it/s]\u001b[A\n",
      "Iteration:  90% 83/92 [00:34<00:03,  2.39it/s]\u001b[A\n",
      "Iteration:  91% 84/92 [00:35<00:03,  2.38it/s]\u001b[A\n",
      "Iteration:  92% 85/92 [00:35<00:02,  2.40it/s]\u001b[A\n",
      "Iteration:  93% 86/92 [00:35<00:02,  2.41it/s]\u001b[A\n",
      "Iteration:  95% 87/92 [00:36<00:02,  2.38it/s]\u001b[A\n",
      "Iteration:  96% 88/92 [00:36<00:01,  2.39it/s]\u001b[A\n",
      "Iteration:  97% 89/92 [00:37<00:01,  2.38it/s]\u001b[A\n",
      "Iteration:  98% 90/92 [00:37<00:00,  2.37it/s]\u001b[A\n",
      "Iteration:  99% 91/92 [00:37<00:00,  2.40it/s]\u001b[A\n",
      "Iteration: 100% 92/92 [00:38<00:00,  2.41it/s]\n",
      "Epoch:  10% 1/10 [00:38<05:43, 38.15s/it]\n",
      "Iteration:   0% 0/92 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   1% 1/92 [00:00<00:37,  2.40it/s]\u001b[A\n",
      "Iteration:   2% 2/92 [00:00<00:37,  2.39it/s]\u001b[A\n",
      "Iteration:   3% 3/92 [00:01<00:37,  2.38it/s]\u001b[A\n",
      "Iteration:   4% 4/92 [00:01<00:37,  2.37it/s]\u001b[A\n",
      "Iteration:   5% 5/92 [00:02<00:36,  2.36it/s]\u001b[A\n",
      "Iteration:   7% 6/92 [00:02<00:36,  2.36it/s]\u001b[A\n",
      "Iteration:   8% 7/92 [00:02<00:35,  2.37it/s]\u001b[A\n",
      "Iteration:   9% 8/92 [00:03<00:35,  2.36it/s]\u001b[A\n",
      "Iteration:  10% 9/92 [00:03<00:35,  2.36it/s]\u001b[A\n",
      "Iteration:  11% 10/92 [00:04<00:34,  2.37it/s]\u001b[A\n",
      "Iteration:  12% 11/92 [00:04<00:34,  2.37it/s]\u001b[A\n",
      "Iteration:  13% 12/92 [00:05<00:33,  2.37it/s]\u001b[A\n",
      "Iteration:  14% 13/92 [00:05<00:33,  2.39it/s]\u001b[A\n",
      "Iteration:  15% 14/92 [00:05<00:32,  2.38it/s]\u001b[A\n",
      "Iteration:  16% 15/92 [00:06<00:32,  2.37it/s]\u001b[A\n",
      "Iteration:  17% 16/92 [00:06<00:32,  2.37it/s]\u001b[A\n",
      "Iteration:  18% 17/92 [00:07<00:31,  2.37it/s]\u001b[A\n",
      "Iteration:  20% 18/92 [00:07<00:31,  2.38it/s]\u001b[A\n",
      "Iteration:  21% 19/92 [00:08<00:30,  2.37it/s]\u001b[A\n",
      "Iteration:  22% 20/92 [00:08<00:30,  2.37it/s]\u001b[A\n",
      "Iteration:  23% 21/92 [00:08<00:29,  2.38it/s]\u001b[A\n",
      "Iteration:  24% 22/92 [00:09<00:29,  2.37it/s]\u001b[A\n",
      "Iteration:  25% 23/92 [00:09<00:29,  2.37it/s]\u001b[A\n",
      "Iteration:  26% 24/92 [00:10<00:28,  2.36it/s]\u001b[A\n",
      "Iteration:  27% 25/92 [00:10<00:28,  2.37it/s]\u001b[A\n",
      "Iteration:  28% 26/92 [00:10<00:27,  2.37it/s]\u001b[A\n",
      "Iteration:  29% 27/92 [00:11<00:27,  2.36it/s]\u001b[A\n",
      "Iteration:  30% 28/92 [00:11<00:27,  2.37it/s]\u001b[A\n",
      "Iteration:  32% 29/92 [00:12<00:26,  2.37it/s]\u001b[A\n",
      "Iteration:  33% 30/92 [00:12<00:26,  2.36it/s]\u001b[A\n",
      "Iteration:  34% 31/92 [00:13<00:25,  2.35it/s]\u001b[A\n",
      "Iteration:  35% 32/92 [00:13<00:25,  2.36it/s]\u001b[A\n",
      "Iteration:  36% 33/92 [00:13<00:25,  2.35it/s]\u001b[A\n",
      "Iteration:  37% 34/92 [00:14<00:24,  2.35it/s]\u001b[A\n",
      "Iteration:  38% 35/92 [00:14<00:24,  2.35it/s]\u001b[A\n",
      "Iteration:  39% 36/92 [00:15<00:23,  2.35it/s]\u001b[A\n",
      "Iteration:  40% 37/92 [00:15<00:23,  2.35it/s]\u001b[A\n",
      "Iteration:  41% 38/92 [00:16<00:23,  2.35it/s]\u001b[A\n",
      "Iteration:  42% 39/92 [00:16<00:22,  2.35it/s]\u001b[A\n",
      "Iteration:  43% 40/92 [00:16<00:22,  2.35it/s]\u001b[A\n",
      "Iteration:  45% 41/92 [00:17<00:21,  2.35it/s]\u001b[A\n",
      "Iteration:  46% 42/92 [00:17<00:21,  2.35it/s]\u001b[A\n",
      "Iteration:  47% 43/92 [00:18<00:20,  2.35it/s]\u001b[A\n",
      "Iteration:  48% 44/92 [00:18<00:20,  2.35it/s]\u001b[A\n",
      "Iteration:  49% 45/92 [00:19<00:19,  2.35it/s]\u001b[A\n",
      "Iteration:  50% 46/92 [00:19<00:19,  2.35it/s]\u001b[A\n",
      "Iteration:  51% 47/92 [00:19<00:19,  2.35it/s]\u001b[A\n",
      "Iteration:  52% 48/92 [00:20<00:18,  2.35it/s]\u001b[A\n",
      "Iteration:  53% 49/92 [00:20<00:18,  2.35it/s]\u001b[A\n",
      "Iteration:  54% 50/92 [00:21<00:17,  2.35it/s]\u001b[A\n",
      "Iteration:  55% 51/92 [00:21<00:17,  2.35it/s]\u001b[A\n",
      "Iteration:  57% 52/92 [00:22<00:17,  2.35it/s]\u001b[A\n",
      "Iteration:  58% 53/92 [00:22<00:16,  2.34it/s]\u001b[A\n",
      "Iteration:  59% 54/92 [00:22<00:16,  2.36it/s]\u001b[A\n",
      "Iteration:  60% 55/92 [00:23<00:15,  2.35it/s]\u001b[A\n",
      "Iteration:  61% 56/92 [00:23<00:15,  2.34it/s]\u001b[A\n",
      "Iteration:  62% 57/92 [00:24<00:14,  2.35it/s]\u001b[A\n",
      "Iteration:  63% 58/92 [00:24<00:14,  2.36it/s]\u001b[A\n",
      "Iteration:  64% 59/92 [00:25<00:13,  2.37it/s]\u001b[A\n",
      "Iteration:  65% 60/92 [00:25<00:13,  2.36it/s]\u001b[A\n",
      "Iteration:  66% 61/92 [00:25<00:13,  2.35it/s]\u001b[A\n",
      "Iteration:  67% 62/92 [00:26<00:12,  2.37it/s]\u001b[A\n",
      "Iteration:  68% 63/92 [00:26<00:12,  2.35it/s]\u001b[A\n",
      "Iteration:  70% 64/92 [00:27<00:11,  2.34it/s]\u001b[A\n",
      "Iteration:  71% 65/92 [00:27<00:11,  2.36it/s]\u001b[A\n",
      "Iteration:  72% 66/92 [00:27<00:11,  2.33it/s]\u001b[A\n",
      "Iteration:  73% 67/92 [00:28<00:10,  2.34it/s]\u001b[A\n",
      "Iteration:  74% 68/92 [00:28<00:10,  2.33it/s]\u001b[A\n",
      "Iteration:  75% 69/92 [00:29<00:09,  2.33it/s]\u001b[A\n",
      "Iteration:  76% 70/92 [00:29<00:09,  2.34it/s]\u001b[A\n",
      "Iteration:  77% 71/92 [00:30<00:09,  2.33it/s]\u001b[A\n",
      "Iteration:  78% 72/92 [00:30<00:08,  2.33it/s]\u001b[A\n",
      "Iteration:  79% 73/92 [00:30<00:08,  2.33it/s]\u001b[A\n",
      "Iteration:  80% 74/92 [00:31<00:07,  2.32it/s]\u001b[A\n",
      "Iteration:  82% 75/92 [00:31<00:07,  2.34it/s]\u001b[A\n",
      "Iteration:  83% 76/92 [00:32<00:06,  2.34it/s]\u001b[A\n",
      "Iteration:  84% 77/92 [00:32<00:06,  2.34it/s]\u001b[A\n",
      "Iteration:  85% 78/92 [00:33<00:06,  2.30it/s]\u001b[A\n",
      "Iteration:  86% 79/92 [00:33<00:05,  2.30it/s]\u001b[A\n",
      "Iteration:  87% 80/92 [00:34<00:05,  2.31it/s]\u001b[A\n",
      "Iteration:  88% 81/92 [00:34<00:04,  2.31it/s]\u001b[A\n",
      "Iteration:  89% 82/92 [00:34<00:04,  2.31it/s]\u001b[A\n",
      "Iteration:  90% 83/92 [00:35<00:03,  2.31it/s]\u001b[A\n",
      "Iteration:  91% 84/92 [00:35<00:03,  2.31it/s]\u001b[A\n",
      "Iteration:  92% 85/92 [00:36<00:03,  2.33it/s]\u001b[A\n",
      "Iteration:  93% 86/92 [00:36<00:02,  2.33it/s]\u001b[A\n",
      "Iteration:  95% 87/92 [00:37<00:02,  2.33it/s]\u001b[A\n",
      "Iteration:  96% 88/92 [00:37<00:01,  2.32it/s]\u001b[A\n",
      "Iteration:  97% 89/92 [00:37<00:01,  2.31it/s]\u001b[A\n",
      "Iteration:  98% 90/92 [00:38<00:00,  2.31it/s]\u001b[A\n",
      "Iteration:  99% 91/92 [00:38<00:00,  2.31it/s]\u001b[A\n",
      "Iteration: 100% 92/92 [00:38<00:00,  2.36it/s]\n",
      "Epoch:  20% 2/10 [01:17<05:07, 38.39s/it]\n",
      "Iteration:   0% 0/92 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   1% 1/92 [00:00<00:40,  2.24it/s]\u001b[A\n",
      "Iteration:   2% 2/92 [00:00<00:39,  2.26it/s]\u001b[A\n",
      "Iteration:   3% 3/92 [00:01<00:39,  2.28it/s]\u001b[A\n",
      "Iteration:   4% 4/92 [00:01<00:38,  2.28it/s]\u001b[A\n",
      "Iteration:   5% 5/92 [00:02<00:37,  2.30it/s]\u001b[A\n",
      "Iteration:   7% 6/92 [00:02<00:37,  2.30it/s]\u001b[A\n",
      "Iteration:   8% 7/92 [00:03<00:36,  2.30it/s]\u001b[A\n",
      "Iteration:   9% 8/92 [00:03<00:36,  2.31it/s]\u001b[A\n",
      "Iteration:  10% 9/92 [00:03<00:35,  2.31it/s]\u001b[A\n",
      "Iteration:  11% 10/92 [00:04<00:35,  2.30it/s]\u001b[A\n",
      "Iteration:  12% 11/92 [00:04<00:34,  2.31it/s]\u001b[A\n",
      "Iteration:  13% 12/92 [00:05<00:34,  2.31it/s]\u001b[A\n",
      "Iteration:  14% 13/92 [00:05<00:34,  2.32it/s]\u001b[A\n",
      "Iteration:  15% 14/92 [00:06<00:33,  2.32it/s]\u001b[A\n",
      "Iteration:  16% 15/92 [00:06<00:33,  2.31it/s]\u001b[A\n",
      "Iteration:  17% 16/92 [00:06<00:32,  2.31it/s]\u001b[A\n",
      "Iteration:  18% 17/92 [00:07<00:32,  2.30it/s]\u001b[A\n",
      "Iteration:  20% 18/92 [00:07<00:31,  2.31it/s]\u001b[A\n",
      "Iteration:  21% 19/92 [00:08<00:31,  2.30it/s]\u001b[A\n",
      "Iteration:  22% 20/92 [00:08<00:31,  2.31it/s]\u001b[A\n",
      "Iteration:  23% 21/92 [00:09<00:30,  2.30it/s]\u001b[A\n",
      "Iteration:  24% 22/92 [00:09<00:30,  2.31it/s]\u001b[A\n",
      "Iteration:  25% 23/92 [00:09<00:29,  2.30it/s]\u001b[A\n",
      "Iteration:  26% 24/92 [00:10<00:29,  2.30it/s]\u001b[A\n",
      "Iteration:  27% 25/92 [00:10<00:29,  2.29it/s]\u001b[A\n",
      "Iteration:  28% 26/92 [00:11<00:28,  2.29it/s]\u001b[A\n",
      "Iteration:  29% 27/92 [00:11<00:28,  2.29it/s]\u001b[A\n",
      "Iteration:  30% 28/92 [00:12<00:27,  2.29it/s]\u001b[A\n",
      "Iteration:  32% 29/92 [00:12<00:27,  2.30it/s]\u001b[A\n",
      "Iteration:  33% 30/92 [00:13<00:26,  2.30it/s]\u001b[A\n",
      "Iteration:  34% 31/92 [00:13<00:26,  2.29it/s]\u001b[A\n",
      "Iteration:  35% 32/92 [00:13<00:26,  2.30it/s]\u001b[A\n",
      "Iteration:  36% 33/92 [00:14<00:25,  2.29it/s]\u001b[A\n",
      "Iteration:  37% 34/92 [00:14<00:25,  2.29it/s]\u001b[A\n",
      "Iteration:  38% 35/92 [00:15<00:24,  2.29it/s]\u001b[A\n",
      "Iteration:  39% 36/92 [00:15<00:24,  2.28it/s]\u001b[A\n",
      "Iteration:  40% 37/92 [00:16<00:24,  2.28it/s]\u001b[A\n",
      "Iteration:  41% 38/92 [00:16<00:23,  2.27it/s]\u001b[A\n",
      "Iteration:  42% 39/92 [00:16<00:23,  2.27it/s]\u001b[A\n",
      "Iteration:  43% 40/92 [00:17<00:22,  2.29it/s]\u001b[A\n",
      "Iteration:  45% 41/92 [00:17<00:22,  2.29it/s]\u001b[A\n",
      "Iteration:  46% 42/92 [00:18<00:21,  2.29it/s]\u001b[A\n",
      "Iteration:  47% 43/92 [00:18<00:21,  2.28it/s]\u001b[A\n",
      "Iteration:  48% 44/92 [00:19<00:20,  2.29it/s]\u001b[A\n",
      "Iteration:  49% 45/92 [00:19<00:20,  2.30it/s]\u001b[A\n",
      "Iteration:  50% 46/92 [00:20<00:20,  2.30it/s]\u001b[A\n",
      "Iteration:  51% 47/92 [00:20<00:19,  2.30it/s]\u001b[A\n",
      "Iteration:  52% 48/92 [00:20<00:19,  2.29it/s]\u001b[A\n",
      "Iteration:  53% 49/92 [00:21<00:18,  2.28it/s]\u001b[A\n",
      "Iteration:  54% 50/92 [00:21<00:18,  2.26it/s]\u001b[A\n",
      "Iteration:  55% 51/92 [00:22<00:17,  2.28it/s]\u001b[A\n",
      "Iteration:  57% 52/92 [00:22<00:17,  2.29it/s]\u001b[A\n",
      "Iteration:  58% 53/92 [00:23<00:16,  2.29it/s]\u001b[A\n",
      "Iteration:  59% 54/92 [00:23<00:16,  2.28it/s]\u001b[A\n",
      "Iteration:  60% 55/92 [00:23<00:16,  2.27it/s]\u001b[A\n",
      "Iteration:  61% 56/92 [00:24<00:15,  2.28it/s]\u001b[A\n",
      "Iteration:  62% 57/92 [00:24<00:15,  2.29it/s]\u001b[A\n",
      "Iteration:  63% 58/92 [00:25<00:14,  2.29it/s]\u001b[A\n",
      "Iteration:  64% 59/92 [00:25<00:14,  2.28it/s]\u001b[A\n",
      "Iteration:  65% 60/92 [00:26<00:13,  2.29it/s]\u001b[A\n",
      "Iteration:  66% 61/92 [00:26<00:13,  2.29it/s]\u001b[A\n",
      "Iteration:  67% 62/92 [00:27<00:13,  2.29it/s]\u001b[A\n",
      "Iteration:  68% 63/92 [00:27<00:12,  2.29it/s]\u001b[A\n",
      "Iteration:  70% 64/92 [00:27<00:12,  2.30it/s]\u001b[A\n",
      "Iteration:  71% 65/92 [00:28<00:11,  2.29it/s]\u001b[A\n",
      "Iteration:  72% 66/92 [00:28<00:11,  2.30it/s]\u001b[A\n",
      "Iteration:  73% 67/92 [00:29<00:10,  2.30it/s]\u001b[A\n",
      "Iteration:  74% 68/92 [00:29<00:10,  2.28it/s]\u001b[A\n",
      "Iteration:  75% 69/92 [00:30<00:10,  2.29it/s]\u001b[A\n",
      "Iteration:  76% 70/92 [00:30<00:09,  2.28it/s]\u001b[A\n",
      "Iteration:  77% 71/92 [00:30<00:09,  2.28it/s]\u001b[A\n",
      "Iteration:  78% 72/92 [00:31<00:08,  2.29it/s]\u001b[A\n",
      "Iteration:  79% 73/92 [00:31<00:08,  2.30it/s]\u001b[A\n",
      "Iteration:  80% 74/92 [00:32<00:07,  2.30it/s]\u001b[A\n",
      "Iteration:  82% 75/92 [00:32<00:07,  2.30it/s]\u001b[A\n",
      "Iteration:  83% 76/92 [00:33<00:06,  2.31it/s]\u001b[A\n",
      "Iteration:  84% 77/92 [00:33<00:06,  2.29it/s]\u001b[A\n",
      "Iteration:  85% 78/92 [00:33<00:06,  2.30it/s]\u001b[A\n",
      "Iteration:  86% 79/92 [00:34<00:05,  2.29it/s]\u001b[A\n",
      "Iteration:  87% 80/92 [00:34<00:05,  2.30it/s]\u001b[A\n",
      "Iteration:  88% 81/92 [00:35<00:04,  2.29it/s]\u001b[A\n",
      "Iteration:  89% 82/92 [00:35<00:04,  2.29it/s]\u001b[A\n",
      "Iteration:  90% 83/92 [00:36<00:03,  2.30it/s]\u001b[A\n",
      "Iteration:  91% 84/92 [00:36<00:03,  2.31it/s]\u001b[A\n",
      "Iteration:  92% 85/92 [00:37<00:03,  2.29it/s]\u001b[A\n",
      "Iteration:  93% 86/92 [00:37<00:02,  2.29it/s]\u001b[A\n",
      "Iteration:  95% 87/92 [00:37<00:02,  2.29it/s]\u001b[A\n",
      "Iteration:  96% 88/92 [00:38<00:01,  2.30it/s]\u001b[A\n",
      "Iteration:  97% 89/92 [00:38<00:01,  2.29it/s]\u001b[A\n",
      "Iteration:  98% 90/92 [00:39<00:00,  2.29it/s]\u001b[A\n",
      "Iteration:  99% 91/92 [00:39<00:00,  2.30it/s]\u001b[A\n",
      "Iteration: 100% 92/92 [00:39<00:00,  2.31it/s]\n",
      "Epoch:  30% 3/10 [01:56<04:31, 38.83s/it]\n",
      "Iteration:   0% 0/92 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   1% 1/92 [00:00<00:40,  2.25it/s]\u001b[A\n",
      "Iteration:   2% 2/92 [00:00<00:39,  2.26it/s]\u001b[A\n",
      "Iteration:   3% 3/92 [00:01<00:38,  2.29it/s]\u001b[A\n",
      "Iteration:   4% 4/92 [00:01<00:38,  2.31it/s]\u001b[A\n",
      "Iteration:   5% 5/92 [00:02<00:37,  2.32it/s]\u001b[A\n",
      "Iteration:   7% 6/92 [00:02<00:36,  2.33it/s]\u001b[A\n",
      "Iteration:   8% 7/92 [00:03<00:36,  2.32it/s]\u001b[A\n",
      "Iteration:   9% 8/92 [00:03<00:36,  2.32it/s]\u001b[A\n",
      "Iteration:  10% 9/92 [00:03<00:35,  2.31it/s]\u001b[A\n",
      "Iteration:  11% 10/92 [00:04<00:35,  2.32it/s]\u001b[A\n",
      "Iteration:  12% 11/92 [00:04<00:35,  2.31it/s]\u001b[A\n",
      "Iteration:  13% 12/92 [00:05<00:34,  2.32it/s]\u001b[A\n",
      "Iteration:  14% 13/92 [00:05<00:33,  2.33it/s]\u001b[A\n",
      "Iteration:  15% 14/92 [00:06<00:33,  2.33it/s]\u001b[A\n",
      "Iteration:  16% 15/92 [00:06<00:33,  2.32it/s]\u001b[A\n",
      "Iteration:  17% 16/92 [00:06<00:32,  2.33it/s]\u001b[A\n",
      "Iteration:  18% 17/92 [00:07<00:32,  2.32it/s]\u001b[A\n",
      "Iteration:  20% 18/92 [00:07<00:31,  2.32it/s]\u001b[A\n",
      "Iteration:  21% 19/92 [00:08<00:31,  2.32it/s]\u001b[A\n",
      "Iteration:  22% 20/92 [00:08<00:30,  2.33it/s]\u001b[A\n",
      "Iteration:  23% 21/92 [00:09<00:30,  2.33it/s]\u001b[A\n",
      "Iteration:  24% 22/92 [00:09<00:30,  2.32it/s]\u001b[A\n",
      "Iteration:  25% 23/92 [00:09<00:29,  2.31it/s]\u001b[A\n",
      "Iteration:  26% 24/92 [00:10<00:29,  2.32it/s]\u001b[A\n",
      "Iteration:  27% 25/92 [00:10<00:28,  2.33it/s]\u001b[A\n",
      "Iteration:  28% 26/92 [00:11<00:28,  2.34it/s]\u001b[A\n",
      "Iteration:  29% 27/92 [00:11<00:28,  2.32it/s]\u001b[A\n",
      "Iteration:  30% 28/92 [00:12<00:27,  2.31it/s]\u001b[A\n",
      "Iteration:  32% 29/92 [00:12<00:27,  2.30it/s]\u001b[A\n",
      "Iteration:  33% 30/92 [00:12<00:26,  2.30it/s]\u001b[A\n",
      "Iteration:  34% 31/92 [00:13<00:26,  2.32it/s]\u001b[A\n",
      "Iteration:  35% 32/92 [00:13<00:25,  2.32it/s]\u001b[A\n",
      "Iteration:  36% 33/92 [00:14<00:25,  2.31it/s]\u001b[A\n",
      "Iteration:  37% 34/92 [00:14<00:25,  2.31it/s]\u001b[A\n",
      "Iteration:  38% 35/92 [00:15<00:24,  2.30it/s]\u001b[A\n",
      "Iteration:  39% 36/92 [00:15<00:24,  2.30it/s]\u001b[A\n",
      "Iteration:  40% 37/92 [00:15<00:23,  2.32it/s]\u001b[A\n",
      "Iteration:  41% 38/92 [00:16<00:23,  2.31it/s]\u001b[A\n",
      "Iteration:  42% 39/92 [00:16<00:22,  2.31it/s]\u001b[A\n",
      "Iteration:  43% 40/92 [00:17<00:22,  2.32it/s]\u001b[A\n",
      "Iteration:  45% 41/92 [00:17<00:22,  2.31it/s]\u001b[A\n",
      "Iteration:  46% 42/92 [00:18<00:21,  2.31it/s]\u001b[A\n",
      "Iteration:  47% 43/92 [00:18<00:21,  2.31it/s]\u001b[A\n",
      "Iteration:  48% 44/92 [00:18<00:20,  2.31it/s]\u001b[A\n",
      "Iteration:  49% 45/92 [00:19<00:20,  2.32it/s]\u001b[A\n",
      "Iteration:  50% 46/92 [00:19<00:19,  2.32it/s]\u001b[A\n",
      "Iteration:  51% 47/92 [00:20<00:19,  2.33it/s]\u001b[A\n",
      "Iteration:  52% 48/92 [00:20<00:18,  2.34it/s]\u001b[A\n",
      "Iteration:  53% 49/92 [00:21<00:18,  2.32it/s]\u001b[A\n",
      "Iteration:  54% 50/92 [00:21<00:18,  2.33it/s]\u001b[A\n",
      "Iteration:  55% 51/92 [00:21<00:17,  2.33it/s]\u001b[A\n",
      "Iteration:  57% 52/92 [00:22<00:17,  2.32it/s]\u001b[A\n",
      "Iteration:  58% 53/92 [00:22<00:16,  2.33it/s]\u001b[A\n",
      "Iteration:  59% 54/92 [00:23<00:16,  2.34it/s]\u001b[A\n",
      "Iteration:  60% 55/92 [00:23<00:15,  2.33it/s]\u001b[A\n",
      "Iteration:  61% 56/92 [00:24<00:15,  2.33it/s]\u001b[A\n",
      "Iteration:  62% 57/92 [00:24<00:15,  2.32it/s]\u001b[A\n",
      "Iteration:  63% 58/92 [00:25<00:14,  2.32it/s]\u001b[A\n",
      "Iteration:  64% 59/92 [00:25<00:14,  2.31it/s]\u001b[A\n",
      "Iteration:  65% 60/92 [00:25<00:13,  2.32it/s]\u001b[A\n",
      "Iteration:  66% 61/92 [00:26<00:13,  2.32it/s]\u001b[A\n",
      "Iteration:  67% 62/92 [00:26<00:12,  2.32it/s]\u001b[A\n",
      "Iteration:  68% 63/92 [00:27<00:12,  2.33it/s]\u001b[A\n",
      "Iteration:  70% 64/92 [00:27<00:11,  2.34it/s]\u001b[A\n",
      "Iteration:  71% 65/92 [00:28<00:11,  2.32it/s]\u001b[A\n",
      "Iteration:  72% 66/92 [00:28<00:11,  2.33it/s]\u001b[A\n",
      "Iteration:  73% 67/92 [00:28<00:10,  2.32it/s]\u001b[A\n",
      "Iteration:  74% 68/92 [00:29<00:10,  2.33it/s]\u001b[A\n",
      "Iteration:  75% 69/92 [00:29<00:09,  2.32it/s]\u001b[A\n",
      "Iteration:  76% 70/92 [00:30<00:09,  2.32it/s]\u001b[A\n",
      "Iteration:  77% 71/92 [00:30<00:09,  2.33it/s]\u001b[A\n",
      "Iteration:  78% 72/92 [00:31<00:08,  2.33it/s]\u001b[A\n",
      "Iteration:  79% 73/92 [00:31<00:08,  2.33it/s]\u001b[A\n",
      "Iteration:  80% 74/92 [00:31<00:07,  2.34it/s]\u001b[A\n",
      "Iteration:  82% 75/92 [00:32<00:07,  2.33it/s]\u001b[A\n",
      "Iteration:  83% 76/92 [00:32<00:06,  2.32it/s]\u001b[A\n",
      "Iteration:  84% 77/92 [00:33<00:06,  2.33it/s]\u001b[A\n",
      "Iteration:  85% 78/92 [00:33<00:06,  2.32it/s]\u001b[A\n",
      "Iteration:  86% 79/92 [00:34<00:05,  2.33it/s]\u001b[A\n",
      "Iteration:  87% 80/92 [00:34<00:05,  2.33it/s]\u001b[A\n",
      "Iteration:  88% 81/92 [00:34<00:04,  2.32it/s]\u001b[A\n",
      "Iteration:  89% 82/92 [00:35<00:04,  2.33it/s]\u001b[A\n",
      "Iteration:  90% 83/92 [00:35<00:03,  2.34it/s]\u001b[A\n",
      "Iteration:  91% 84/92 [00:36<00:03,  2.32it/s]\u001b[A\n",
      "Iteration:  92% 85/92 [00:36<00:03,  2.32it/s]\u001b[A\n",
      "Iteration:  93% 86/92 [00:37<00:02,  2.32it/s]\u001b[A\n",
      "Iteration:  95% 87/92 [00:37<00:02,  2.33it/s]\u001b[A\n",
      "Iteration:  96% 88/92 [00:37<00:01,  2.32it/s]\u001b[A\n",
      "Iteration:  97% 89/92 [00:38<00:01,  2.32it/s]\u001b[A\n",
      "Iteration:  98% 90/92 [00:38<00:00,  2.33it/s]\u001b[A\n",
      "Iteration:  99% 91/92 [00:39<00:00,  2.33it/s]\u001b[A\n",
      "Iteration: 100% 92/92 [00:39<00:00,  2.34it/s]\n",
      "Epoch:  40% 4/10 [02:36<03:53, 39.00s/it]\n",
      "Iteration:   0% 0/92 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   1% 1/92 [00:00<00:39,  2.32it/s]\u001b[A\n",
      "Iteration:   2% 2/92 [00:00<00:38,  2.33it/s]\u001b[A\n",
      "Iteration:   3% 3/92 [00:01<00:38,  2.34it/s]\u001b[A\n",
      "Iteration:   4% 4/92 [00:01<00:37,  2.34it/s]\u001b[A\n",
      "Iteration:   5% 5/92 [00:02<00:37,  2.32it/s]\u001b[A\n",
      "Iteration:   7% 6/92 [00:02<00:37,  2.32it/s]\u001b[A\n",
      "Iteration:   8% 7/92 [00:03<00:36,  2.33it/s]\u001b[A\n",
      "Iteration:   9% 8/92 [00:03<00:36,  2.32it/s]\u001b[A\n",
      "Iteration:  10% 9/92 [00:03<00:35,  2.31it/s]\u001b[A\n",
      "Iteration:  11% 10/92 [00:04<00:35,  2.32it/s]\u001b[A\n",
      "Iteration:  12% 11/92 [00:04<00:34,  2.32it/s]\u001b[A\n",
      "Iteration:  13% 12/92 [00:05<00:34,  2.33it/s]\u001b[A\n",
      "Iteration:  14% 13/92 [00:05<00:33,  2.34it/s]\u001b[A\n",
      "Iteration:  15% 14/92 [00:06<00:33,  2.34it/s]\u001b[A\n",
      "Iteration:  16% 15/92 [00:06<00:32,  2.34it/s]\u001b[A\n",
      "Iteration:  17% 16/92 [00:06<00:32,  2.32it/s]\u001b[A\n",
      "Iteration:  18% 17/92 [00:07<00:32,  2.33it/s]\u001b[A\n",
      "Iteration:  20% 18/92 [00:07<00:31,  2.31it/s]\u001b[A\n",
      "Iteration:  21% 19/92 [00:08<00:31,  2.32it/s]\u001b[A\n",
      "Iteration:  22% 20/92 [00:08<00:30,  2.33it/s]\u001b[A\n",
      "Iteration:  23% 21/92 [00:09<00:30,  2.33it/s]\u001b[A\n",
      "Iteration:  24% 22/92 [00:09<00:30,  2.32it/s]\u001b[A\n",
      "Iteration:  25% 23/92 [00:09<00:29,  2.31it/s]\u001b[A\n",
      "Iteration:  26% 24/92 [00:10<00:29,  2.32it/s]\u001b[A\n",
      "Iteration:  27% 25/92 [00:10<00:28,  2.33it/s]\u001b[A\n",
      "Iteration:  28% 26/92 [00:11<00:28,  2.33it/s]\u001b[A\n",
      "Iteration:  29% 27/92 [00:11<00:27,  2.32it/s]\u001b[A\n",
      "Iteration:  30% 28/92 [00:12<00:27,  2.32it/s]\u001b[A\n",
      "Iteration:  32% 29/92 [00:12<00:27,  2.33it/s]\u001b[A\n",
      "Iteration:  33% 30/92 [00:12<00:26,  2.31it/s]\u001b[A\n",
      "Iteration:  34% 31/92 [00:13<00:26,  2.32it/s]\u001b[A\n",
      "Iteration:  35% 32/92 [00:13<00:25,  2.32it/s]\u001b[A\n",
      "Iteration:  36% 33/92 [00:14<00:25,  2.31it/s]\u001b[A\n",
      "Iteration:  37% 34/92 [00:14<00:25,  2.30it/s]\u001b[A\n",
      "Iteration:  38% 35/92 [00:15<00:24,  2.30it/s]\u001b[A\n",
      "Iteration:  39% 36/92 [00:15<00:24,  2.31it/s]\u001b[A\n",
      "Iteration:  40% 37/92 [00:15<00:23,  2.31it/s]\u001b[A\n",
      "Iteration:  41% 38/92 [00:16<00:23,  2.31it/s]\u001b[A\n",
      "Iteration:  42% 39/92 [00:16<00:22,  2.32it/s]\u001b[A\n",
      "Iteration:  43% 40/92 [00:17<00:22,  2.32it/s]\u001b[A\n",
      "Iteration:  45% 41/92 [00:17<00:21,  2.33it/s]\u001b[A\n",
      "Iteration:  46% 42/92 [00:18<00:21,  2.32it/s]\u001b[A\n",
      "Iteration:  47% 43/92 [00:18<00:21,  2.31it/s]\u001b[A\n",
      "Iteration:  48% 44/92 [00:18<00:20,  2.31it/s]\u001b[A\n",
      "Iteration:  49% 45/92 [00:19<00:20,  2.30it/s]\u001b[A\n",
      "Iteration:  50% 46/92 [00:19<00:20,  2.29it/s]\u001b[A\n",
      "Iteration:  51% 47/92 [00:20<00:19,  2.29it/s]\u001b[A\n",
      "Iteration:  52% 48/92 [00:20<00:19,  2.29it/s]\u001b[A\n",
      "Iteration:  53% 49/92 [00:21<00:18,  2.29it/s]\u001b[A\n",
      "Iteration:  54% 50/92 [00:21<00:18,  2.31it/s]\u001b[A\n",
      "Iteration:  55% 51/92 [00:22<00:17,  2.31it/s]\u001b[A\n",
      "Iteration:  57% 52/92 [00:22<00:17,  2.32it/s]\u001b[A\n",
      "Iteration:  58% 53/92 [00:22<00:16,  2.31it/s]\u001b[A\n",
      "Iteration:  59% 54/92 [00:23<00:16,  2.31it/s]\u001b[A\n",
      "Iteration:  60% 55/92 [00:23<00:15,  2.32it/s]\u001b[A\n",
      "Iteration:  61% 56/92 [00:24<00:15,  2.33it/s]\u001b[A\n",
      "Iteration:  62% 57/92 [00:24<00:15,  2.33it/s]\u001b[A\n",
      "Iteration:  63% 58/92 [00:25<00:14,  2.32it/s]\u001b[A\n",
      "Iteration:  64% 59/92 [00:25<00:14,  2.32it/s]\u001b[A\n",
      "Iteration:  65% 60/92 [00:25<00:13,  2.31it/s]\u001b[A\n",
      "Iteration:  66% 61/92 [00:26<00:13,  2.31it/s]\u001b[A\n",
      "Iteration:  67% 62/92 [00:26<00:12,  2.32it/s]\u001b[A\n",
      "Iteration:  68% 63/92 [00:27<00:12,  2.32it/s]\u001b[A\n",
      "Iteration:  70% 64/92 [00:27<00:12,  2.32it/s]\u001b[A\n",
      "Iteration:  71% 65/92 [00:28<00:11,  2.32it/s]\u001b[A\n",
      "Iteration:  72% 66/92 [00:28<00:11,  2.32it/s]\u001b[A\n",
      "Iteration:  73% 67/92 [00:28<00:10,  2.32it/s]\u001b[A\n",
      "Iteration:  74% 68/92 [00:29<00:10,  2.32it/s]\u001b[A\n",
      "Iteration:  75% 69/92 [00:29<00:09,  2.32it/s]\u001b[A\n",
      "Iteration:  76% 70/92 [00:30<00:09,  2.33it/s]\u001b[A\n",
      "Iteration:  77% 71/92 [00:30<00:08,  2.33it/s]\u001b[A\n",
      "Iteration:  78% 72/92 [00:31<00:08,  2.34it/s]\u001b[A\n",
      "Iteration:  79% 73/92 [00:31<00:08,  2.33it/s]\u001b[A\n",
      "Iteration:  80% 74/92 [00:31<00:07,  2.33it/s]\u001b[A\n",
      "Iteration:  82% 75/92 [00:32<00:07,  2.33it/s]\u001b[A\n",
      "Iteration:  83% 76/92 [00:32<00:06,  2.33it/s]\u001b[A\n",
      "Iteration:  84% 77/92 [00:33<00:06,  2.33it/s]\u001b[A\n",
      "Iteration:  85% 78/92 [00:33<00:06,  2.32it/s]\u001b[A\n",
      "Iteration:  86% 79/92 [00:34<00:05,  2.32it/s]\u001b[A\n",
      "Iteration:  87% 80/92 [00:34<00:05,  2.32it/s]\u001b[A\n",
      "Iteration:  88% 81/92 [00:34<00:04,  2.31it/s]\u001b[A\n",
      "Iteration:  89% 82/92 [00:35<00:04,  2.32it/s]\u001b[A\n",
      "Iteration:  90% 83/92 [00:35<00:03,  2.32it/s]\u001b[A\n",
      "Iteration:  91% 84/92 [00:36<00:03,  2.33it/s]\u001b[A\n",
      "Iteration:  92% 85/92 [00:36<00:03,  2.33it/s]\u001b[A\n",
      "Iteration:  93% 86/92 [00:37<00:02,  2.33it/s]\u001b[A\n",
      "Iteration:  95% 87/92 [00:37<00:02,  2.33it/s]\u001b[A\n",
      "Iteration:  96% 88/92 [00:37<00:01,  2.31it/s]\u001b[A\n",
      "Iteration:  97% 89/92 [00:38<00:01,  2.32it/s]\u001b[A\n",
      "Iteration:  98% 90/92 [00:38<00:00,  2.32it/s]\u001b[A\n",
      "Iteration:  99% 91/92 [00:39<00:00,  2.33it/s]\u001b[A\n",
      "Iteration: 100% 92/92 [00:39<00:00,  2.33it/s]\n",
      "Epoch:  50% 5/10 [03:15<03:15, 39.12s/it]\n",
      "Iteration:   0% 0/92 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   1% 1/92 [00:00<00:38,  2.34it/s]\u001b[A\n",
      "Iteration:   2% 2/92 [00:00<00:38,  2.31it/s]\u001b[A\n",
      "Iteration:   3% 3/92 [00:01<00:38,  2.32it/s]\u001b[A\n",
      "Iteration:   4% 4/92 [00:01<00:37,  2.33it/s]\u001b[A\n",
      "Iteration:   5% 5/92 [00:02<00:37,  2.32it/s]\u001b[A\n",
      "Iteration:   7% 6/92 [00:02<00:36,  2.33it/s]\u001b[A\n",
      "Iteration:   8% 7/92 [00:03<00:36,  2.34it/s]\u001b[A\n",
      "Iteration:   9% 8/92 [00:03<00:36,  2.32it/s]\u001b[A\n",
      "Iteration:  10% 9/92 [00:03<00:35,  2.32it/s]\u001b[A\n",
      "Iteration:  11% 10/92 [00:04<00:35,  2.33it/s]\u001b[A\n",
      "Iteration:  12% 11/92 [00:04<00:34,  2.34it/s]\u001b[A\n",
      "Iteration:  13% 12/92 [00:05<00:34,  2.32it/s]\u001b[A\n",
      "Iteration:  14% 13/92 [00:05<00:33,  2.33it/s]\u001b[A\n",
      "Iteration:  15% 14/92 [00:06<00:33,  2.33it/s]\u001b[A\n",
      "Iteration:  16% 15/92 [00:06<00:33,  2.31it/s]\u001b[A\n",
      "Iteration:  17% 16/92 [00:06<00:32,  2.32it/s]\u001b[A\n",
      "Iteration:  18% 17/92 [00:07<00:32,  2.32it/s]\u001b[A\n",
      "Iteration:  20% 18/92 [00:07<00:31,  2.33it/s]\u001b[A\n",
      "Iteration:  21% 19/92 [00:08<00:31,  2.33it/s]\u001b[A\n",
      "Iteration:  22% 20/92 [00:08<00:30,  2.34it/s]\u001b[A\n",
      "Iteration:  23% 21/92 [00:09<00:30,  2.34it/s]\u001b[A\n",
      "Iteration:  24% 22/92 [00:09<00:29,  2.34it/s]\u001b[A\n",
      "Iteration:  25% 23/92 [00:09<00:29,  2.34it/s]\u001b[A\n",
      "Iteration:  26% 24/92 [00:10<00:29,  2.32it/s]\u001b[A\n",
      "Iteration:  27% 25/92 [00:10<00:28,  2.33it/s]\u001b[A\n",
      "Iteration:  28% 26/92 [00:11<00:28,  2.34it/s]\u001b[A\n",
      "Iteration:  29% 27/92 [00:11<00:27,  2.34it/s]\u001b[A\n",
      "Iteration:  30% 28/92 [00:12<00:27,  2.34it/s]\u001b[A\n",
      "Iteration:  32% 29/92 [00:12<00:26,  2.34it/s]\u001b[A\n",
      "Iteration:  33% 30/92 [00:12<00:26,  2.34it/s]\u001b[A\n",
      "Iteration:  34% 31/92 [00:13<00:26,  2.33it/s]\u001b[A\n",
      "Iteration:  35% 32/92 [00:13<00:25,  2.33it/s]\u001b[A\n",
      "Iteration:  36% 33/92 [00:14<00:25,  2.33it/s]\u001b[A\n",
      "Iteration:  37% 34/92 [00:14<00:24,  2.34it/s]\u001b[A\n",
      "Iteration:  38% 35/92 [00:15<00:24,  2.34it/s]\u001b[A\n",
      "Iteration:  39% 36/92 [00:15<00:23,  2.34it/s]\u001b[A\n",
      "Iteration:  40% 37/92 [00:15<00:23,  2.33it/s]\u001b[A\n",
      "Iteration:  41% 38/92 [00:16<00:23,  2.33it/s]\u001b[A\n",
      "Iteration:  42% 39/92 [00:16<00:22,  2.33it/s]\u001b[A/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "\n",
      "Iteration:  43% 40/92 [00:17<00:22,  2.33it/s]\u001b[A\n",
      "Iteration:  45% 41/92 [00:17<00:21,  2.34it/s]\u001b[A\n",
      "Iteration:  46% 42/92 [00:18<00:21,  2.34it/s]\u001b[A\n",
      "Iteration:  47% 43/92 [00:18<00:20,  2.34it/s]\u001b[A\n",
      "Iteration:  48% 44/92 [00:18<00:20,  2.34it/s]\u001b[A\n",
      "Iteration:  49% 45/92 [00:19<00:20,  2.35it/s]\u001b[A\n",
      "Iteration:  50% 46/92 [00:19<00:19,  2.35it/s]\u001b[A\n",
      "Iteration:  51% 47/92 [00:20<00:19,  2.35it/s]\u001b[A\n",
      "Iteration:  52% 48/92 [00:20<00:18,  2.35it/s]\u001b[A\n",
      "Iteration:  53% 49/92 [00:20<00:18,  2.35it/s]\u001b[A\n",
      "Iteration:  54% 50/92 [00:21<00:17,  2.34it/s]\u001b[A\n",
      "Iteration:  55% 51/92 [00:21<00:17,  2.34it/s]\u001b[A\n",
      "Iteration:  57% 52/92 [00:22<00:17,  2.34it/s]\u001b[A\n",
      "Iteration:  58% 53/92 [00:22<00:16,  2.34it/s]\u001b[A\n",
      "Iteration:  59% 54/92 [00:23<00:16,  2.34it/s]\u001b[A\n",
      "Iteration:  60% 55/92 [00:23<00:15,  2.34it/s]\u001b[A\n",
      "Iteration:  61% 56/92 [00:23<00:15,  2.34it/s]\u001b[A\n",
      "Iteration:  62% 57/92 [00:24<00:14,  2.34it/s]\u001b[A\n",
      "Iteration:  63% 58/92 [00:24<00:14,  2.34it/s]\u001b[A\n",
      "Iteration:  64% 59/92 [00:25<00:14,  2.34it/s]\u001b[A\n",
      "Iteration:  65% 60/92 [00:25<00:13,  2.34it/s]\u001b[A\n",
      "Iteration:  66% 61/92 [00:26<00:13,  2.34it/s]\u001b[A\n",
      "Iteration:  67% 62/92 [00:26<00:12,  2.34it/s]\u001b[A\n",
      "Iteration:  68% 63/92 [00:26<00:12,  2.34it/s]\u001b[A\n",
      "Iteration:  70% 64/92 [00:27<00:11,  2.34it/s]\u001b[A\n",
      "Iteration:  71% 65/92 [00:27<00:11,  2.34it/s]\u001b[A\n",
      "Iteration:  72% 66/92 [00:28<00:11,  2.34it/s]\u001b[A\n",
      "Iteration:  73% 67/92 [00:28<00:10,  2.34it/s]\u001b[A\n",
      "Iteration:  74% 68/92 [00:29<00:10,  2.34it/s]\u001b[A\n",
      "Iteration:  75% 69/92 [00:29<00:09,  2.34it/s]\u001b[A\n",
      "Iteration:  76% 70/92 [00:29<00:09,  2.35it/s]\u001b[A\n",
      "Iteration:  77% 71/92 [00:30<00:09,  2.33it/s]\u001b[A\n",
      "Iteration:  78% 72/92 [00:30<00:08,  2.32it/s]\u001b[A\n",
      "Iteration:  79% 73/92 [00:31<00:08,  2.32it/s]\u001b[A\n",
      "Iteration:  80% 74/92 [00:31<00:07,  2.33it/s]\u001b[A\n",
      "Iteration:  82% 75/92 [00:32<00:07,  2.33it/s]\u001b[A\n",
      "Iteration:  83% 76/92 [00:32<00:06,  2.33it/s]\u001b[A\n",
      "Iteration:  84% 77/92 [00:32<00:06,  2.34it/s]\u001b[A\n",
      "Iteration:  85% 78/92 [00:33<00:05,  2.34it/s]\u001b[A\n",
      "Iteration:  86% 79/92 [00:33<00:05,  2.32it/s]\u001b[A\n",
      "Iteration:  87% 80/92 [00:34<00:05,  2.33it/s]\u001b[A\n",
      "Iteration:  88% 81/92 [00:34<00:04,  2.33it/s]\u001b[A\n",
      "Iteration:  89% 82/92 [00:35<00:04,  2.33it/s]\u001b[A\n",
      "Iteration:  90% 83/92 [00:35<00:03,  2.33it/s]\u001b[A\n",
      "Iteration:  91% 84/92 [00:35<00:03,  2.34it/s]\u001b[A\n",
      "Iteration:  92% 85/92 [00:36<00:02,  2.34it/s]\u001b[A\n",
      "Iteration:  93% 86/92 [00:36<00:02,  2.33it/s]\u001b[A\n",
      "Iteration:  95% 87/92 [00:37<00:02,  2.33it/s]\u001b[A\n",
      "Iteration:  96% 88/92 [00:37<00:01,  2.33it/s]\u001b[A\n",
      "Iteration:  97% 89/92 [00:38<00:01,  2.34it/s]\u001b[A\n",
      "Iteration:  98% 90/92 [00:38<00:00,  2.32it/s]\u001b[A\n",
      "Iteration:  99% 91/92 [00:38<00:00,  2.33it/s]\u001b[A\n",
      "Iteration: 100% 92/92 [00:39<00:00,  2.35it/s]\n",
      "Epoch:  60% 6/10 [03:54<02:36, 39.14s/it]\n",
      "Iteration:   0% 0/92 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   1% 1/92 [00:00<00:39,  2.31it/s]\u001b[A\n",
      "Iteration:   2% 2/92 [00:00<00:38,  2.32it/s]\u001b[A\n",
      "Iteration:   3% 3/92 [00:01<00:38,  2.33it/s]\u001b[A\n",
      "Iteration:   4% 4/92 [00:01<00:37,  2.33it/s]\u001b[A\n",
      "Iteration:   5% 5/92 [00:02<00:37,  2.33it/s]\u001b[A\n",
      "Iteration:   7% 6/92 [00:02<00:36,  2.34it/s]\u001b[A\n",
      "Iteration:   8% 7/92 [00:02<00:36,  2.34it/s]\u001b[A\n",
      "Iteration:   9% 8/92 [00:03<00:35,  2.34it/s]\u001b[A\n",
      "Iteration:  10% 9/92 [00:03<00:35,  2.34it/s]\u001b[A\n",
      "Iteration:  11% 10/92 [00:04<00:35,  2.32it/s]\u001b[A\n",
      "Iteration:  12% 11/92 [00:04<00:34,  2.33it/s]\u001b[A\n",
      "Iteration:  13% 12/92 [00:05<00:34,  2.33it/s]\u001b[A\n",
      "Iteration:  14% 13/92 [00:05<00:33,  2.33it/s]\u001b[A\n",
      "Iteration:  15% 14/92 [00:05<00:33,  2.34it/s]\u001b[A\n",
      "Iteration:  16% 15/92 [00:06<00:32,  2.34it/s]\u001b[A\n",
      "Iteration:  17% 16/92 [00:06<00:32,  2.34it/s]\u001b[A\n",
      "Iteration:  18% 17/92 [00:07<00:32,  2.34it/s]\u001b[A\n",
      "Iteration:  20% 18/92 [00:07<00:31,  2.34it/s]\u001b[A\n",
      "Iteration:  21% 19/92 [00:08<00:31,  2.35it/s]\u001b[A\n",
      "Iteration:  22% 20/92 [00:08<00:30,  2.35it/s]\u001b[A\n",
      "Iteration:  23% 21/92 [00:08<00:30,  2.35it/s]\u001b[A\n",
      "Iteration:  24% 22/92 [00:09<00:29,  2.35it/s]\u001b[A\n",
      "Iteration:  25% 23/92 [00:09<00:29,  2.35it/s]\u001b[A\n",
      "Iteration:  26% 24/92 [00:10<00:29,  2.33it/s]\u001b[A\n",
      "Iteration:  27% 25/92 [00:10<00:28,  2.34it/s]\u001b[A\n",
      "Iteration:  28% 26/92 [00:11<00:28,  2.33it/s]\u001b[A\n",
      "Iteration:  29% 27/92 [00:11<00:27,  2.34it/s]\u001b[A\n",
      "Iteration:  30% 28/92 [00:11<00:27,  2.34it/s]\u001b[A\n",
      "Iteration:  32% 29/92 [00:12<00:26,  2.35it/s]\u001b[A\n",
      "Iteration:  33% 30/92 [00:12<00:26,  2.35it/s]\u001b[A\n",
      "Iteration:  34% 31/92 [00:13<00:25,  2.35it/s]\u001b[A\n",
      "Iteration:  35% 32/92 [00:13<00:25,  2.34it/s]\u001b[A\n",
      "Iteration:  36% 33/92 [00:14<00:25,  2.35it/s]\u001b[A\n",
      "Iteration:  37% 34/92 [00:14<00:24,  2.35it/s]\u001b[A\n",
      "Iteration:  38% 35/92 [00:14<00:24,  2.35it/s]\u001b[A\n",
      "Iteration:  39% 36/92 [00:15<00:23,  2.35it/s]\u001b[A\n",
      "Iteration:  40% 37/92 [00:15<00:23,  2.35it/s]\u001b[A\n",
      "Iteration:  41% 38/92 [00:16<00:23,  2.34it/s]\u001b[A\n",
      "Iteration:  42% 39/92 [00:16<00:22,  2.35it/s]\u001b[A\n",
      "Iteration:  43% 40/92 [00:17<00:22,  2.33it/s]\u001b[A\n",
      "Iteration:  45% 41/92 [00:17<00:21,  2.33it/s]\u001b[A\n",
      "Iteration:  46% 42/92 [00:17<00:21,  2.33it/s]\u001b[A\n",
      "Iteration:  47% 43/92 [00:18<00:20,  2.34it/s]\u001b[A\n",
      "Iteration:  48% 44/92 [00:18<00:20,  2.34it/s]\u001b[A\n",
      "Iteration:  49% 45/92 [00:19<00:20,  2.34it/s]\u001b[A\n",
      "Iteration:  50% 46/92 [00:19<00:19,  2.33it/s]\u001b[A\n",
      "Iteration:  51% 47/92 [00:20<00:19,  2.33it/s]\u001b[A\n",
      "Iteration:  52% 48/92 [00:20<00:18,  2.34it/s]\u001b[A\n",
      "Iteration:  53% 49/92 [00:20<00:18,  2.34it/s]\u001b[A\n",
      "Iteration:  54% 50/92 [00:21<00:18,  2.33it/s]\u001b[A\n",
      "Iteration:  55% 51/92 [00:21<00:17,  2.34it/s]\u001b[A\n",
      "Iteration:  57% 52/92 [00:22<00:17,  2.34it/s]\u001b[A\n",
      "Iteration:  58% 53/92 [00:22<00:16,  2.34it/s]\u001b[A\n",
      "Iteration:  59% 54/92 [00:23<00:16,  2.35it/s]\u001b[A\n",
      "Iteration:  60% 55/92 [00:23<00:15,  2.34it/s]\u001b[A\n",
      "Iteration:  61% 56/92 [00:23<00:15,  2.34it/s]\u001b[A\n",
      "Iteration:  62% 57/92 [00:24<00:14,  2.34it/s]\u001b[A\n",
      "Iteration:  63% 58/92 [00:24<00:14,  2.33it/s]\u001b[A\n",
      "Iteration:  64% 59/92 [00:25<00:14,  2.34it/s]\u001b[A\n",
      "Iteration:  65% 60/92 [00:25<00:13,  2.34it/s]\u001b[A\n",
      "Iteration:  66% 61/92 [00:26<00:13,  2.34it/s]\u001b[A\n",
      "Iteration:  67% 62/92 [00:26<00:12,  2.34it/s]\u001b[A\n",
      "Iteration:  68% 63/92 [00:26<00:12,  2.33it/s]\u001b[A\n",
      "Iteration:  70% 64/92 [00:27<00:11,  2.34it/s]\u001b[A\n",
      "Iteration:  71% 65/92 [00:27<00:11,  2.34it/s]\u001b[A\n",
      "Iteration:  72% 66/92 [00:28<00:11,  2.34it/s]\u001b[A\n",
      "Iteration:  73% 67/92 [00:28<00:10,  2.33it/s]\u001b[A\n",
      "Iteration:  74% 68/92 [00:29<00:10,  2.34it/s]\u001b[A\n",
      "Iteration:  75% 69/92 [00:29<00:09,  2.34it/s]\u001b[A\n",
      "Iteration:  76% 70/92 [00:29<00:09,  2.34it/s]\u001b[A\n",
      "Iteration:  77% 71/92 [00:30<00:08,  2.34it/s]\u001b[A\n",
      "Iteration:  78% 72/92 [00:30<00:08,  2.33it/s]\u001b[A\n",
      "Iteration:  79% 73/92 [00:31<00:08,  2.34it/s]\u001b[A\n",
      "Iteration:  80% 74/92 [00:31<00:07,  2.33it/s]\u001b[A\n",
      "Iteration:  82% 75/92 [00:32<00:07,  2.34it/s]\u001b[A\n",
      "Iteration:  83% 76/92 [00:32<00:06,  2.34it/s]\u001b[A\n",
      "Iteration:  84% 77/92 [00:32<00:06,  2.34it/s]\u001b[A\n",
      "Iteration:  85% 78/92 [00:33<00:05,  2.34it/s]\u001b[A\n",
      "Iteration:  86% 79/92 [00:33<00:05,  2.34it/s]\u001b[A\n",
      "Iteration:  87% 80/92 [00:34<00:05,  2.34it/s]\u001b[A\n",
      "Iteration:  88% 81/92 [00:34<00:04,  2.34it/s]\u001b[A\n",
      "Iteration:  89% 82/92 [00:35<00:04,  2.34it/s]\u001b[A\n",
      "Iteration:  90% 83/92 [00:35<00:03,  2.34it/s]\u001b[A\n",
      "Iteration:  91% 84/92 [00:35<00:03,  2.34it/s]\u001b[A\n",
      "Iteration:  92% 85/92 [00:36<00:02,  2.33it/s]\u001b[A\n",
      "Iteration:  93% 86/92 [00:36<00:02,  2.33it/s]\u001b[A\n",
      "Iteration:  95% 87/92 [00:37<00:02,  2.33it/s]\u001b[A\n",
      "Iteration:  96% 88/92 [00:37<00:01,  2.33it/s]\u001b[A\n",
      "Iteration:  97% 89/92 [00:38<00:01,  2.34it/s]\u001b[A\n",
      "Iteration:  98% 90/92 [00:38<00:00,  2.34it/s]\u001b[A\n",
      "Iteration:  99% 91/92 [00:38<00:00,  2.34it/s]\u001b[A\n",
      "Iteration: 100% 92/92 [00:39<00:00,  2.35it/s]\n",
      "Epoch:  70% 7/10 [04:34<01:57, 39.13s/it]\n",
      "Iteration:   0% 0/92 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   1% 1/92 [00:00<00:39,  2.31it/s]\u001b[A\n",
      "Iteration:   2% 2/92 [00:00<00:38,  2.32it/s]\u001b[A\n",
      "Iteration:   3% 3/92 [00:01<00:38,  2.33it/s]\u001b[A\n",
      "Iteration:   4% 4/92 [00:01<00:37,  2.33it/s]\u001b[A\n",
      "Iteration:   5% 5/92 [00:02<00:37,  2.34it/s]\u001b[A\n",
      "Iteration:   7% 6/92 [00:02<00:36,  2.34it/s]\u001b[A\n",
      "Iteration:   8% 7/92 [00:02<00:36,  2.34it/s]\u001b[A\n",
      "Iteration:   9% 8/92 [00:03<00:36,  2.33it/s]\u001b[A\n",
      "Iteration:  10% 9/92 [00:03<00:35,  2.34it/s]\u001b[A\n",
      "Iteration:  11% 10/92 [00:04<00:35,  2.34it/s]\u001b[A\n",
      "Iteration:  12% 11/92 [00:04<00:34,  2.34it/s]\u001b[A\n",
      "Iteration:  13% 12/92 [00:05<00:34,  2.34it/s]\u001b[A\n",
      "Iteration:  14% 13/92 [00:05<00:33,  2.34it/s]\u001b[A\n",
      "Iteration:  15% 14/92 [00:05<00:33,  2.34it/s]\u001b[A\n",
      "Iteration:  16% 15/92 [00:06<00:32,  2.34it/s]\u001b[A\n",
      "Iteration:  17% 16/92 [00:06<00:32,  2.34it/s]\u001b[A\n",
      "Iteration:  18% 17/92 [00:07<00:32,  2.34it/s]\u001b[A\n",
      "Iteration:  20% 18/92 [00:07<00:31,  2.33it/s]\u001b[A\n",
      "Iteration:  21% 19/92 [00:08<00:31,  2.34it/s]\u001b[A\n",
      "Iteration:  22% 20/92 [00:08<00:30,  2.34it/s]\u001b[A\n",
      "Iteration:  23% 21/92 [00:08<00:30,  2.33it/s]\u001b[A\n",
      "Iteration:  24% 22/92 [00:09<00:30,  2.33it/s]\u001b[A\n",
      "Iteration:  25% 23/92 [00:09<00:29,  2.33it/s]\u001b[A\n",
      "Iteration:  26% 24/92 [00:10<00:29,  2.33it/s]\u001b[A\n",
      "Iteration:  27% 25/92 [00:10<00:28,  2.34it/s]\u001b[A\n",
      "Iteration:  28% 26/92 [00:11<00:28,  2.34it/s]\u001b[A\n",
      "Iteration:  29% 27/92 [00:11<00:27,  2.34it/s]\u001b[A\n",
      "Iteration:  30% 28/92 [00:11<00:27,  2.34it/s]\u001b[A\n",
      "Iteration:  32% 29/92 [00:12<00:26,  2.34it/s]\u001b[A\n",
      "Iteration:  33% 30/92 [00:12<00:26,  2.33it/s]\u001b[A\n",
      "Iteration:  34% 31/92 [00:13<00:26,  2.33it/s]\u001b[A\n",
      "Iteration:  35% 32/92 [00:13<00:25,  2.34it/s]\u001b[A\n",
      "Iteration:  36% 33/92 [00:14<00:25,  2.34it/s]\u001b[A\n",
      "Iteration:  37% 34/92 [00:14<00:24,  2.34it/s]\u001b[A\n",
      "Iteration:  38% 35/92 [00:14<00:24,  2.34it/s]\u001b[A\n",
      "Iteration:  39% 36/92 [00:15<00:23,  2.34it/s]\u001b[A\n",
      "Iteration:  40% 37/92 [00:15<00:23,  2.33it/s]\u001b[A\n",
      "Iteration:  41% 38/92 [00:16<00:23,  2.33it/s]\u001b[A\n",
      "Iteration:  42% 39/92 [00:16<00:22,  2.34it/s]\u001b[A\n",
      "Iteration:  43% 40/92 [00:17<00:22,  2.34it/s]\u001b[A\n",
      "Iteration:  45% 41/92 [00:17<00:21,  2.33it/s]\u001b[A\n",
      "Iteration:  46% 42/92 [00:17<00:21,  2.33it/s]\u001b[A\n",
      "Iteration:  47% 43/92 [00:18<00:21,  2.33it/s]\u001b[A\n",
      "Iteration:  48% 44/92 [00:18<00:20,  2.33it/s]\u001b[A\n",
      "Iteration:  49% 45/92 [00:19<00:20,  2.34it/s]\u001b[A\n",
      "Iteration:  50% 46/92 [00:19<00:19,  2.33it/s]\u001b[A\n",
      "Iteration:  51% 47/92 [00:20<00:19,  2.33it/s]\u001b[A\n",
      "Iteration:  52% 48/92 [00:20<00:18,  2.33it/s]\u001b[A\n",
      "Iteration:  53% 49/92 [00:20<00:18,  2.33it/s]\u001b[A\n",
      "Iteration:  54% 50/92 [00:21<00:18,  2.33it/s]\u001b[A\n",
      "Iteration:  55% 51/92 [00:21<00:17,  2.33it/s]\u001b[A\n",
      "Iteration:  57% 52/92 [00:22<00:17,  2.34it/s]\u001b[A\n",
      "Iteration:  58% 53/92 [00:22<00:16,  2.34it/s]\u001b[A\n",
      "Iteration:  59% 54/92 [00:23<00:16,  2.34it/s]\u001b[A\n",
      "Iteration:  60% 55/92 [00:23<00:15,  2.33it/s]\u001b[A\n",
      "Iteration:  61% 56/92 [00:23<00:15,  2.33it/s]\u001b[A\n",
      "Iteration:  62% 57/92 [00:24<00:14,  2.34it/s]\u001b[A\n",
      "Iteration:  63% 58/92 [00:24<00:14,  2.34it/s]\u001b[A\n",
      "Iteration:  64% 59/92 [00:25<00:14,  2.34it/s]\u001b[A\n",
      "Iteration:  65% 60/92 [00:25<00:13,  2.34it/s]\u001b[A\n",
      "Iteration:  66% 61/92 [00:26<00:13,  2.34it/s]\u001b[A\n",
      "Iteration:  67% 62/92 [00:26<00:12,  2.34it/s]\u001b[A\n",
      "Iteration:  68% 63/92 [00:26<00:12,  2.33it/s]\u001b[A\n",
      "Iteration:  70% 64/92 [00:27<00:12,  2.33it/s]\u001b[A\n",
      "Iteration:  71% 65/92 [00:27<00:11,  2.34it/s]\u001b[A\n",
      "Iteration:  72% 66/92 [00:28<00:11,  2.34it/s]\u001b[A\n",
      "Iteration:  73% 67/92 [00:28<00:10,  2.34it/s]\u001b[A\n",
      "Iteration:  74% 68/92 [00:29<00:10,  2.34it/s]\u001b[A\n",
      "Iteration:  75% 69/92 [00:29<00:09,  2.33it/s]\u001b[A\n",
      "Iteration:  76% 70/92 [00:29<00:09,  2.34it/s]\u001b[A\n",
      "Iteration:  77% 71/92 [00:30<00:08,  2.34it/s]\u001b[A\n",
      "Iteration:  78% 72/92 [00:30<00:08,  2.33it/s]\u001b[A\n",
      "Iteration:  79% 73/92 [00:31<00:08,  2.33it/s]\u001b[A\n",
      "Iteration:  80% 74/92 [00:31<00:07,  2.33it/s]\u001b[A\n",
      "Iteration:  82% 75/92 [00:32<00:07,  2.33it/s]\u001b[A\n",
      "Iteration:  83% 76/92 [00:32<00:06,  2.33it/s]\u001b[A\n",
      "Iteration:  84% 77/92 [00:32<00:06,  2.34it/s]\u001b[A\n",
      "Iteration:  85% 78/92 [00:33<00:05,  2.34it/s]\u001b[A\n",
      "Iteration:  86% 79/92 [00:33<00:05,  2.34it/s]\u001b[A\n",
      "Iteration:  87% 80/92 [00:34<00:05,  2.34it/s]\u001b[A\n",
      "Iteration:  88% 81/92 [00:34<00:04,  2.32it/s]\u001b[A\n",
      "Iteration:  89% 82/92 [00:35<00:04,  2.33it/s]\u001b[A\n",
      "Iteration:  90% 83/92 [00:35<00:03,  2.33it/s]\u001b[A\n",
      "Iteration:  91% 84/92 [00:35<00:03,  2.34it/s]\u001b[A\n",
      "Iteration:  92% 85/92 [00:36<00:02,  2.34it/s]\u001b[A\n",
      "Iteration:  93% 86/92 [00:36<00:02,  2.34it/s]\u001b[A\n",
      "Iteration:  95% 87/92 [00:37<00:02,  2.34it/s]\u001b[A\n",
      "Iteration:  96% 88/92 [00:37<00:01,  2.34it/s]\u001b[A\n",
      "Iteration:  97% 89/92 [00:38<00:01,  2.33it/s]\u001b[A\n",
      "Iteration:  98% 90/92 [00:38<00:00,  2.34it/s]\u001b[A\n",
      "Iteration:  99% 91/92 [00:38<00:00,  2.34it/s]\u001b[A\n",
      "Iteration: 100% 92/92 [00:39<00:00,  2.35it/s]\n",
      "Epoch:  80% 8/10 [05:13<01:18, 39.14s/it]\n",
      "Iteration:   0% 0/92 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   1% 1/92 [00:00<00:39,  2.31it/s]\u001b[A\n",
      "Iteration:   2% 2/92 [00:00<00:38,  2.32it/s]\u001b[A\n",
      "Iteration:   3% 3/92 [00:01<00:38,  2.33it/s]\u001b[A\n",
      "Iteration:   4% 4/92 [00:01<00:37,  2.33it/s]\u001b[A\n",
      "Iteration:   5% 5/92 [00:02<00:37,  2.34it/s]\u001b[A\n",
      "Iteration:   7% 6/92 [00:02<00:36,  2.34it/s]\u001b[A\n",
      "Iteration:   8% 7/92 [00:02<00:36,  2.34it/s]\u001b[A\n",
      "Iteration:   9% 8/92 [00:03<00:35,  2.34it/s]\u001b[A\n",
      "Iteration:  10% 9/92 [00:03<00:35,  2.34it/s]\u001b[A\n",
      "Iteration:  11% 10/92 [00:04<00:35,  2.34it/s]\u001b[A\n",
      "Iteration:  12% 11/92 [00:04<00:34,  2.34it/s]\u001b[A\n",
      "Iteration:  13% 12/92 [00:05<00:34,  2.34it/s]\u001b[A\n",
      "Iteration:  14% 13/92 [00:05<00:33,  2.33it/s]\u001b[A\n",
      "Iteration:  15% 14/92 [00:05<00:33,  2.33it/s]\u001b[A\n",
      "Iteration:  16% 15/92 [00:06<00:33,  2.33it/s]\u001b[A\n",
      "Iteration:  17% 16/92 [00:06<00:32,  2.33it/s]\u001b[A\n",
      "Iteration:  18% 17/92 [00:07<00:32,  2.33it/s]\u001b[A\n",
      "Iteration:  20% 18/92 [00:07<00:31,  2.33it/s]\u001b[A\n",
      "Iteration:  21% 19/92 [00:08<00:31,  2.34it/s]\u001b[A\n",
      "Iteration:  22% 20/92 [00:08<00:30,  2.34it/s]\u001b[A\n",
      "Iteration:  23% 21/92 [00:08<00:30,  2.34it/s]\u001b[A\n",
      "Iteration:  24% 22/92 [00:09<00:29,  2.34it/s]\u001b[A\n",
      "Iteration:  25% 23/92 [00:09<00:29,  2.34it/s]\u001b[A\n",
      "Iteration:  26% 24/92 [00:10<00:29,  2.34it/s]\u001b[A\n",
      "Iteration:  27% 25/92 [00:10<00:28,  2.34it/s]\u001b[A\n",
      "Iteration:  28% 26/92 [00:11<00:28,  2.34it/s]\u001b[A\n",
      "Iteration:  29% 27/92 [00:11<00:27,  2.34it/s]\u001b[A\n",
      "Iteration:  30% 28/92 [00:11<00:27,  2.34it/s]\u001b[A\n",
      "Iteration:  32% 29/92 [00:12<00:26,  2.34it/s]\u001b[A\n",
      "Iteration:  33% 30/92 [00:12<00:26,  2.34it/s]\u001b[A\n",
      "Iteration:  34% 31/92 [00:13<00:26,  2.33it/s]\u001b[A\n",
      "Iteration:  35% 32/92 [00:13<00:25,  2.33it/s]\u001b[A\n",
      "Iteration:  36% 33/92 [00:14<00:25,  2.34it/s]\u001b[A\n",
      "Iteration:  37% 34/92 [00:14<00:24,  2.33it/s]\u001b[A\n",
      "Iteration:  38% 35/92 [00:14<00:24,  2.34it/s]\u001b[A\n",
      "Iteration:  39% 36/92 [00:15<00:23,  2.34it/s]\u001b[A\n",
      "Iteration:  40% 37/92 [00:15<00:23,  2.34it/s]\u001b[A\n",
      "Iteration:  41% 38/92 [00:16<00:23,  2.35it/s]\u001b[A\n",
      "Iteration:  42% 39/92 [00:16<00:22,  2.34it/s]\u001b[A\n",
      "Iteration:  43% 40/92 [00:17<00:22,  2.34it/s]\u001b[A\n",
      "Iteration:  45% 41/92 [00:17<00:21,  2.34it/s]\u001b[A\n",
      "Iteration:  46% 42/92 [00:17<00:21,  2.34it/s]\u001b[A\n",
      "Iteration:  47% 43/92 [00:18<00:20,  2.34it/s]\u001b[A\n",
      "Iteration:  48% 44/92 [00:18<00:20,  2.34it/s]\u001b[A\n",
      "Iteration:  49% 45/92 [00:19<00:20,  2.34it/s]\u001b[A\n",
      "Iteration:  50% 46/92 [00:19<00:19,  2.34it/s]\u001b[A\n",
      "Iteration:  51% 47/92 [00:20<00:19,  2.34it/s]\u001b[A\n",
      "Iteration:  52% 48/92 [00:20<00:18,  2.35it/s]\u001b[A\n",
      "Iteration:  53% 49/92 [00:20<00:18,  2.35it/s]\u001b[A\n",
      "Iteration:  54% 50/92 [00:21<00:17,  2.35it/s]\u001b[A\n",
      "Iteration:  55% 51/92 [00:21<00:17,  2.34it/s]\u001b[A\n",
      "Iteration:  57% 52/92 [00:22<00:17,  2.34it/s]\u001b[A\n",
      "Iteration:  58% 53/92 [00:22<00:16,  2.34it/s]\u001b[A\n",
      "Iteration:  59% 54/92 [00:23<00:16,  2.34it/s]\u001b[A\n",
      "Iteration:  60% 55/92 [00:23<00:15,  2.34it/s]\u001b[A\n",
      "Iteration:  61% 56/92 [00:23<00:15,  2.34it/s]\u001b[A\n",
      "Iteration:  62% 57/92 [00:24<00:14,  2.34it/s]\u001b[A\n",
      "Iteration:  63% 58/92 [00:24<00:14,  2.34it/s]\u001b[A\n",
      "Iteration:  64% 59/92 [00:25<00:14,  2.34it/s]\u001b[A\n",
      "Iteration:  65% 60/92 [00:25<00:13,  2.35it/s]\u001b[A\n",
      "Iteration:  66% 61/92 [00:26<00:13,  2.35it/s]\u001b[A\n",
      "Iteration:  67% 62/92 [00:26<00:12,  2.35it/s]\u001b[A\n",
      "Iteration:  68% 63/92 [00:26<00:12,  2.35it/s]\u001b[A\n",
      "Iteration:  70% 64/92 [00:27<00:11,  2.34it/s]\u001b[A\n",
      "Iteration:  71% 65/92 [00:27<00:11,  2.34it/s]\u001b[A\n",
      "Iteration:  72% 66/92 [00:28<00:11,  2.34it/s]\u001b[A\n",
      "Iteration:  73% 67/92 [00:28<00:10,  2.34it/s]\u001b[A\n",
      "Iteration:  74% 68/92 [00:29<00:10,  2.34it/s]\u001b[A\n",
      "Iteration:  75% 69/92 [00:29<00:09,  2.34it/s]\u001b[A\n",
      "Iteration:  76% 70/92 [00:29<00:09,  2.34it/s]\u001b[A\n",
      "Iteration:  77% 71/92 [00:30<00:08,  2.34it/s]\u001b[A\n",
      "Iteration:  78% 72/92 [00:30<00:08,  2.34it/s]\u001b[A\n",
      "Iteration:  79% 73/92 [00:31<00:08,  2.34it/s]\u001b[A\n",
      "Iteration:  80% 74/92 [00:31<00:07,  2.33it/s]\u001b[A\n",
      "Iteration:  82% 75/92 [00:32<00:07,  2.34it/s]\u001b[A\n",
      "Iteration:  83% 76/92 [00:32<00:06,  2.34it/s]\u001b[A\n",
      "Iteration:  84% 77/92 [00:32<00:06,  2.34it/s]\u001b[A\n",
      "Iteration:  85% 78/92 [00:33<00:05,  2.34it/s]\u001b[A\n",
      "Iteration:  86% 79/92 [00:33<00:05,  2.34it/s]\u001b[A\n",
      "Iteration:  87% 80/92 [00:34<00:05,  2.34it/s]\u001b[A\n",
      "Iteration:  88% 81/92 [00:34<00:04,  2.34it/s]\u001b[A\n",
      "Iteration:  89% 82/92 [00:35<00:04,  2.34it/s]\u001b[A\n",
      "Iteration:  90% 83/92 [00:35<00:03,  2.33it/s]\u001b[A\n",
      "Iteration:  91% 84/92 [00:35<00:03,  2.33it/s]\u001b[A\n",
      "Iteration:  92% 85/92 [00:36<00:02,  2.34it/s]\u001b[A\n",
      "Iteration:  93% 86/92 [00:36<00:02,  2.34it/s]\u001b[A\n",
      "Iteration:  95% 87/92 [00:37<00:02,  2.34it/s]\u001b[A\n",
      "Iteration:  96% 88/92 [00:37<00:01,  2.34it/s]\u001b[A\n",
      "Iteration:  97% 89/92 [00:38<00:01,  2.34it/s]\u001b[A\n",
      "Iteration:  98% 90/92 [00:38<00:00,  2.34it/s]\u001b[A\n",
      "Iteration:  99% 91/92 [00:38<00:00,  2.33it/s]\u001b[A\n",
      "Iteration: 100% 92/92 [00:39<00:00,  2.35it/s]\n",
      "Epoch:  90% 9/10 [05:52<00:39, 39.13s/it]\n",
      "Iteration:   0% 0/92 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   1% 1/92 [00:00<00:39,  2.31it/s]\u001b[A\n",
      "Iteration:   2% 2/92 [00:00<00:38,  2.31it/s]\u001b[A\n",
      "Iteration:   3% 3/92 [00:01<00:38,  2.33it/s]\u001b[A\n",
      "Iteration:   4% 4/92 [00:01<00:37,  2.33it/s]\u001b[A\n",
      "Iteration:   5% 5/92 [00:02<00:37,  2.34it/s]\u001b[A\n",
      "Iteration:   7% 6/92 [00:02<00:36,  2.34it/s]\u001b[A\n",
      "Iteration:   8% 7/92 [00:02<00:36,  2.34it/s]\u001b[A\n",
      "Iteration:   9% 8/92 [00:03<00:35,  2.34it/s]\u001b[A\n",
      "Iteration:  10% 9/92 [00:03<00:35,  2.33it/s]\u001b[A\n",
      "Iteration:  11% 10/92 [00:04<00:35,  2.33it/s]\u001b[A\n",
      "Iteration:  12% 11/92 [00:04<00:34,  2.33it/s]\u001b[A\n",
      "Iteration:  13% 12/92 [00:05<00:34,  2.34it/s]\u001b[A\n",
      "Iteration:  14% 13/92 [00:05<00:33,  2.35it/s]\u001b[A\n",
      "Iteration:  15% 14/92 [00:05<00:33,  2.34it/s]\u001b[A\n",
      "Iteration:  16% 15/92 [00:06<00:32,  2.35it/s]\u001b[A\n",
      "Iteration:  17% 16/92 [00:06<00:32,  2.35it/s]\u001b[A\n",
      "Iteration:  18% 17/92 [00:07<00:31,  2.35it/s]\u001b[A\n",
      "Iteration:  20% 18/92 [00:07<00:31,  2.34it/s]\u001b[A\n",
      "Iteration:  21% 19/92 [00:08<00:31,  2.34it/s]\u001b[A\n",
      "Iteration:  22% 20/92 [00:08<00:30,  2.34it/s]\u001b[A\n",
      "Iteration:  23% 21/92 [00:08<00:30,  2.34it/s]\u001b[A\n",
      "Iteration:  24% 22/92 [00:09<00:29,  2.34it/s]\u001b[A\n",
      "Iteration:  25% 23/92 [00:09<00:29,  2.34it/s]\u001b[A\n",
      "Iteration:  26% 24/92 [00:10<00:29,  2.34it/s]\u001b[A\n",
      "Iteration:  27% 25/92 [00:10<00:28,  2.34it/s]\u001b[A\n",
      "Iteration:  28% 26/92 [00:11<00:28,  2.35it/s]\u001b[A\n",
      "Iteration:  29% 27/92 [00:11<00:27,  2.34it/s]\u001b[A\n",
      "Iteration:  30% 28/92 [00:11<00:27,  2.34it/s]\u001b[A\n",
      "Iteration:  32% 29/92 [00:12<00:26,  2.34it/s]\u001b[A\n",
      "Iteration:  33% 30/92 [00:12<00:26,  2.34it/s]\u001b[A\n",
      "Iteration:  34% 31/92 [00:13<00:26,  2.33it/s]\u001b[A\n",
      "Iteration:  35% 32/92 [00:13<00:25,  2.33it/s]\u001b[A\n",
      "Iteration:  36% 33/92 [00:14<00:25,  2.33it/s]\u001b[A\n",
      "Iteration:  37% 34/92 [00:14<00:24,  2.33it/s]\u001b[A\n",
      "Iteration:  38% 35/92 [00:14<00:24,  2.34it/s]\u001b[A\n",
      "Iteration:  39% 36/92 [00:15<00:23,  2.34it/s]\u001b[A\n",
      "Iteration:  40% 37/92 [00:15<00:23,  2.34it/s]\u001b[A\n",
      "Iteration:  41% 38/92 [00:16<00:23,  2.34it/s]\u001b[A\n",
      "Iteration:  42% 39/92 [00:16<00:22,  2.34it/s]\u001b[A\n",
      "Iteration:  43% 40/92 [00:17<00:22,  2.34it/s]\u001b[A\n",
      "Iteration:  45% 41/92 [00:17<00:21,  2.35it/s]\u001b[A\n",
      "Iteration:  46% 42/92 [00:17<00:21,  2.34it/s]\u001b[A\n",
      "Iteration:  47% 43/92 [00:18<00:20,  2.34it/s]\u001b[A\n",
      "Iteration:  48% 44/92 [00:18<00:20,  2.34it/s]\u001b[A\n",
      "Iteration:  49% 45/92 [00:19<00:20,  2.34it/s]\u001b[A\n",
      "Iteration:  50% 46/92 [00:19<00:19,  2.34it/s]\u001b[A\n",
      "Iteration:  51% 47/92 [00:20<00:19,  2.34it/s]\u001b[A\n",
      "Iteration:  52% 48/92 [00:20<00:18,  2.34it/s]\u001b[A\n",
      "Iteration:  53% 49/92 [00:20<00:18,  2.34it/s]\u001b[A\n",
      "Iteration:  54% 50/92 [00:21<00:17,  2.34it/s]\u001b[A\n",
      "Iteration:  55% 51/92 [00:21<00:17,  2.34it/s]\u001b[A\n",
      "Iteration:  57% 52/92 [00:22<00:17,  2.34it/s]\u001b[A\n",
      "Iteration:  58% 53/92 [00:22<00:16,  2.34it/s]\u001b[A\n",
      "Iteration:  59% 54/92 [00:23<00:16,  2.34it/s]\u001b[A\n",
      "Iteration:  60% 55/92 [00:23<00:15,  2.34it/s]\u001b[A\n",
      "Iteration:  61% 56/92 [00:23<00:15,  2.34it/s]\u001b[A\n",
      "Iteration:  62% 57/92 [00:24<00:15,  2.33it/s]\u001b[A\n",
      "Iteration:  63% 58/92 [00:24<00:14,  2.33it/s]\u001b[A\n",
      "Iteration:  64% 59/92 [00:25<00:14,  2.33it/s]\u001b[A\n",
      "Iteration:  65% 60/92 [00:25<00:13,  2.34it/s]\u001b[A\n",
      "Iteration:  66% 61/92 [00:26<00:13,  2.34it/s]\u001b[A\n",
      "Iteration:  67% 62/92 [00:26<00:12,  2.34it/s]\u001b[A\n",
      "Iteration:  68% 63/92 [00:26<00:12,  2.33it/s]\u001b[A\n",
      "Iteration:  70% 64/92 [00:27<00:12,  2.33it/s]\u001b[A\n",
      "Iteration:  71% 65/92 [00:27<00:11,  2.33it/s]\u001b[A\n",
      "Iteration:  72% 66/92 [00:28<00:11,  2.33it/s]\u001b[A\n",
      "Iteration:  73% 67/92 [00:28<00:10,  2.33it/s]\u001b[A\n",
      "Iteration:  74% 68/92 [00:29<00:10,  2.34it/s]\u001b[A\n",
      "Iteration:  75% 69/92 [00:29<00:09,  2.34it/s]\u001b[A\n",
      "Iteration:  76% 70/92 [00:29<00:09,  2.34it/s]\u001b[A\n",
      "Iteration:  77% 71/92 [00:30<00:08,  2.34it/s]\u001b[A\n",
      "Iteration:  78% 72/92 [00:30<00:08,  2.34it/s]\u001b[A\n",
      "Iteration:  79% 73/92 [00:31<00:08,  2.35it/s]\u001b[A\n",
      "Iteration:  80% 74/92 [00:31<00:07,  2.34it/s]\u001b[A\n",
      "Iteration:  82% 75/92 [00:32<00:07,  2.34it/s]\u001b[A\n",
      "Iteration:  83% 76/92 [00:32<00:06,  2.34it/s]\u001b[A\n",
      "Iteration:  84% 77/92 [00:32<00:06,  2.33it/s]\u001b[A\n",
      "Iteration:  85% 78/92 [00:33<00:05,  2.34it/s]\u001b[A\n",
      "Iteration:  86% 79/92 [00:33<00:05,  2.33it/s]\u001b[A\n",
      "Iteration:  87% 80/92 [00:34<00:05,  2.33it/s]\u001b[A\n",
      "Iteration:  88% 81/92 [00:34<00:04,  2.34it/s]\u001b[A\n",
      "Iteration:  89% 82/92 [00:35<00:04,  2.34it/s]\u001b[A\n",
      "Iteration:  90% 83/92 [00:35<00:03,  2.34it/s]\u001b[A\n",
      "Iteration:  91% 84/92 [00:35<00:03,  2.34it/s]\u001b[A\n",
      "Iteration:  92% 85/92 [00:36<00:02,  2.34it/s]\u001b[A\n",
      "Iteration:  93% 86/92 [00:36<00:02,  2.34it/s]\u001b[A\n",
      "Iteration:  95% 87/92 [00:37<00:02,  2.34it/s]\u001b[A\n",
      "Iteration:  96% 88/92 [00:37<00:01,  2.33it/s]\u001b[A\n",
      "Iteration:  97% 89/92 [00:38<00:01,  2.33it/s]\u001b[A\n",
      "Iteration:  98% 90/92 [00:38<00:00,  2.33it/s]\u001b[A\n",
      "Iteration:  99% 91/92 [00:38<00:00,  2.34it/s]\u001b[A\n",
      "Iteration: 100% 92/92 [00:39<00:00,  2.35it/s]\n",
      "Epoch: 100% 10/10 [06:31<00:00, 39.14s/it]\n",
      "11/05/2020 15:09:00 - INFO - __main__ -    global_step = 920, average loss = 0.09991488769652357\n",
      "11/05/2020 15:09:00 - INFO - __main__ -   Saving model checkpoint to model-xlmroberta-e10-manual\n",
      "11/05/2020 15:09:00 - INFO - transformers.configuration_utils -   Configuration saved in model-xlmroberta-e10-manual/config.json\n",
      "11/05/2020 15:09:06 - INFO - transformers.modeling_utils -   Model weights saved in model-xlmroberta-e10-manual/pytorch_model.bin\n",
      "11/05/2020 15:09:06 - INFO - transformers.configuration_utils -   loading configuration file model-xlmroberta-e10-manual/config.json\n",
      "11/05/2020 15:09:06 - INFO - transformers.configuration_utils -   Model config XLMRobertaConfig {\n",
      "  \"_num_labels\": 2,\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "11/05/2020 15:09:06 - INFO - transformers.tokenization_utils -   Model name 'model-xlmroberta-e10-manual' not found in model shortcut name list (xlm-roberta-base, xlm-roberta-large, xlm-roberta-large-finetuned-conll02-dutch, xlm-roberta-large-finetuned-conll02-spanish, xlm-roberta-large-finetuned-conll03-english, xlm-roberta-large-finetuned-conll03-german). Assuming 'model-xlmroberta-e10-manual' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "11/05/2020 15:09:06 - INFO - transformers.tokenization_utils -   Didn't find file model-xlmroberta-e10-manual/added_tokens.json. We won't load it.\n",
      "11/05/2020 15:09:06 - INFO - transformers.tokenization_utils -   loading file model-xlmroberta-e10-manual/sentencepiece.bpe.model\n",
      "11/05/2020 15:09:06 - INFO - transformers.tokenization_utils -   loading file None\n",
      "11/05/2020 15:09:06 - INFO - transformers.tokenization_utils -   loading file model-xlmroberta-e10-manual/special_tokens_map.json\n",
      "11/05/2020 15:09:06 - INFO - transformers.tokenization_utils -   loading file model-xlmroberta-e10-manual/tokenizer_config.json\n",
      "11/05/2020 15:09:07 - INFO - __main__ -   Evaluate the following checkpoints: ['model-xlmroberta-e10-manual']\n",
      "11/05/2020 15:09:07 - INFO - transformers.configuration_utils -   loading configuration file model-xlmroberta-e10-manual/config.json\n",
      "11/05/2020 15:09:07 - INFO - transformers.configuration_utils -   Model config XLMRobertaConfig {\n",
      "  \"_num_labels\": 2,\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "11/05/2020 15:09:07 - INFO - transformers.modeling_utils -   loading weights file model-xlmroberta-e10-manual/pytorch_model.bin\n",
      "11/05/2020 15:09:20 - INFO - __main__ -   Creating features from dataset file at /content/gdrive/My Drive/pythoncode/experiments/corpus_manual_1_5stars\n",
      "100% 180/180 [00:00<00:00, 12343.45it/s]\n",
      "11/05/2020 15:09:21 - INFO - __main__ -   Saving features into cached file /content/gdrive/My Drive/pythoncode/experiments/corpus_manual_1_5stars/cached_dev_xlm-roberta-base_128\n",
      "11/05/2020 15:09:21 - INFO - __main__ -   ***** Running evaluation  on  dev set*****\n",
      "11/05/2020 15:09:21 - INFO - __main__ -     Num examples = 180\n",
      "11/05/2020 15:09:21 - INFO - __main__ -     Batch size = 8\n",
      "Evaluating: 100% 23/23 [00:01<00:00, 16.13it/s]\n",
      "11/05/2020 15:09:22 - INFO - __main__ -   ***** Eval results  on dev set*****\n",
      "11/05/2020 15:09:22 - INFO - __main__ -     f1 = 0.9722222222222222\n",
      "11/05/2020 15:09:22 - INFO - __main__ -     loss = 0.2567195148254225\n",
      "11/05/2020 15:09:22 - INFO - __main__ -     precision = 0.9722222222222222\n",
      "11/05/2020 15:09:22 - INFO - __main__ -     recall = 0.9722222222222222\n",
      "11/05/2020 15:09:22 - INFO - __main__ -     report =\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE     1.0000    0.9444    0.9714        90\n",
      "    POSITIVE     0.9474    1.0000    0.9730        90\n",
      "\n",
      "    accuracy                         0.9722       180\n",
      "   macro avg     0.9737    0.9722    0.9722       180\n",
      "weighted avg     0.9737    0.9722    0.9722       180\n",
      "\n",
      "11/05/2020 15:09:22 - INFO - transformers.configuration_utils -   loading configuration file model-xlmroberta-e10-manual/config.json\n",
      "11/05/2020 15:09:22 - INFO - transformers.configuration_utils -   Model config XLMRobertaConfig {\n",
      "  \"_num_labels\": 2,\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "11/05/2020 15:09:22 - INFO - transformers.tokenization_utils -   Model name 'model-xlmroberta-e10-manual' not found in model shortcut name list (xlm-roberta-base, xlm-roberta-large, xlm-roberta-large-finetuned-conll02-dutch, xlm-roberta-large-finetuned-conll02-spanish, xlm-roberta-large-finetuned-conll03-english, xlm-roberta-large-finetuned-conll03-german). Assuming 'model-xlmroberta-e10-manual' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "11/05/2020 15:09:22 - INFO - transformers.tokenization_utils -   Didn't find file model-xlmroberta-e10-manual/added_tokens.json. We won't load it.\n",
      "11/05/2020 15:09:22 - INFO - transformers.tokenization_utils -   loading file model-xlmroberta-e10-manual/sentencepiece.bpe.model\n",
      "11/05/2020 15:09:22 - INFO - transformers.tokenization_utils -   loading file None\n",
      "11/05/2020 15:09:22 - INFO - transformers.tokenization_utils -   loading file model-xlmroberta-e10-manual/special_tokens_map.json\n",
      "11/05/2020 15:09:22 - INFO - transformers.tokenization_utils -   loading file model-xlmroberta-e10-manual/tokenizer_config.json\n",
      "11/05/2020 15:09:23 - INFO - transformers.configuration_utils -   loading configuration file model-xlmroberta-e10-manual/config.json\n",
      "11/05/2020 15:09:23 - INFO - transformers.configuration_utils -   Model config XLMRobertaConfig {\n",
      "  \"_num_labels\": 2,\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "11/05/2020 15:09:23 - INFO - transformers.modeling_utils -   loading weights file model-xlmroberta-e10-manual/pytorch_model.bin\n",
      "11/05/2020 15:09:36 - INFO - __main__ -   Creating features from dataset file at /content/gdrive/My Drive/pythoncode/experiments/corpus_manual_1_5stars\n",
      "100% 360/360 [00:00<00:00, 13044.81it/s]\n",
      "11/05/2020 15:09:37 - INFO - __main__ -   Saving features into cached file /content/gdrive/My Drive/pythoncode/experiments/corpus_manual_1_5stars/cached_test_xlm-roberta-base_128\n",
      "11/05/2020 15:09:37 - INFO - __main__ -   ***** Running evaluation  on  test set*****\n",
      "11/05/2020 15:09:37 - INFO - __main__ -     Num examples = 360\n",
      "11/05/2020 15:09:37 - INFO - __main__ -     Batch size = 8\n",
      "Evaluating: 100% 45/45 [00:02<00:00, 15.90it/s]\n",
      "11/05/2020 15:09:40 - INFO - __main__ -   ***** Eval results  on test set*****\n",
      "11/05/2020 15:09:40 - INFO - __main__ -     f1 = 0.9777777777777777\n",
      "11/05/2020 15:09:40 - INFO - __main__ -     loss = 0.15040612603544207\n",
      "11/05/2020 15:09:40 - INFO - __main__ -     precision = 0.9777777777777777\n",
      "11/05/2020 15:09:40 - INFO - __main__ -     recall = 0.9777777777777777\n",
      "11/05/2020 15:09:40 - INFO - __main__ -     report =\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE     0.9886    0.9667    0.9775       180\n",
      "    POSITIVE     0.9674    0.9889    0.9780       180\n",
      "\n",
      "    accuracy                         0.9778       360\n",
      "   macro avg     0.9780    0.9778    0.9778       360\n",
      "weighted avg     0.9780    0.9778    0.9778       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=0\n",
    "!export MAX_LENGTH=128\n",
    "!export TRAIN_BATCH_SIZE=16\n",
    "!export LEARNING_RATE=5e-5\n",
    "!export SAVE_STEPS=0\n",
    "!export SEED=1\n",
    "!export EPOCHS=10\n",
    "!export CORPUS_DIR=/content/gdrive/My\\ Drive/pythoncode/experiments/ruido0_1_5_stars\n",
    "\n",
    "!mkdir model-xlmroberta-e10-manual\n",
    "\n",
    "!python /content/gdrive/My\\ Drive/pythoncode/transformers-training-scripts-master/run_classification.py --data_dir=/content/gdrive/My\\ Drive/pythoncode/experiments/ruido0_1_5_stars  \\\n",
    "--labels /content/gdrive/My\\ Drive/pythoncode/experiments/ruido0_1_5_stars/labels.txt \\\n",
    "--model_type xlm-roberta \\\n",
    "--model_name_or_path 'xlm-roberta-base' \\\n",
    "--output_dir='model-xlmroberta-e10-manual' \\\n",
    "--max_seq_length 128 \\\n",
    "--num_train_epochs=10 \\\n",
    "--per_gpu_train_batch_size 16 \\\n",
    "--learning_rate 5e-5 \\\n",
    "--save_steps 0 \\\n",
    "--seed 1 \\\n",
    "--overwrite_cache \\\n",
    "--do_train \\\n",
    "--do_eval \\\n",
    "--do_predict \\\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNyc3QewevMOGipo9V+6Ekk",
   "collapsed_sections": [],
   "name": "Copia de 5octubre_corpusMANUAL2_5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
